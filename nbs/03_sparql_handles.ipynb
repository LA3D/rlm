{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# sparql_handles\n",
    "\n",
    "> SPARQL query execution with first-class result handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp sparql_handles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This module implements Stage 3 from the trajectory: SPARQL query execution with first-class result handles.\n",
    "\n",
    "### Result Handle Pattern\n",
    "\n",
    "Every SPARQL execution produces a `SPARQLResultHandle` with:\n",
    "- `meta`: query, endpoint/local, timestamp, row count, columns\n",
    "- `rows`: stored internally as list of dicts (SELECT) or Graph (CONSTRUCT/DESCRIBE)\n",
    "- Bounded view operations: `res_head()`, `res_where()`, `res_group()`, `res_sample()`\n",
    "\n",
    "### Progressive Disclosure\n",
    "\n",
    "Result handles enable the root model to refine queries by inspecting metadata and small slices, not rerunning blind queries.\n",
    "\n",
    "### Dataset Integration\n",
    "\n",
    "SPARQL results can optionally be stored in dataset work graphs with full provenance tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from sparqlx import SPARQLWrapper\n",
    "from rdflib import Graph, URIRef, Literal\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import random\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## SPARQLResultHandle\n",
    "\n",
    "Unified wrapper for all SPARQL result types with metadata and bounded view operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class SPARQLResultHandle:\n",
    "    \"\"\"Wrapper for SPARQL results with metadata and bounded view operations.\"\"\"\n",
    "\n",
    "    # Result data (never dumped wholesale to LLM)\n",
    "    rows: list | Graph          # SELECT rows or CONSTRUCT/DESCRIBE graph\n",
    "    result_type: str            # 'select' | 'ask' | 'construct' | 'describe'\n",
    "\n",
    "    # Metadata\n",
    "    query: str                  # Original SPARQL query\n",
    "    endpoint: str               # Where executed (URL or 'local')\n",
    "    timestamp: str = field(default_factory=lambda: datetime.utcnow().isoformat() + 'Z')\n",
    "\n",
    "    # For SELECT results\n",
    "    columns: list = None        # Column names\n",
    "    total_rows: int = 0         # Total before limit\n",
    "\n",
    "    # For Graph results\n",
    "    triple_count: int = 0       # Number of triples\n",
    "\n",
    "    def summary(self) -> str:\n",
    "        \"\"\"Bounded summary for LLM.\"\"\"\n",
    "        if self.result_type == 'select':\n",
    "            return f\"SELECT: {len(self.rows)} rows, columns={self.columns}\"\n",
    "        elif self.result_type == 'ask':\n",
    "            return f\"ASK: {self.rows}\"\n",
    "        else:\n",
    "            return f\"{self.result_type.upper()}: {self.triple_count} triples\"\n",
    "\n",
    "    def __len__(self):\n",
    "        if isinstance(self.rows, bool):\n",
    "            return 1  # ASK result\n",
    "        return len(self.rows) if hasattr(self.rows, '__len__') else 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        if isinstance(self.rows, bool):\n",
    "            return iter([self.rows])\n",
    "        return iter(self.rows)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"SPARQLResultHandle({self.summary()})\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "Test SPARQLResultHandle with different result types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SELECT result\n",
    "select_handle = SPARQLResultHandle(\n",
    "    rows=[{'s': 'http://ex.org/alice', 'age': '30'}],\n",
    "    result_type='select',\n",
    "    query='SELECT ?s ?age WHERE { ?s :age ?age }',\n",
    "    endpoint='local',\n",
    "    columns=['s', 'age'],\n",
    "    total_rows=1\n",
    ")\n",
    "assert select_handle.summary() == \"SELECT: 1 rows, columns=['s', 'age']\"\n",
    "assert len(select_handle) == 1\n",
    "print(f\"✓ SELECT handle: {select_handle}\")\n",
    "\n",
    "# Test ASK result\n",
    "ask_handle = SPARQLResultHandle(\n",
    "    rows=True,\n",
    "    result_type='ask',\n",
    "    query='ASK { ?s ?p ?o }',\n",
    "    endpoint='local'\n",
    ")\n",
    "assert ask_handle.summary() == \"ASK: True\"\n",
    "print(f\"✓ ASK handle: {ask_handle}\")\n",
    "\n",
    "# Test CONSTRUCT result\n",
    "g = Graph()\n",
    "g.add((URIRef('http://ex.org/alice'), URIRef('http://ex.org/age'), Literal('30')))\n",
    "construct_handle = SPARQLResultHandle(\n",
    "    rows=g,\n",
    "    result_type='construct',\n",
    "    query='CONSTRUCT { ?s ?p ?o } WHERE { ?s ?p ?o }',\n",
    "    endpoint='local',\n",
    "    triple_count=1\n",
    ")\n",
    "assert construct_handle.summary() == \"CONSTRUCT: 1 triples\"\n",
    "print(f\"✓ CONSTRUCT handle: {construct_handle}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Remote SPARQL Query\n",
    "\n",
    "Execute SPARQL queries against remote endpoints and return result handles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def sparql_query(\n",
    "    query: str,\n",
    "    endpoint: str = \"https://query.wikidata.org/sparql\",\n",
    "    max_results: int = 100,\n",
    "    name: str = 'res',\n",
    "    ns: dict = None,\n",
    "    timeout: float = 30.0,\n",
    "    # Dataset integration\n",
    "    ds_meta = None,\n",
    "    store_in_work: bool = False,\n",
    "    work_task_id: str = None\n",
    ") -> str:\n",
    "    \"\"\"Execute SPARQL query, store SPARQLResultHandle in namespace.\n",
    "\n",
    "    For SELECT: Stores SPARQLResultHandle with rows as list of dicts\n",
    "    For CONSTRUCT/DESCRIBE: Stores SPARQLResultHandle with rdflib.Graph\n",
    "    For ASK: Stores SPARQLResultHandle with boolean result\n",
    "\n",
    "    If ds_meta provided and store_in_work=True:\n",
    "    - CONSTRUCT results stored in work/<task_id> graph\n",
    "    - Query logged to prov graph\n",
    "    \n",
    "    Args:\n",
    "        query: SPARQL query string\n",
    "        endpoint: SPARQL endpoint URL\n",
    "        max_results: Maximum results to return (for SELECT/CONSTRUCT)\n",
    "        name: Variable name to store result handle\n",
    "        ns: Namespace dict (defaults to globals())\n",
    "        timeout: Query timeout in seconds\n",
    "        ds_meta: Optional DatasetMeta for dataset integration\n",
    "        store_in_work: If True and ds_meta provided, store CONSTRUCT results in work graph\n",
    "        work_task_id: Task ID for work graph (auto-generated if None)\n",
    "        \n",
    "    Returns:\n",
    "        Summary string describing the result\n",
    "    \"\"\"\n",
    "    if ns is None:\n",
    "        ns = globals()\n",
    "    \n",
    "    # Configure wrapper with timeout and headers\n",
    "    headers = {\"User-Agent\": \"RLM/1.0 (https://github.com/LA3D/rlm)\"}\n",
    "    wrapper = SPARQLWrapper(\n",
    "        sparql_endpoint=endpoint,\n",
    "        client_config=dict(timeout=timeout, headers=headers)\n",
    "    )\n",
    "    \n",
    "    # Execute query with rdflib conversion\n",
    "    result = wrapper.query(query, convert=True)\n",
    "    \n",
    "    # Determine result type and create handle\n",
    "    if isinstance(result, bool):\n",
    "        # ASK query\n",
    "        handle = SPARQLResultHandle(\n",
    "            rows=result,\n",
    "            result_type='ask',\n",
    "            query=query,\n",
    "            endpoint=endpoint\n",
    "        )\n",
    "        ns[name] = handle\n",
    "        return f\"ASK result: {result}, stored in '{name}'\"\n",
    "    \n",
    "    elif hasattr(result, 'serialize'):\n",
    "        # CONSTRUCT or DESCRIBE query - result is rdflib.Graph\n",
    "        triples = list(result)[:max_results]\n",
    "        g = Graph()\n",
    "        for t in triples:\n",
    "            g.add(t)\n",
    "        \n",
    "        # Determine if CONSTRUCT or DESCRIBE\n",
    "        query_upper = query.upper()\n",
    "        result_type = 'construct' if 'CONSTRUCT' in query_upper else 'describe'\n",
    "        \n",
    "        handle = SPARQLResultHandle(\n",
    "            rows=g,\n",
    "            result_type=result_type,\n",
    "            query=query,\n",
    "            endpoint=endpoint,\n",
    "            triple_count=len(g)\n",
    "        )\n",
    "        ns[name] = handle\n",
    "        \n",
    "        # Dataset integration for CONSTRUCT results\n",
    "        if ds_meta is not None and store_in_work:\n",
    "            from rlm.dataset import work_create\n",
    "            import uuid\n",
    "            \n",
    "            task_id = work_task_id if work_task_id else f\"sparql_{uuid.uuid4().hex[:8]}\"\n",
    "            graph_uri, work_graph = work_create(ds_meta, task_id)\n",
    "            \n",
    "            # Copy triples to work graph\n",
    "            for s, p, o in g:\n",
    "                work_graph.add((s, p, o))\n",
    "            \n",
    "            # Log query to prov\n",
    "            from rdflib import Namespace, RDF, XSD\n",
    "            RLM_PROV = Namespace('urn:rlm:prov:')\n",
    "            event_uri = URIRef(f'urn:rlm:prov:sparql_{uuid.uuid4().hex[:8]}')\n",
    "            ds_meta.prov.add((event_uri, RDF.type, RLM_PROV.SPARQLQuery))\n",
    "            ds_meta.prov.add((event_uri, RLM_PROV.query, Literal(query)))\n",
    "            ds_meta.prov.add((event_uri, RLM_PROV.endpoint, Literal(endpoint)))\n",
    "            ds_meta.prov.add((event_uri, RLM_PROV.resultGraph, URIRef(graph_uri)))\n",
    "            ds_meta.prov.add((event_uri, RLM_PROV.timestamp, Literal(handle.timestamp, datatype=XSD.dateTime)))\n",
    "            ds_meta.prov.add((event_uri, RLM_PROV.session, Literal(ds_meta.session_id)))\n",
    "            \n",
    "            return f\"Graph with {len(g)} triples stored in '{name}' and work/{task_id}\" + \\\n",
    "                   (f\" (truncated from {len(result)})\" if len(result) > max_results else \"\")\n",
    "        \n",
    "        return f\"Graph with {len(g)} triples stored in '{name}'\" + \\\n",
    "               (f\" (truncated from {len(result)})\" if len(result) > max_results else \"\")\n",
    "    \n",
    "    else:\n",
    "        # SELECT query - result is list of dicts\n",
    "        result = result[:max_results]\n",
    "        cols = list(result[0].keys()) if result else []\n",
    "        \n",
    "        handle = SPARQLResultHandle(\n",
    "            rows=result,\n",
    "            result_type='select',\n",
    "            query=query,\n",
    "            endpoint=endpoint,\n",
    "            columns=cols,\n",
    "            total_rows=len(result)\n",
    "        )\n",
    "        ns[name] = handle\n",
    "        \n",
    "        return f\"SELECT result with {len(result)} rows, columns: {cols}, stored in '{name}'\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "Test against Wikidata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# Test SELECT query against Wikidata\n",
    "test_ns = {}\n",
    "result = sparql_query(\n",
    "    \"SELECT ?s ?p ?o WHERE { ?s ?p ?o } LIMIT 5\",\n",
    "    ns=test_ns,\n",
    "    name='wikidata_test'\n",
    ")\n",
    "print(result)\n",
    "assert 'wikidata_test' in test_ns\n",
    "assert isinstance(test_ns['wikidata_test'], SPARQLResultHandle)\n",
    "assert test_ns['wikidata_test'].result_type == 'select'\n",
    "assert len(test_ns['wikidata_test'].rows) == 5\n",
    "print(f\"✓ SELECT query works: {test_ns['wikidata_test'].summary()}\")\n",
    "\n",
    "# Test CONSTRUCT query\n",
    "result = sparql_query(\n",
    "    \"CONSTRUCT { ?s ?p ?o } WHERE { ?s ?p ?o } LIMIT 3\",\n",
    "    ns=test_ns,\n",
    "    name='graph_test'\n",
    ")\n",
    "print(result)\n",
    "assert test_ns['graph_test'].result_type == 'construct'\n",
    "assert isinstance(test_ns['graph_test'].rows, Graph)\n",
    "print(f\"✓ CONSTRUCT query works: {test_ns['graph_test'].summary()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Local Graph Query\n",
    "\n",
    "Execute SPARQL queries against local rdflib graphs (mounted ontologies or work graphs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def sparql_local(\n",
    "    query: str,\n",
    "    graph: Graph | str,\n",
    "    max_results: int = 100,\n",
    "    name: str = 'res',\n",
    "    ns: dict = None\n",
    ") -> str:\n",
    "    \"\"\"Execute SPARQL query on local rdflib Graph.\n",
    "\n",
    "    Useful for querying mounted ontologies or work graphs.\n",
    "    Returns SPARQLResultHandle same as sparql_query().\n",
    "    \n",
    "    Args:\n",
    "        query: SPARQL query string\n",
    "        graph: rdflib.Graph object or name of graph in namespace\n",
    "        max_results: Maximum results to return\n",
    "        name: Variable name to store result handle\n",
    "        ns: Namespace dict (defaults to globals())\n",
    "        \n",
    "    Returns:\n",
    "        Summary string describing the result\n",
    "    \"\"\"\n",
    "    if ns is None:\n",
    "        ns = globals()\n",
    "    \n",
    "    # Resolve graph if string name provided\n",
    "    if isinstance(graph, str):\n",
    "        if graph not in ns:\n",
    "            return f\"Error: Graph '{graph}' not found in namespace\"\n",
    "        graph_obj = ns[graph]\n",
    "        # Handle GraphMeta wrapper\n",
    "        if hasattr(graph_obj, 'graph'):\n",
    "            graph_obj = graph_obj.graph\n",
    "    else:\n",
    "        graph_obj = graph\n",
    "    \n",
    "    if not isinstance(graph_obj, Graph):\n",
    "        return f\"Error: Expected rdflib.Graph, got {type(graph_obj)}\"\n",
    "    \n",
    "    # Execute query on local graph\n",
    "    result = graph_obj.query(query)\n",
    "    \n",
    "    # Determine result type\n",
    "    query_upper = query.upper()\n",
    "    \n",
    "    if 'ASK' in query_upper:\n",
    "        # ASK query\n",
    "        ask_result = bool(result)\n",
    "        handle = SPARQLResultHandle(\n",
    "            rows=ask_result,\n",
    "            result_type='ask',\n",
    "            query=query,\n",
    "            endpoint='local'\n",
    "        )\n",
    "        ns[name] = handle\n",
    "        return f\"ASK result: {ask_result}, stored in '{name}'\"\n",
    "    \n",
    "    elif 'CONSTRUCT' in query_upper or 'DESCRIBE' in query_upper:\n",
    "        # CONSTRUCT or DESCRIBE query\n",
    "        result_type = 'construct' if 'CONSTRUCT' in query_upper else 'describe'\n",
    "        g = Graph()\n",
    "        for triple in list(result)[:max_results]:\n",
    "            g.add(triple)\n",
    "        \n",
    "        handle = SPARQLResultHandle(\n",
    "            rows=g,\n",
    "            result_type=result_type,\n",
    "            query=query,\n",
    "            endpoint='local',\n",
    "            triple_count=len(g)\n",
    "        )\n",
    "        ns[name] = handle\n",
    "        return f\"Graph with {len(g)} triples stored in '{name}'\"\n",
    "    \n",
    "    else:\n",
    "        # SELECT query\n",
    "        rows = []\n",
    "        for row in list(result)[:max_results]:\n",
    "            row_dict = {}\n",
    "            for var in result.vars:\n",
    "                row_dict[str(var)] = row[var] if row[var] else None\n",
    "            rows.append(row_dict)\n",
    "        \n",
    "        cols = [str(v) for v in result.vars] if result.vars else []\n",
    "        \n",
    "        handle = SPARQLResultHandle(\n",
    "            rows=rows,\n",
    "            result_type='select',\n",
    "            query=query,\n",
    "            endpoint='local',\n",
    "            columns=cols,\n",
    "            total_rows=len(rows)\n",
    "        )\n",
    "        ns[name] = handle\n",
    "        \n",
    "        return f\"SELECT result with {len(rows)} rows, columns: {cols}, stored in '{name}'\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "Test with local graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test graph\n",
    "test_graph = Graph()\n",
    "test_graph.add((URIRef('http://ex.org/alice'), URIRef('http://ex.org/age'), Literal('30')))\n",
    "test_graph.add((URIRef('http://ex.org/bob'), URIRef('http://ex.org/age'), Literal('25')))\n",
    "test_graph.add((URIRef('http://ex.org/alice'), URIRef('http://ex.org/city'), Literal('Boston')))\n",
    "\n",
    "test_ns = {'my_graph': test_graph}\n",
    "\n",
    "# Test SELECT query on local graph\n",
    "result = sparql_local(\n",
    "    \"SELECT ?s ?age WHERE { ?s <http://ex.org/age> ?age }\",\n",
    "    'my_graph',\n",
    "    ns=test_ns,\n",
    "    name='local_res'\n",
    ")\n",
    "print(result)\n",
    "assert 'local_res' in test_ns\n",
    "assert test_ns['local_res'].result_type == 'select'\n",
    "assert len(test_ns['local_res'].rows) == 2\n",
    "print(f\"✓ Local SELECT query works: {test_ns['local_res'].rows}\")\n",
    "\n",
    "# Test CONSTRUCT on local graph\n",
    "result = sparql_local(\n",
    "    \"CONSTRUCT { ?s <http://ex.org/age> ?age } WHERE { ?s <http://ex.org/age> ?age }\",\n",
    "    test_graph,\n",
    "    ns=test_ns,\n",
    "    name='local_graph'\n",
    ")\n",
    "print(result)\n",
    "assert test_ns['local_graph'].result_type == 'construct'\n",
    "assert len(test_ns['local_graph'].rows) == 2\n",
    "print(f\"✓ Local CONSTRUCT query works\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## View Operations\n",
    "\n",
    "Bounded view functions for progressive disclosure over result sets.\n",
    "\n",
    "These functions work with `SPARQLResultHandle`, `ResultTable`, or plain lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def res_sample(result, n: int = 10, seed: int = None) -> list:\n",
    "    \"\"\"Get random sample of N rows from result.\n",
    "\n",
    "    Args:\n",
    "        result: SPARQLResultHandle, ResultTable, or list\n",
    "        n: Number of rows to sample\n",
    "        seed: Optional random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "        List of sampled rows\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "\n",
    "    # Extract rows from different result types\n",
    "    if isinstance(result, SPARQLResultHandle):\n",
    "        if result.result_type in ['construct', 'describe']:\n",
    "            # For graphs, sample triples\n",
    "            rows = list(result.rows)\n",
    "        elif result.result_type == 'ask':\n",
    "            # ASK has no rows to sample\n",
    "            return [result.rows]\n",
    "        else:\n",
    "            rows = result.rows\n",
    "    elif hasattr(result, 'rows'):\n",
    "        # ResultTable or similar\n",
    "        rows = result.rows\n",
    "    else:\n",
    "        # Plain list\n",
    "        rows = result\n",
    "\n",
    "    if len(rows) <= n:\n",
    "        return list(rows)\n",
    "    return random.sample(list(rows), n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "Test res_sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with list\n",
    "test_list = [{'x': i} for i in range(20)]\n",
    "sample = res_sample(test_list, n=5, seed=42)\n",
    "assert len(sample) == 5\n",
    "assert all(isinstance(item, dict) for item in sample)\n",
    "print(f\"✓ res_sample works with list: {len(sample)} items\")\n",
    "\n",
    "# Test with SPARQLResultHandle\n",
    "handle = SPARQLResultHandle(\n",
    "    rows=[{'s': f'http://ex.org/item{i}'} for i in range(15)],\n",
    "    result_type='select',\n",
    "    query='SELECT ?s WHERE { ?s ?p ?o }',\n",
    "    endpoint='local',\n",
    "    columns=['s'],\n",
    "    total_rows=15\n",
    ")\n",
    "sample = res_sample(handle, n=3, seed=42)\n",
    "assert len(sample) == 3\n",
    "print(f\"✓ res_sample works with SPARQLResultHandle\")\n",
    "\n",
    "# Test with small result (no sampling needed)\n",
    "small_list = [1, 2, 3]\n",
    "sample = res_sample(small_list, n=10)\n",
    "assert len(sample) == 3\n",
    "print(f\"✓ res_sample handles small results correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Setup Function\n",
    "\n",
    "Initialize SPARQL tools in namespace for RLM sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def setup_sparql_context(\n",
    "    ns: dict,\n",
    "    default_endpoint: str = \"https://query.wikidata.org/sparql\",\n",
    "    ds_meta = None\n",
    ") -> str:\n",
    "    \"\"\"Initialize SPARQL tools in namespace.\n",
    "\n",
    "    Binds:\n",
    "    - sparql_query() with default endpoint\n",
    "    - sparql_local() if ds_meta provided\n",
    "    - res_head(), res_where(), res_group(), res_distinct(), res_sample()\n",
    "\n",
    "    Args:\n",
    "        ns: Namespace dict where functions will be bound\n",
    "        default_endpoint: Default SPARQL endpoint URL\n",
    "        ds_meta: Optional DatasetMeta for dataset integration\n",
    "        \n",
    "    Returns:\n",
    "        Status message\n",
    "    \"\"\"\n",
    "    # Import view functions from dataset module\n",
    "    try:\n",
    "        from rlm.dataset import res_head, res_where, res_group, res_distinct\n",
    "    except ImportError:\n",
    "        # Fallback if dataset module not available\n",
    "        res_head = res_where = res_group = res_distinct = None\n",
    "    \n",
    "    # Bind sparql_query with default endpoint and dataset integration\n",
    "    if ds_meta is not None:\n",
    "        ns['sparql_query'] = partial(sparql_query, endpoint=default_endpoint, ns=ns, ds_meta=ds_meta)\n",
    "    else:\n",
    "        ns['sparql_query'] = partial(sparql_query, endpoint=default_endpoint, ns=ns)\n",
    "    \n",
    "    # Bind sparql_local\n",
    "    ns['sparql_local'] = partial(sparql_local, ns=ns)\n",
    "    \n",
    "    # Bind view operations\n",
    "    if res_head is not None:\n",
    "        ns['res_head'] = res_head\n",
    "        ns['res_where'] = res_where\n",
    "        ns['res_group'] = res_group\n",
    "        ns['res_distinct'] = res_distinct\n",
    "    ns['res_sample'] = res_sample\n",
    "    \n",
    "    bound_funcs = ['sparql_query', 'sparql_local', 'res_sample']\n",
    "    if res_head is not None:\n",
    "        bound_funcs.extend(['res_head', 'res_where', 'res_group', 'res_distinct'])\n",
    "    \n",
    "    msg = f\"SPARQL context initialized with endpoint: {default_endpoint}\"\n",
    "    if ds_meta is not None:\n",
    "        msg += f\"\\nDataset integration enabled (session: {ds_meta.session_id})\"\n",
    "    msg += f\"\\nBound functions: {', '.join(bound_funcs)}\"\n",
    "    \n",
    "    return msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "Test setup function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test basic setup\n",
    "test_ns = {}\n",
    "result = setup_sparql_context(test_ns)\n",
    "print(result)\n",
    "assert 'sparql_query' in test_ns\n",
    "assert 'sparql_local' in test_ns\n",
    "assert 'res_sample' in test_ns\n",
    "print(f\"✓ Setup function works\")\n",
    "\n",
    "# Test with dataset integration\n",
    "try:\n",
    "    from rlm.dataset import DatasetMeta\n",
    "    from rdflib import Dataset\n",
    "    \n",
    "    ds = Dataset()\n",
    "    ds_meta = DatasetMeta(ds, name='test')\n",
    "    \n",
    "    test_ns2 = {}\n",
    "    result = setup_sparql_context(test_ns2, ds_meta=ds_meta)\n",
    "    print(result)\n",
    "    assert 'session:' in result\n",
    "    print(f\"✓ Setup with dataset integration works\")\n",
    "except ImportError:\n",
    "    print(\"⊘ Dataset module not available, skipping integration test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## Usage Examples\n",
    "\n",
    "End-to-end examples showing SPARQL handles in RLM context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# Example 1: Basic SPARQL workflow\n",
    "ns = {}\n",
    "setup_sparql_context(ns)\n",
    "\n",
    "# Execute query (LLM would do this)\n",
    "ns['sparql_query']('SELECT ?s ?p ?o WHERE { ?s ?p ?o } LIMIT 10', name='results')\n",
    "\n",
    "# Inspect results\n",
    "print(ns['results'].summary())\n",
    "print(res_head(ns['results'], 5))\n",
    "print(res_sample(ns['results'], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# Example 2: Dataset integration\n",
    "from rlm.dataset import setup_dataset_context\n",
    "\n",
    "ns = {}\n",
    "setup_dataset_context(ns)\n",
    "setup_sparql_context(ns, ds_meta=ns['ds_meta'])\n",
    "\n",
    "# Query and store in work graph\n",
    "ns['sparql_query'](\n",
    "    'CONSTRUCT { ?s ?p ?o } WHERE { ?s ?p ?o } LIMIT 5',\n",
    "    name='discovered_triples',\n",
    "    store_in_work=True,\n",
    "    work_task_id='discovery_1'\n",
    ")\n",
    "\n",
    "# Check provenance\n",
    "print(ns['dataset_stats']())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# Example 3: Local graph queries\n",
    "from rlm.ontology import setup_ontology_context\n",
    "\n",
    "ns = {}\n",
    "setup_sparql_context(ns)\n",
    "setup_ontology_context('ontology/prov.ttl', ns, name='prov')\n",
    "\n",
    "# Query mounted ontology\n",
    "ns['sparql_local'](\n",
    "    'SELECT ?c WHERE { ?c a <http://www.w3.org/2002/07/owl#Class> }',\n",
    "    'prov',\n",
    "    name='classes'\n",
    ")\n",
    "\n",
    "print(f\"Found {len(ns['classes'].rows)} classes\")\n",
    "print(res_head(ns['classes'], 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
