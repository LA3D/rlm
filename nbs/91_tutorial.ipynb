{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c9cf176",
   "metadata": {},
   "source": [
    "# RLM Tutorial: Progressive Disclosure Over RDF Graphs\n",
    "\n",
    "This notebook demonstrates the RLM (Recursive Language Model) architecture\n",
    "with working examples.\n",
    "\n",
    "**Note:** Sections 1, 3, and 8 require network access and `ANTHROPIC_API_KEY` set in\n",
    "your environment (used by `claudette`). Without these, only the non-LLM sections\n",
    "(ontology loading, dataset memory, SPARQL handles, procedural memory, SHACL indexing)\n",
    "will execute successfully.\n",
    "\n",
    "Example:\n",
    "\n",
    "```bash\n",
    "export ANTHROPIC_API_KEY=\"...\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12b830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared namespace for the entire notebook - demonstrating REPL persistence\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "ns = {}  # This single namespace persists throughout the tutorial\n",
    "\n",
    "def require_anthropic_api_key():\n",
    "    \"\"\"Fail fast if the Claude API key is not configured.\"\"\"\n",
    "    if not os.getenv('ANTHROPIC_API_KEY'):\n",
    "        raise RuntimeError(\n",
    "            \"Missing ANTHROPIC_API_KEY. Set it in your environment to run llm_query()/rlm_run() cells.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecb9221",
   "metadata": {},
   "source": [
    "## 1. Core RLM Loop\n",
    "\n",
    "The `llm_query()` function delegates a question to Claude and stores the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3793e79d",
   "metadata": {},
   "outputs": [],
   "source": "#| eval: false\nfrom rlm.core import llm_query\n\nrequire_anthropic_api_key()\n\n# Use shared ns - result will persist\nresult = llm_query(\"What is 2+2? Answer with just the number.\", ns, name='math')\nprint(f\"Result: {result}\")\nprint(f\"Stored as: ns['math'] = {ns.get('math', 'not found')}\")"
  },
  {
   "cell_type": "markdown",
   "id": "a9ea1ddd",
   "metadata": {},
   "source": [
    "The `rlm_run()` function runs the full RLM loop: the model emits code,\n",
    "executes it in a REPL, and iterates until it finds an answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a6323c",
   "metadata": {},
   "outputs": [],
   "source": "#| eval: false\nfrom rlm.core import rlm_run\n\nrequire_anthropic_api_key()\n\n# Continue using shared ns\nanswer, iterations, ns = rlm_run(\n    \"Calculate the sum of squares of 1, 2, and 3.\",\n    \"You can use Python to calculate.\",\n    ns=ns,\n    max_iters=3\n)\nprint(f\"Answer: {answer}\")\nprint(f\"Iterations: {len(iterations)}\")\nprint(f\"ns still has 'math': {ns.get('math', 'not found')}\")"
  },
  {
   "cell_type": "markdown",
   "id": "c5e29c9a",
   "metadata": {},
   "source": [
    "## 2. Ontology Loading\n",
    "\n",
    "Load RDF ontologies and explore them with bounded view functions.\n",
    "The key insight: we never dump the full graph into context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb8ad7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph 'prov': 1,664 triples\n",
      "Classes: 59\n",
      "Properties: 89\n",
      "Individuals: 1\n",
      "Namespaces: brick, csvw, dc, dcat, dcmitype, dcterms, dcam, doap, foaf, geo, odrl, org, prof, qb, schema, sh, skos, sosa, ssn, time, vann, void, wgs, owl, rdf, rdfs, xsd, xml, prov\n",
      "\n",
      "ns now contains: ['math', 'context', 'llm_query', 'llm_query_batched', 'FINAL_VAR', 'llm_res', 'analysis', 'sum_of_squares', 'prov', 'prov_meta', 'prov_graph_stats', 'prov_search_by_label', 'prov_describe_entity', 'prov_search_entity', 'prov_probe_relationships', 'prov_find_path', 'prov_predicate_frequency', 'graph_stats', 'search_by_label', 'describe_entity', 'search_entity', 'probe_relationships', 'find_path', 'predicate_frequency']\n"
     ]
    }
   ],
   "source": [
    "from rlm.ontology import setup_ontology_context\n",
    "\n",
    "# Add PROV ontology to shared ns\n",
    "setup_ontology_context('ontology/prov.ttl', ns, name='prov')\n",
    "print(ns['prov_meta'].summary())\n",
    "print(f\"\\nns now contains: {[k for k in ns.keys() if not k.startswith('_')]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f41df3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity: http://www.w3.org/ns/prov#Activity\n",
      "ActivityInfluence: http://www.w3.org/ns/prov#ActivityInfluence\n",
      "activity: http://www.w3.org/ns/prov#activity\n",
      "hadActivity: http://www.w3.org/ns/prov#hadActivity\n",
      "activityOfInfluence: http://www.w3.org/ns/prov#activityOfInfluence\n"
     ]
    }
   ],
   "source": [
    "# Search for classes related to \"Activity\"\n",
    "results = ns['prov_search_by_label']('Activity', limit=5)\n",
    "for uri, label in results:\n",
    "    print(f\"{label}: {uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69bb750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Activity\n",
      "Types: ['http://www.w3.org/2002/07/owl#Class']\n",
      "Comment: None...\n",
      "Outgoing triples (sample): 10\n"
     ]
    }
   ],
   "source": [
    "# Get bounded description of Activity class\n",
    "desc = ns['prov_describe_entity']('http://www.w3.org/ns/prov#Activity', limit=10)\n",
    "print(f\"Label: {desc['label']}\")\n",
    "print(f\"Types: {desc['types']}\")\n",
    "print(f\"Comment: {desc['comment'][:100] if desc['comment'] else 'None'}...\")\n",
    "print(f\"Outgoing triples (sample): {len(desc['outgoing_sample'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40613dbf",
   "metadata": {},
   "source": [
    "## 3. RLM with Ontology Exploration\n",
    "\n",
    "Combine the RLM loop with ontology tools for intelligent exploration.\n",
    "The model uses bounded views to progressively discover information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae3190c",
   "metadata": {},
   "outputs": [],
   "source": "#| eval: false\nfrom rlm.core import rlm_run\nfrom rlm.ontology import setup_ontology_context\n\nrequire_anthropic_api_key()\n\n# PROV is already loaded in ns from previous section\nquery = \"What is prov:Activity? Use search_by_label and describe_entity.\"\ncontext = ns['prov_meta'].summary()\n\nanswer, iterations, ns = rlm_run(\n    query,\n    context,\n    ns=ns,\n    max_iters=3,\n    verbose=False\n)\n\nprint(f\"Answer: {answer[:500] if answer else 'No answer'}...\")\nprint(f\"Iterations: {len(iterations)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b656e982",
   "metadata": {},
   "outputs": [],
   "source": "#| eval: false\n# Show what code the LLM executed (depends on previous API cell)\nfor i, it in enumerate(iterations):\n    if it.code_blocks:\n        print(f\"Iteration {i}:\")\n        for cb in it.code_blocks:\n            print(f\"  Code: {cb.code[:100]}...\")"
  },
  {
   "cell_type": "markdown",
   "id": "f642155e",
   "metadata": {},
   "source": [
    "## 4. Dataset Memory\n",
    "\n",
    "Store discovered facts in an RDF Dataset with provenance tracking.\n",
    "Facts persist within the same namespace/session. Use `snapshot_dataset()` and\n",
    "`load_snapshot()` APIs for persistence across sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1531060b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'ds' (session: f7322b86)\n",
      "mem: 0 triples\n",
      "prov: 0 events\n",
      "work graphs: 0\n",
      "onto graphs: 0\n",
      "\n",
      "PROV ontology still accessible: 'prov_meta' in ns = True\n"
     ]
    }
   ],
   "source": [
    "from rlm.dataset import setup_dataset_context\n",
    "\n",
    "# Add dataset to shared ns (alongside previously loaded ontology)\n",
    "setup_dataset_context(ns)\n",
    "print(ns['dataset_stats']())\n",
    "print(f\"\\nPROV ontology still accessible: 'prov_meta' in ns = {'prov_meta' in ns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c49e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'ds' (session: f7322b86)\n",
      "mem: 1 triples\n",
      "prov: 7 events\n",
      "work graphs: 0\n",
      "onto graphs: 0\n"
     ]
    }
   ],
   "source": [
    "# Add a fact we discovered\n",
    "ns['mem_add'](\n",
    "    'http://example.org/myAnalysis',\n",
    "    'http://www.w3.org/ns/prov#wasGeneratedBy',\n",
    "    'http://example.org/rlmSession1'\n",
    ")\n",
    "\n",
    "# Check stats\n",
    "print(ns['dataset_stats']())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c276a347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'s': 'http://example.org/myAnalysis', 'p': 'http://www.w3.org/ns/prov#wasGeneratedBy', 'o': 'http://example.org/rlmSession1'}\n"
     ]
    }
   ],
   "source": [
    "# Query the memory graph\n",
    "results = ns['mem_query'](\"\"\"\n",
    "    SELECT ?s ?p ?o WHERE { ?s ?p ?o }\n",
    "\"\"\")\n",
    "for r in results:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0aefca",
   "metadata": {},
   "source": [
    "## 5. SPARQL Result Handles\n",
    "\n",
    "Query results return handles with metadata, not raw data dumps.\n",
    "Handles support bounded sampling (e.g., `rows[:n]`) and summary statistics.\n",
    "\n",
    "**Note:** Results are still fetched into memory; handles provide metadata-first\n",
    "access patterns rather than true server-side pagination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7171bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT: 100 rows, columns=['name', 'value']\n",
      "First 3 rows: [{'name': 'Item0', 'value': 0}, {'name': 'Item1', 'value': 1}, {'name': 'Item2', 'value': 2}]\n"
     ]
    }
   ],
   "source": [
    "from rlm.sparql_handles import SPARQLResultHandle\n",
    "\n",
    "# Simulating a large result set\n",
    "handle = SPARQLResultHandle(\n",
    "    rows=[{'name': f'Item{i}', 'value': i} for i in range(100)],\n",
    "    result_type='select',\n",
    "    query='SELECT ?name ?value WHERE { ... }',\n",
    "    endpoint='local',\n",
    "    columns=['name', 'value'],\n",
    "    total_rows=100\n",
    ")\n",
    "\n",
    "print(handle.summary())\n",
    "print(f\"First 3 rows: {handle.rows[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3802a2",
   "metadata": {},
   "source": [
    "## 6. Procedural Memory\n",
    "\n",
    "Store and retrieve methods learned from past trajectories.\n",
    "Uses BM25 for similarity-based retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c11059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store has 1 memories\n"
     ]
    }
   ],
   "source": [
    "from rlm.procedural_memory import MemoryStore, MemoryItem, retrieve_memories\n",
    "from datetime import datetime, timezone\n",
    "import uuid\n",
    "\n",
    "store = MemoryStore()\n",
    "\n",
    "# Add a learned procedure\n",
    "item = MemoryItem(\n",
    "    id=str(uuid.uuid4()),\n",
    "    title='Find Activity classes in PROV',\n",
    "    description='How to discover Activity-related classes',\n",
    "    content='1. Use search_by_label(\"Activity\")\\n2. Use describe_entity() on results',\n",
    "    source_type='success',\n",
    "    task_query='find activities in PROV',\n",
    "    created_at=datetime.now(timezone.utc).isoformat(),\n",
    "    tags=['prov', 'ontology', 'exploration']\n",
    ")\n",
    "store.add(item)\n",
    "\n",
    "print(f\"Store has {len(store.memories)} memories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ae0b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Find Activity classes in PROV\n",
      "Content:\n",
      "1. Use search_by_label(\"Activity\")\n",
      "2. Use describe_entity() on results\n"
     ]
    }
   ],
   "source": [
    "# Retrieve relevant memories for a new task\n",
    "retrieved = retrieve_memories(store, 'how to explore PROV ontology activities', k=1)\n",
    "for mem in retrieved:\n",
    "    print(f\"Title: {mem.title}\")\n",
    "    print(f\"Content:\\n{mem.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a4774c",
   "metadata": {},
   "source": [
    "## 7. SHACL Shape Indexing\n",
    "\n",
    "Detect and index SHACL shapes for schema discovery and constraint inspection.\n",
    "\n",
    "**Note:** This provides shape detection and constraint inspection (targets, properties,\n",
    "cardinalities), not runtime validation. Use a SHACL validator for actual data validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd24bcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node shapes: 42\n",
      "Property shapes: 0\n"
     ]
    }
   ],
   "source": [
    "from rlm.shacl_examples import detect_shacl, build_shacl_index, search_shapes\n",
    "from rdflib import Graph\n",
    "\n",
    "# Load DCAT-AP shapes\n",
    "g = Graph()\n",
    "g.parse('ontology/dcat-ap/dcat-ap-SHACL.ttl')\n",
    "\n",
    "# Detect SHACL content\n",
    "detection = detect_shacl(g)\n",
    "print(f\"Node shapes: {detection['node_shapes']}\")\n",
    "print(f\"Property shapes: {detection['property_shapes']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634870ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dcat:CatalogShape: targets ['http://www.w3.org/ns/dcat#Catalog']\n",
      "dcat:DatasetShape: targets ['http://www.w3.org/ns/dcat#Dataset']\n",
      "dcat:DataServiceShape: targets ['http://www.w3.org/ns/dcat#DataService']\n"
     ]
    }
   ],
   "source": [
    "# Build index and search\n",
    "index = build_shacl_index(g)\n",
    "results = search_shapes(index, 'dataset', limit=3)\n",
    "\n",
    "for r in results:\n",
    "    print(f\"{r['uri'].split('#')[-1]}: targets {r['targets']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a074ae38",
   "metadata": {},
   "source": [
    "## 8. Full Integration: Multi-Ontology Comparison\n",
    "\n",
    "Putting it all together: load multiple ontologies, build sense documents,\n",
    "and use RLM to answer complex questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8431d10",
   "metadata": {},
   "outputs": [],
   "source": "#| eval: false\nfrom rlm.ontology import build_sense\n\nrequire_anthropic_api_key()\n\n# Build PROV sense document in shared ns\nbuild_sense('ontology/prov.ttl', name='prov_sense', ns=ns)\nprint(\"PROV sense document built\")\nprint(f\"Summary length: {len(ns['prov_sense'].summary)} chars\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bb9932",
   "metadata": {},
   "outputs": [],
   "source": "#| eval: false\nfrom rlm.core import rlm_run\n\nrequire_anthropic_api_key()\n\n# Build sense for SIO in shared ns\nbuild_sense('ontology/sio/sio-release.owl', name='sio_sense', ns=ns)\n\n# Context as dict - model can inspect context['prov'] / context['sio'] directly\ncontext = {\n    'prov': ns['prov_sense'].summary[:2000],  # Truncate for demo\n    'sio': ns['sio_sense'].summary[:2000]\n}\n\nquery = \"What are the key differences between PROV and SIO ontologies?\"\n\n# Pass dict context directly (not str(context)) for progressive disclosure\nanswer, iterations, ns = rlm_run(\n    query,\n    context,  # Keep dict structure for model inspection\n    ns=ns,\n    max_iters=3,\n    verbose=False\n)\n\nprint(f\"Answer:\\n{answer[:800] if answer else 'No answer'}...\")\nprint(f\"\\nIterations: {len(iterations)}\")"
  },
  {
   "cell_type": "markdown",
   "id": "c2680b38",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial demonstrated:\n",
    "\n",
    "1. **Core RLM loop**: `llm_query()` and `rlm_run()` for LLM-driven exploration\n",
    "2. **Ontology loading**: Bounded views prevent context overflow\n",
    "3. **Progressive disclosure**: Start small, explore as needed\n",
    "4. **Dataset memory**: Persist discovered facts with provenance (within a session/namespace)\n",
    "5. **SPARQL handles**: Metadata-first result handling with bounded sampling\n",
    "6. **Procedural memory**: Learn and reuse exploration strategies\n",
    "7. **SHACL indexing**: Schema discovery and constraint inspection through shape search\n",
    "\n",
    "**Environment requirements:** Sections using `llm_query()` or `rlm_run()` require\n",
    "network access and `ANTHROPIC_API_KEY` set in your environment. Non-LLM sections work\n",
    "offline."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}