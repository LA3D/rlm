{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ddf7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from rlm.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e393652",
   "metadata": {},
   "source": [
    "# RLM\n",
    "\n",
    "> Recursive Language Models for ontology-based query construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac6b7db",
   "metadata": {},
   "source": [
    "This project implements the Recursive Language Model (RLM) architecture for querying RDF ontologies through progressive disclosure. The implementation follows the protocol from [Zhang et al. (2025)](https://github.com/alexzhang13/rlm) while using [claudette](https://claudette.answer.ai/) as the LLM backend.\n",
    "\n",
    "The work is part of an ongoing investigation into how LLM agents can navigate large knowledge graphs without overwhelming their context windows. Rather than loading entire ontologies into the prompt, the agent iteratively explores through bounded REPL operations, delegating heavy summarization tasks to sub-LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e593094",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "The RLM architecture addresses a fundamental tension in using LLMs for knowledge graph tasks: ontologies and query results are often too large to fit in context, yet the model needs semantic understanding to construct correct queries.\n",
    "\n",
    "The solution externalizes the large context to a REPL environment. The root LLM emits small code blocks that execute against the graph, receiving truncated results. When more detail is needed, it delegates to sub-LLMs via `llm_query()` calls that summarize specific chunks. The process iterates until the model returns a final answer.\n",
    "\n",
    "This implementation extends RLM with two complementary memory systems:\n",
    "\n",
    "**Dataset memory** (RDF quads) stores domain facts discovered during exploration. An RDF Dataset provides named graphs for working memory (`mem`), provenance tracking (`prov`), and scratch space (`work/*`). Facts persist across queries and can be snapshotted for session continuity.\n",
    "\n",
    "**Procedural memory** ([ReasoningBank](https://arxiv.org/html/2509.25140v1)-style) stores reusable methods extracted from past trajectories. After each RLM run, a judge evaluates success or failure, and an extractor distills procedural insights: query templates, debugging strategies, exploration heuristics. These are retrieved via BM25 for similar future tasks, allowing the agent to improve over time without relearning from scratch.\n",
    "\n",
    "Additional components include SPARQL result handles that expose metadata without materializing full result sets, SHACL shape indexing for schema discovery, and query template retrieval from `sh:SPARQLExecutable` examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfca2326",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "This project uses [uv](https://github.com/astral-sh/uv) for package management with a shared environment:\n",
    "\n",
    "```bash\n",
    "source ~/uvws/.venv/bin/activate\n",
    "uv pip install fastcore claudette rdflib rank-bm25\n",
    "uv pip install -e .\n",
    "```\n",
    "\n",
    "For development, you also need nbdev:\n",
    "\n",
    "```bash\n",
    "uv pip install nbdev\n",
    "nbdev_install_hooks\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55bb374",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "The following demonstrates loading an ontology into the dataset memory and using bounded view functions to explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff93197c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'ds' (session: ae4334a3)\n",
      "mem: 0 triples\n",
      "prov: 0 events\n",
      "work graphs: 0\n",
      "onto graphs: 0\n"
     ]
    }
   ],
   "source": [
    "from rlm.dataset import setup_dataset_context\n",
    "\n",
    "# Initialize dataset with mem/prov graphs\n",
    "ns = {}\n",
    "setup_dataset_context(ns)\n",
    "print(ns['dataset_stats']())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e264c2",
   "metadata": {},
   "outputs": [],
   "source": "#| eval: false\n# Mount an ontology (SHACL shapes are auto-indexed)\nns['mount_ontology']('ontology/dcat-ap/dcat-ap-SHACL.ttl', 'dcat')\n\n# The SHACL index is now available\nprint(ns['dcat_shacl'].summary())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e821b3",
   "metadata": {},
   "outputs": [],
   "source": "#| eval: false\nfrom rlm.shacl_examples import search_shapes, describe_shape\n\n# Search for shapes related to datasets\nresults = search_shapes(ns['dcat_shacl'], 'dataset', limit=3)\nfor r in results:\n    print(f\"{r['uri'].split('#')[-1]}: targets {r['targets']}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0db89b",
   "metadata": {},
   "outputs": [],
   "source": "#| eval: false\n# Get bounded description of a shape (first 10 properties)\ndesc = describe_shape(ns['dcat_shacl'], results[0]['uri'], limit=10)\nprint(f\"Properties: {desc['property_count']} (showing {len(desc['properties'])})\")\nfor p in desc['properties'][:5]:\n    print(f\"  {p['path'].split('/')[-1]}: min={p.get('minCount')}\")"
  },
  {
   "cell_type": "markdown",
   "id": "d1298fb5",
   "metadata": {},
   "source": [
    "Query templates can be loaded from SHACL-AF examples and searched by keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40345e1",
   "metadata": {},
   "outputs": [],
   "source": "#| eval: false\nfrom rlm.shacl_examples import load_query_examples, search_queries, get_query_text\n\n# Load neXtProt SPARQL examples\nload_query_examples('ontology/uniprot/examples/neXtProt', ns, 'nxq')\nprint(ns['nxq'].summary())\n\n# Find queries about phosphorylation\nqueries = search_queries(ns['nxq'], 'phosphorylation', limit=2)\nfor q in queries:\n    print(f\"{q['uri'].split('/')[-1]}: {q['comment'][:60]}...\")"
  },
  {
   "cell_type": "markdown",
   "id": "bffc5d9d",
   "metadata": {},
   "source": [
    "## Project Structure\n",
    "\n",
    "The implementation follows nbdev conventions. Source notebooks are in `nbs/`, with modules exported to `rlm/`.\n",
    "\n",
    "```\n",
    "nbs/\n",
    "├── 00_core.ipynb           # RLM loop, llm_query, FINAL_VAR\n",
    "├── 01_ontology.ipynb       # Ontology loading and namespace binding\n",
    "├── 02_dataset_memory.ipynb # RDF Dataset with mem/prov/work graphs\n",
    "├── 03_sparql_handles.ipynb # SPARQL result handles and bounded views\n",
    "├── 05_procedural_memory.ipynb # ReasoningBank-style procedural memory\n",
    "└── 06_shacl_examples.ipynb # SHACL indexing and query templates\n",
    "```\n",
    "\n",
    "Design documents and the project trajectory are in `docs/`. See [docs/planning/trajectory.md](docs/planning/trajectory.md) for the implementation roadmap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ea2760",
   "metadata": {},
   "source": [
    "## Status\n",
    "\n",
    "This is preliminary research code under active development. The current implementation covers stages 1-4 of the trajectory:\n",
    "\n",
    "- Stage 1: Core RLM loop with claudette backend\n",
    "- Stage 2: Bounded view primitives for progressive disclosure\n",
    "- Stage 3: SPARQL handles with work-bound query execution\n",
    "- Stage 4: SHACL shape indexing and query template retrieval\n",
    "\n",
    "Stages 5-6 (full ontology trajectories and evaluation framework) are planned but not yet implemented.\n",
    "\n",
    "The code is developed through exploratory programming in Jupyter notebooks using nbdev. It targets integration with the [Solveit](https://solveit.ai) platform but can run standalone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118cac6e",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Zhang, A., et al. (2025). [Recursive Language Models](https://github.com/alexzhang13/rlm). The reference implementation this project follows.\n",
    "- Wang, B., et al. (2025). [ReasoningBank: Self-Evolving Procedural Knowledge for Adaptive Reasoning](https://arxiv.org/html/2509.25140v1). Procedural memory approach for learning from trajectories.\n",
    "- Anthropic. (2025). [Building Effective Agents](https://www.anthropic.com/research/building-effective-agents). Context engineering patterns for agentic systems.\n",
    "- Howard, J. & Gugger, S. [nbdev](https://nbdev.fast.ai/). Literate programming framework.\n",
    "- Howard, J. [claudette](https://claudette.answer.ai/). Claude API wrapper used as the LLM backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad20328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
