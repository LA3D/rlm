{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ddf7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from rlm.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e393652",
   "metadata": {},
   "source": [
    "# RLM\n",
    "\n",
    "> Recursive Language Models for ontology-based query construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac6b7db",
   "metadata": {},
   "source": [
    "This project implements the Recursive Language Model (RLM) architecture for querying RDF ontologies through progressive disclosure. The implementation follows the protocol from [Zhang et al. (2025)](https://github.com/alexzhang13/rlm) while using [claudette](https://claudette.answer.ai/) as the LLM backend.\n",
    "\n",
    "The work is part of an ongoing investigation into how LLM agents can navigate large knowledge graphs without overwhelming their context windows. Rather than loading entire ontologies into the prompt, the agent iteratively explores through bounded REPL operations, delegating heavy summarization tasks to sub-LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e593094",
   "metadata": {},
   "source": "## Background\n\nThe RLM architecture addresses a fundamental tension in using LLMs for knowledge graph tasks: ontologies and query results are often too large to fit in context, yet the model needs semantic understanding to construct correct queries.\n\nThe solution externalizes the large context to a REPL environment. The root LLM emits small code blocks that execute against the graph, receiving truncated results. When more detail is needed, it delegates to sub-LLMs via `llm_query()` calls that summarize specific chunks. The process iterates until the model returns a final answer.\n\nThis implementation extends RLM with two complementary memory systems and a four-layer context injection strategy:\n\n**Dataset memory** (RDF quads) stores domain facts discovered during exploration. An RDF Dataset provides named graphs for working memory (`mem`), provenance tracking (`prov`), and scratch space (`work/*`). Facts persist across queries and can be snapshotted for session continuity.\n\n**Procedural memory** ([ReasoningBank](https://arxiv.org/html/2509.25140v1)-style) stores reusable exploration strategies extracted from past trajectories. The system bootstraps with 7 universal strategies (describe entity, navigate hierarchy, find properties) stored as `MemoryItem` objects. After each RLM run, a judge evaluates success or failure, and an extractor distills new procedural insights. These are retrieved via BM25 for similar future tasks, allowing the agent to improve over time.\n\n**Structured sense data** provides compact ontology metadata (~600 chars) with 100% URI grounding validation. Instead of loading full ontologies into context, the system injects targeted sense cards with key classes, properties, and exploration hints—achieving 83% iteration reduction on entity queries.\n\nAdditional components include SPARQL result handles that expose metadata without materializing full result sets, SHACL shape indexing for schema discovery, and query template retrieval from `sh:SPARQLExecutable` examples."
  },
  {
   "cell_type": "markdown",
   "id": "80bd2fed",
   "metadata": {},
   "source": "## Context Engineering: Ont-Sense & Memory-Based Architecture\n\nTo enable effective ontology exploration, this implementation uses a **four-layer context injection strategy** that provides the LLM with just enough information without overwhelming its context window:\n\n### Layer 0: Structured Sense Data\n\n**Ont-Sense** provides compact, programmatically-extracted ontology metadata with 100% URI grounding validation. Instead of loading full ontologies, the system injects ~600 character sense cards containing:\n\n- Key classes and properties (with URIs)\n- Available indexes (hierarchy, domains, ranges)\n- Label/description predicates\n- Quick exploration hints\n\nThe sense card is auto-generated from GraphMeta scaffolding and validated to ensure all URIs exist in the ontology (zero hallucinations). Progressive disclosure automatically injects detailed sections (hierarchy overview, common patterns) when query keywords trigger them.\n\n### Layer 1: General Strategies (Procedural Memory)\n\nUniversal exploration patterns are **bootstrapped as procedural memories** and retrieved via BM25 when relevant to the query. These 7 general strategies include:\n\n- Describe Entity by Label\n- Find Subclasses/Superclasses Using GraphMeta\n- Find Properties by Domain/Range\n- Pattern-Based Entity Search\n- Find Relationship Paths\n- Navigate Class Hierarchy from Roots\n\nThese strategies are stored as `MemoryItem` objects (not hardcoded), enabling the system to learn new patterns over time and update success rates based on actual performance.\n\n### Layer 2: Ontology-Specific Recipes\n\nDomain-specific patterns (PROV Activity-Entity relationships, SIO measurement patterns) can be authored as `Recipe` objects and injected when working with specific ontologies. This layer is currently a placeholder, reserved for future ontology-specific guidance.\n\n### Layer 3: Base Context\n\nGraphMeta summary and ontology statistics provide foundational context about triple counts, class/property distributions, and index availability.\n\n### Performance Results\n\nThis architecture achieves **83% iteration reduction** on entity description queries:\n\n- **Baseline** (no enhancements): 6 iterations\n- **With sense + memory**: 1 iteration\n\nThe four-layer approach maintains bounded context size (~1800 chars total) while providing targeted, relevant guidance for each query type."
  },
  {
   "cell_type": "markdown",
   "id": "cfca2326",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "This project uses [uv](https://github.com/astral-sh/uv) for package management with a shared environment:\n",
    "\n",
    "```bash\n",
    "source ~/uvws/.venv/bin/activate\n",
    "uv pip install fastcore claudette rdflib rank-bm25\n",
    "uv pip install -e .\n",
    "```\n",
    "\n",
    "For development, you also need nbdev:\n",
    "\n",
    "```bash\n",
    "uv pip install nbdev\n",
    "nbdev_install_hooks\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55bb374",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "The following demonstrates loading an ontology into the dataset memory and using bounded view functions to explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff93197c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'ds' (session: ae4334a3)\n",
      "mem: 0 triples\n",
      "prov: 0 events\n",
      "work graphs: 0\n",
      "onto graphs: 0\n"
     ]
    }
   ],
   "source": [
    "from rlm.dataset import setup_dataset_context\n",
    "\n",
    "# Initialize dataset with mem/prov graphs\n",
    "ns = {}\n",
    "setup_dataset_context(ns)\n",
    "print(ns['dataset_stats']())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e264c2",
   "metadata": {},
   "outputs": [],
   "source": "#| eval: false\n# Mount an ontology (SHACL shapes are auto-indexed)\nns['mount_ontology']('ontology/dcat-ap/dcat-ap-SHACL.ttl', 'dcat')\n\n# The SHACL index is now available\nprint(ns['dcat_shacl'].summary())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e821b3",
   "metadata": {},
   "outputs": [],
   "source": "#| eval: false\nfrom rlm.shacl_examples import search_shapes, describe_shape\n\n# Search for shapes related to datasets\nresults = search_shapes(ns['dcat_shacl'], 'dataset', limit=3)\nfor r in results:\n    print(f\"{r['uri'].split('#')[-1]}: targets {r['targets']}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0db89b",
   "metadata": {},
   "outputs": [],
   "source": "#| eval: false\n# Get bounded description of a shape (first 10 properties)\ndesc = describe_shape(ns['dcat_shacl'], results[0]['uri'], limit=10)\nprint(f\"Properties: {desc['property_count']} (showing {len(desc['properties'])})\")\nfor p in desc['properties'][:5]:\n    print(f\"  {p['path'].split('/')[-1]}: min={p.get('minCount')}\")"
  },
  {
   "cell_type": "markdown",
   "id": "d1298fb5",
   "metadata": {},
   "source": [
    "Query templates can be loaded from SHACL-AF examples and searched by keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40345e1",
   "metadata": {},
   "outputs": [],
   "source": "#| eval: false\nfrom rlm.shacl_examples import load_query_examples, search_queries, get_query_text\n\n# Load neXtProt SPARQL examples\nload_query_examples('ontology/uniprot/examples/neXtProt', ns, 'nxq')\nprint(ns['nxq'].summary())\n\n# Find queries about phosphorylation\nqueries = search_queries(ns['nxq'], 'phosphorylation', limit=2)\nfor q in queries:\n    print(f\"{q['uri'].split('/')[-1]}: {q['comment'][:60]}...\")"
  },
  {
   "cell_type": "markdown",
   "id": "bffc5d9d",
   "metadata": {},
   "source": "## Tutorial\n\nFor a complete walkthrough with working examples, see [91_tutorial.ipynb](91_tutorial.html). The tutorial demonstrates:\n\n- Core RLM loop with `llm_query()` and `rlm_run()`\n- Ontology loading with bounded views\n- Progressive disclosure over RDF graphs\n- **Structured sense data** with 100% URI grounding\n- **Four-layer context injection** (sense + memory + recipes + base)\n- **Memory-based general strategies** and BM25 retrieval\n- Dataset memory for fact persistence\n- SPARQL result handles\n- Procedural memory closed loop (judge + extract)\n- SHACL shape indexing\n- Multi-ontology integration\n\nAll cells are executed with real Claude API calls showing actual outputs."
  },
  {
   "cell_type": "markdown",
   "id": "5a1dd061",
   "metadata": {},
   "source": "## Testing\n\nThe project includes a comprehensive test suite with 110+ tests covering all components:\n\n```\ntests/\n├── unit/                    # Component-level tests\n│   ├── test_sparql_handles.py\n│   ├── test_session_tracking.py\n│   ├── test_memory_store.py\n│   ├── test_bootstrap_strategies.py      # NEW: Bootstrap validation\n│   ├── test_memory_recipe_separation.py  # NEW: Architecture separation\n│   └── test_sense_structured.py          # NEW: Sense data validation\n├── integration/             # Cross-component tests\n│   ├── test_dataset_memory.py\n│   ├── test_sparql_dataset.py\n│   ├── test_memory_closed_loop.py\n│   └── test_full_stack.py\n├── live/                    # API-required tests\n│   └── test_memory_integration.py        # NEW: Memory-based architecture\n└── test_quick_e2e.py        # End-to-end validation\n```\n\n### Running Tests\n\n```bash\n# Activate environment\nsource ~/uvws/.venv/bin/activate\n\n# Run unit tests (no API calls)\npytest tests/unit/ -v\n\n# Run integration tests (no API calls)\npytest tests/integration/ -v\n\n# Run live tests (requires ANTHROPIC_API_KEY)\nANTHROPIC_API_KEY=sk-... pytest tests/live/ -v\n\n# Run quick end-to-end test (with API calls)\npython tests/test_quick_e2e.py\n\n# Run notebook tests\nnbdev_test\n```\n\nAll tests pass, validating:\n- Core RLM loop with Claude API\n- Ontology loading and exploration\n- **Structured sense data with URI grounding** ✅\n- **Bootstrap general strategies (7 universal patterns)** ✅\n- **Memory-recipe separation validation** ✅\n- **Four-layer context injection** ✅\n- Dataset memory persistence\n- SPARQL result handles\n- Procedural memory closed loop\n- SHACL shape indexing\n- End-to-end integration workflows\n\nSee `tests/README.md` for detailed test documentation."
  },
  {
   "cell_type": "markdown",
   "id": "57f945ce",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "The project includes a comprehensive test suite with 100+ tests covering all components:\n",
    "\n",
    "```\n",
    "tests/\n",
    "├── unit/                    # Component-level tests\n",
    "│   ├── test_sparql_handles.py\n",
    "│   ├── test_session_tracking.py\n",
    "│   └── test_memory_store.py\n",
    "├── integration/             # Cross-component tests\n",
    "│   ├── test_dataset_memory.py\n",
    "│   ├── test_sparql_dataset.py\n",
    "│   ├── test_memory_closed_loop.py\n",
    "│   └── test_full_stack.py\n",
    "└── test_quick_e2e.py        # End-to-end validation\n",
    "```\n",
    "\n",
    "### Running Tests\n",
    "\n",
    "```bash\n",
    "# Activate environment\n",
    "source ~/uvws/.venv/bin/activate\n",
    "\n",
    "# Run all tests (no API calls)\n",
    "pytest tests/unit/ tests/integration/ -v\n",
    "\n",
    "# Run quick end-to-end test (with API calls)\n",
    "python tests/test_quick_e2e.py\n",
    "\n",
    "# Run notebook tests\n",
    "nbdev_test\n",
    "```\n",
    "\n",
    "All tests pass, validating:\n",
    "- Core RLM loop with Claude API\n",
    "- Ontology loading and exploration\n",
    "- Dataset memory persistence\n",
    "- SPARQL result handles\n",
    "- Procedural memory closed loop\n",
    "- SHACL shape indexing\n",
    "- End-to-end integration workflows\n",
    "\n",
    "See `tests/README.md` for detailed test documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ea2760",
   "metadata": {},
   "source": "## Status\n\nThis is preliminary research code under active development. The current implementation covers stages 1-5 of the trajectory:\n\n- Stage 1: Core RLM loop with claudette backend ✅\n- Stage 2: Bounded view primitives for progressive disclosure ✅\n- Stage 3: SPARQL handles with work-bound query execution ✅\n- Stage 4: SHACL shape indexing and query template retrieval ✅\n- Stage 5: Ont-Sense improvements & ReasoningBank integration ✅\n  - Structured sense data with 100% URI grounding\n  - Four-layer context injection (sense, memory, recipes, base context)\n  - Memory-based general strategies (bootstrap + learning)\n  - Validation pipeline and comprehensive test suite\n  - 83% iteration reduction on entity queries\n\nStage 6 (evaluation framework) is in progress with task-based eval system in `evals/`.\n\nThe code is developed through exploratory programming in Jupyter notebooks using nbdev. It targets integration with the [Solveit](https://solveit.ai) platform but can run standalone."
  },
  {
   "cell_type": "markdown",
   "id": "118cac6e",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Zhang, A., et al. (2025). [Recursive Language Models](https://github.com/alexzhang13/rlm). The reference implementation this project follows.\n",
    "- Wang, B., et al. (2025). [ReasoningBank: Self-Evolving Procedural Knowledge for Adaptive Reasoning](https://arxiv.org/html/2509.25140v1). Procedural memory approach for learning from trajectories.\n",
    "- Anthropic. (2025). [Building Effective Agents](https://www.anthropic.com/research/building-effective-agents). Context engineering patterns for agentic systems.\n",
    "- Howard, J. & Gugger, S. [nbdev](https://nbdev.fast.ai/). Literate programming framework.\n",
    "- Howard, J. [claudette](https://claudette.answer.ai/). Claude API wrapper used as the LLM backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad20328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
