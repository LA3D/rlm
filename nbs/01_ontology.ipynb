{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ontology\n",
    "\n",
    "> RDF ontology loading and meta-graph navigation for RLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ontology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Overview\n\nThis module implements Stages 1-2 of the trajectory: Define the Ontology \"Context Model\" and provide bounded view primitives for progressive disclosure.\n\n**Stage 1**: Meta-graph scaffolding with navigation indexes  \n**Stage 2**: Bounded view primitives for safe graph exploration\n\n### Design Principles\n\n- **Handles, not dumps**: Return graph handles with bounded view operations\n- **Meta-graph scaffolding**: Build navigation indexes (labels, hierarchy, properties)\n- **Progressive disclosure**: Small summaries guide exploration\n- **RLM-compatible**: Works with namespace-explicit `rlm_run()`\n\n### Context Model\n\nFrom the trajectory document:\n> The *root model never gets a graph dump*. It gets a handle name (e.g. `ont`, `res_0`) and uses bounded view operations."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#| export\nfrom rdflib import Graph, Namespace, RDF, RDFS, OWL, URIRef, Literal, SKOS, DCTERMS\nfrom pathlib import Path\nfrom collections import Counter, defaultdict\nfrom dataclasses import dataclass, field\nfrom fastcore.basics import AttrDict\n\n# Additional namespaces for ontology metadata (Widoco guide)\nVANN = Namespace('http://purl.org/vocab/vann/')\nDC = Namespace('http://purl.org/dc/elements/1.1/')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_ontology(path: str | Path, ns: dict, name: str = 'ont') -> str:\n",
    "    \"\"\"Load an RDF ontology file into namespace as a Graph handle.\n",
    "    \n",
    "    Args:\n",
    "        path: Path to ontology file (.ttl, .rdf, .owl)\n",
    "        ns: Namespace dict where Graph will be stored\n",
    "        name: Variable name for the Graph handle\n",
    "        \n",
    "    Returns:\n",
    "        Summary string describing what was loaded\n",
    "    \"\"\"\n",
    "    g = Graph()\n",
    "    g.parse(path)\n",
    "    ns[name] = g\n",
    "    \n",
    "    return f\"Loaded {len(g)} triples from {Path(path).name} into '{name}'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading prov.ttl\n",
    "test_ns = {}\n",
    "result = load_ontology('ontology/prov.ttl', test_ns, name='prov_ont')\n",
    "print(result)\n",
    "assert 'prov_ont' in test_ns\n",
    "assert isinstance(test_ns['prov_ont'], Graph)\n",
    "assert len(test_ns['prov_ont']) > 0\n",
    "print(f\"✓ Loaded {len(test_ns['prov_ont'])} triples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Graph Navigation\n",
    "\n",
    "Build navigation scaffolding from a Graph to enable progressive disclosure.\n",
    "This is what goes in the REPL environment, not the graph itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@dataclass\nclass GraphMeta:\n    \"\"\"Meta-graph navigation scaffolding for an RDF Graph.\n    \n    This is REPL-resident and provides bounded views over the graph.\n    Indexes discovered in dialogs/inspect_tools.ipynb exploration.\n    \"\"\"\n    graph: Graph\n    name: str = 'ont'\n    \n    # Computed lazily\n    _namespaces: dict = field(default=None, init=False, repr=False)\n    _classes: list = field(default=None, init=False, repr=False)\n    _properties: list = field(default=None, init=False, repr=False)\n    _individuals: list = field(default=None, init=False, repr=False)\n    _labels: dict = field(default=None, init=False, repr=False)\n    _by_label: dict = field(default=None, init=False, repr=False)\n    _subs: dict = field(default=None, init=False, repr=False)\n    _supers: dict = field(default=None, init=False, repr=False)\n    _doms: dict = field(default=None, init=False, repr=False)\n    _rngs: dict = field(default=None, init=False, repr=False)\n    _pred_freq: Counter = field(default=None, init=False, repr=False)\n    \n    @property\n    def triple_count(self) -> int:\n        \"\"\"Total number of triples in graph.\"\"\"\n        return len(self.graph)\n    \n    @property\n    def namespaces(self) -> dict:\n        \"\"\"Get namespace prefix bindings.\"\"\"\n        if self._namespaces is None:\n            self._namespaces = {prefix: str(ns) for prefix, ns in self.graph.namespaces()}\n        return self._namespaces\n    \n    @property\n    def classes(self) -> list:\n        \"\"\"Get all OWL/RDFS classes (URIs only, sorted).\"\"\"\n        if self._classes is None:\n            classes = set(\n                self.graph.subjects(RDF.type, OWL.Class)\n            ).union(\n                self.graph.subjects(RDF.type, RDFS.Class)\n            )\n            self._classes = sorted([str(c) for c in classes])\n        return self._classes\n    \n    @property\n    def properties(self) -> list:\n        \"\"\"Get all properties (URIs only, sorted).\"\"\"\n        if self._properties is None:\n            props = set(\n                self.graph.subjects(RDF.type, OWL.ObjectProperty)\n            ).union(\n                self.graph.subjects(RDF.type, OWL.DatatypeProperty)\n            ).union(\n                self.graph.subjects(RDF.type, OWL.AnnotationProperty)\n            ).union(\n                self.graph.subjects(RDF.type, RDF.Property)\n            )\n            self._properties = sorted([str(p) for p in props])\n        return self._properties\n    \n    @property\n    def individuals(self) -> list:\n        \"\"\"Get all named individuals (URIs only, sorted).\"\"\"\n        if self._individuals is None:\n            inds = set(self.graph.subjects(RDF.type, OWL.NamedIndividual))\n            self._individuals = sorted([str(i) for i in inds])\n        return self._individuals\n    \n    @property\n    def labels(self) -> dict:\n        \"\"\"Get label index: URI -> label string.\"\"\"\n        if self._labels is None:\n            self._labels = {}\n            for s, o in self.graph.subject_objects(RDFS.label):\n                self._labels[str(s)] = str(o)\n        return self._labels\n    \n    @property\n    def by_label(self) -> dict:\n        \"\"\"Get inverted label index: label_text -> list of URIs.\"\"\"\n        if self._by_label is None:\n            inv = defaultdict(list)\n            for uri, lbl in self.labels.items():\n                inv[lbl.lower()].append(uri)\n            self._by_label = dict(inv)\n        return self._by_label\n    \n    @property\n    def subs(self) -> dict:\n        \"\"\"Get subclass relationships: superclass_uri -> list of subclass_uris.\"\"\"\n        if self._subs is None:\n            subs_dict = defaultdict(list)\n            for s, _, o in self.graph.triples((None, RDFS.subClassOf, None)):\n                if isinstance(o, URIRef):\n                    subs_dict[str(o)].append(str(s))\n            self._subs = dict(subs_dict)\n        return self._subs\n    \n    @property\n    def supers(self) -> dict:\n        \"\"\"Get superclass relationships: subclass_uri -> list of superclass_uris.\"\"\"\n        if self._supers is None:\n            supers_dict = defaultdict(list)\n            for s, _, o in self.graph.triples((None, RDFS.subClassOf, None)):\n                if isinstance(o, URIRef):\n                    supers_dict[str(s)].append(str(o))\n            self._supers = dict(supers_dict)\n        return self._supers\n    \n    @property\n    def doms(self) -> dict:\n        \"\"\"Get property domains: property_uri -> domain_uri.\"\"\"\n        if self._doms is None:\n            self._doms = {str(s): str(o) for s, _, o in self.graph.triples((None, RDFS.domain, None))}\n        return self._doms\n    \n    @property\n    def rngs(self) -> dict:\n        \"\"\"Get property ranges: property_uri -> range_uri.\"\"\"\n        if self._rngs is None:\n            self._rngs = {str(s): str(o) for s, _, o in self.graph.triples((None, RDFS.range, None))}\n        return self._rngs\n    \n    @property\n    def pred_freq(self) -> Counter:\n        \"\"\"Get predicate frequency counts (cached).\"\"\"\n        if self._pred_freq is None:\n            from collections import Counter\n            self._pred_freq = Counter(str(p) for s, p, o in self.graph.triples((None, None, None)))\n        return self._pred_freq\n    \n    def summary(self) -> str:\n        \"\"\"Generate a summary of the graph for display.\"\"\"\n        lines = [\n            f\"Graph '{self.name}': {self.triple_count:,} triples\",\n            f\"Classes: {len(self.classes)}\",\n            f\"Properties: {len(self.properties)}\",\n            f\"Individuals: {len(self.individuals)}\",\n            f\"Namespaces: {', '.join(self.namespaces.keys())}\"\n        ]\n        return '\\n'.join(lines)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test GraphMeta with prov ontology\n",
    "prov_g = test_ns['prov_ont']\n",
    "meta = GraphMeta(prov_g, name='prov')\n",
    "\n",
    "print(meta.summary())\n",
    "print()\n",
    "print(f\"Sample classes (first 5): {meta.classes[:5]}\")\n",
    "print(f\"Sample properties (first 5): {meta.properties[:5]}\")\n",
    "print(f\"Namespaces: {list(meta.namespaces.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Bounded View Functions (Stage 1)\n\nBasic operations on GraphMeta that return small, bounded summaries:\n\n- **graph_stats()**: Overall graph statistics\n- **search_by_label()**: Simple label-based search\n- **describe_entity()**: Get entity description with sample triples\n\nThese provide the foundation for progressive disclosure."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def graph_stats(meta: GraphMeta) -> str:\n",
    "    \"\"\"Get graph statistics summary.\"\"\"\n",
    "    return meta.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#| export\ndef search_entity(meta: GraphMeta, query: str, limit: int = 10,\n                  search_in: str = 'all') -> list:\n    \"\"\"Search for entities by label, IRI, or localname.\n\n    Args:\n        meta: GraphMeta to search\n        query: Search string (case-insensitive substring match)\n        limit: Maximum results to return\n        search_in: Where to search - 'label', 'iri', 'localname', or 'all'\n\n    Returns:\n        List of dicts: [{'uri': str, 'label': str, 'match_type': str}, ...]\n    \"\"\"\n    query_lower = query.lower()\n    matches = []\n\n    # Search in labels\n    if search_in in ('label', 'all'):\n        for uri, label in meta.labels.items():\n            if query_lower in label.lower():\n                matches.append({\n                    'uri': uri,\n                    'label': label,\n                    'match_type': 'label'\n                })\n\n    # Search in full IRIs\n    if search_in in ('iri', 'all'):\n        all_uris = set(meta.classes + meta.properties + meta.individuals)\n        for uri in all_uris:\n            if query_lower in uri.lower() and not any(m['uri'] == uri for m in matches):\n                label = meta.labels.get(uri, uri)\n                matches.append({\n                    'uri': uri,\n                    'label': label,\n                    'match_type': 'iri'\n                })\n\n    # Search in localnames (fragment or last path segment)\n    if search_in in ('localname', 'all'):\n        all_uris = set(meta.classes + meta.properties + meta.individuals)\n        for uri in all_uris:\n            # Extract localname (after # or last /)\n            if '#' in uri:\n                localname = uri.split('#')[-1]\n            else:\n                localname = uri.split('/')[-1]\n\n            if query_lower in localname.lower() and not any(m['uri'] == uri for m in matches):\n                label = meta.labels.get(uri, uri)\n                matches.append({\n                    'uri': uri,\n                    'label': label,\n                    'match_type': 'localname'\n                })\n\n    return matches[:limit]\n\n\ndef search_by_label(meta: GraphMeta, search: str, limit: int = 10) -> list:\n    \"\"\"Search for entities by label substring (case-insensitive).\n\n    Backward-compatible wrapper around search_entity().\n\n    Args:\n        meta: GraphMeta to search\n        search: Substring to search for in labels\n        limit: Maximum results to return\n\n    Returns:\n        List of (URI, label) tuples\n    \"\"\"\n    results = search_entity(meta, search, limit=limit, search_in='label')\n    return [(r['uri'], r['label']) for r in results]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test search_entity\nresults = search_entity(meta, 'activity', limit=5)\nprint(f\"Found {len(results)} matches for 'activity':\")\nfor r in results:\n    print(f\"  {r['label']}: {r['uri']} ({r['match_type']})\")\n\n# Test different search modes\nprint(\"\\nSearch by IRI only:\")\niri_results = search_entity(meta, 'prov', search_in='iri', limit=3)\nfor r in iri_results:\n    print(f\"  {r['label']}: {r['uri']}\")\n\n# Test backward compatibility\nprint(\"\\nBackward compatibility test:\")\nlegacy_results = search_by_label(meta, 'activity', limit=5)\nprint(f\"Found {len(legacy_results)} matches using search_by_label():\")\nfor uri, label in legacy_results:\n    print(f\"  {label}: {uri}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#| export\ndef describe_entity(meta: GraphMeta, uri: str, limit: int = 20) -> dict:\n    \"\"\"Get bounded description of an entity.\n    \n    Args:\n        meta: GraphMeta containing the entity\n        uri: URI of entity to describe\n        limit: Max number of triples to include\n        \n    Returns:\n        Dict with label, types, and sample triples\n    \"\"\"\n    from rdflib import URIRef\n    \n    entity = URIRef(uri)\n    \n    # Get label\n    label = meta.labels.get(uri, uri)\n    \n    # Get types\n    types = [str(t) for t in meta.graph.objects(entity, RDF.type)]\n    \n    # Get sample of outgoing triples\n    outgoing = []\n    for p, o in list(meta.graph.predicate_objects(entity))[:limit]:\n        outgoing.append((str(p), str(o)))\n    \n    # Get comment if available\n    comments = list(meta.graph.objects(entity, RDFS.comment))\n    comment = str(comments[0]) if comments else None\n    \n    return {\n        'uri': uri,\n        'label': label,\n        'types': types,\n        'comment': comment,\n        'outgoing_sample': outgoing[:limit]  # FIX: Use limit parameter, not hardcoded [:10]\n    }"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test describe_entity\n",
    "# Find the Activity class\n",
    "activity_uri = 'http://www.w3.org/ns/prov#Activity'\n",
    "desc = describe_entity(meta, activity_uri)\n",
    "\n",
    "print(f\"Label: {desc['label']}\")\n",
    "print(f\"Types: {desc['types']}\")\n",
    "print(f\"Comment: {desc['comment'][:100]}...\" if desc['comment'] else \"No comment\")\n",
    "print(f\"Outgoing triples: {len(desc['outgoing_sample'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Stage 2: Progressive Disclosure Primitives\n\nAdvanced bounded view operations that enable root models to explore graphs iteratively:\n\n- **search_entity()**: Multi-mode entity search (label/IRI/localname)\n- **probe_relationships()**: One-hop neighbor exploration with filtering\n- **find_path()**: BFS path finding between entities\n- **predicate_frequency()**: Usage analysis for understanding graph structure\n\nThese primitives answer questions like:\n- \"Is X defined?\" → `search_entity()`\n- \"What connects A to B?\" → `find_path()`\n- \"What are the most important predicates?\" → `predicate_frequency()`\n- \"What does X relate to?\" → `probe_relationships()`",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "#| export\ndef probe_relationships(meta: GraphMeta, uri: str, predicate: str = None,\n                        direction: str = 'both', limit: int = 20) -> dict:\n    \"\"\"Get one-hop neighbors of an entity, optionally filtered by predicate.\n\n    Args:\n        meta: GraphMeta containing the entity\n        uri: URI of entity to probe\n        predicate: Optional predicate URI to filter by\n        direction: 'out', 'in', or 'both' (default: 'both')\n        limit: Maximum neighbors to return per direction\n\n    Returns:\n        {\n            'uri': str, 'label': str,\n            'outgoing': [{'predicate': str, 'pred_label': str,\n                          'object': str, 'obj_label': str}, ...],\n            'incoming': [{'subject': str, 'subj_label': str,\n                          'predicate': str, 'pred_label': str}, ...],\n            'outgoing_count': int, 'incoming_count': int\n        }\n    \"\"\"\n    from rdflib import URIRef\n\n    entity = URIRef(uri)\n    entity_label = meta.labels.get(uri, uri)\n\n    outgoing = []\n    incoming = []\n\n    # Get outgoing triples (entity as subject)\n    if direction in ('out', 'both'):\n        pred_filter = URIRef(predicate) if predicate else None\n        triples = list(meta.graph.triples((entity, pred_filter, None)))\n\n        for s, p, o in triples[:limit]:\n            pred_uri = str(p)\n            obj_uri = str(o)\n            outgoing.append({\n                'predicate': pred_uri,\n                'pred_label': meta.labels.get(pred_uri, pred_uri),\n                'object': obj_uri,\n                'obj_label': meta.labels.get(obj_uri, obj_uri)\n            })\n\n    # Get incoming triples (entity as object)\n    if direction in ('in', 'both'):\n        pred_filter = URIRef(predicate) if predicate else None\n        triples = list(meta.graph.triples((None, pred_filter, entity)))\n\n        for s, p, o in triples[:limit]:\n            subj_uri = str(s)\n            pred_uri = str(p)\n            incoming.append({\n                'subject': subj_uri,\n                'subj_label': meta.labels.get(subj_uri, subj_uri),\n                'predicate': pred_uri,\n                'pred_label': meta.labels.get(pred_uri, pred_uri)\n            })\n\n    # Count total (not just limited sample)\n    pred_filter = URIRef(predicate) if predicate else None\n    if direction in ('out', 'both'):\n        outgoing_count = sum(1 for _ in meta.graph.triples((entity, pred_filter, None)))\n    else:\n        outgoing_count = 0\n\n    if direction in ('in', 'both'):\n        incoming_count = sum(1 for _ in meta.graph.triples((None, pred_filter, entity)))\n    else:\n        incoming_count = 0\n\n    return {\n        'uri': uri,\n        'label': entity_label,\n        'outgoing': outgoing,\n        'incoming': incoming,\n        'outgoing_count': outgoing_count,\n        'incoming_count': incoming_count\n    }",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "#| export\ndef find_path(meta: GraphMeta, source: str, target: str,\n              max_depth: int = 2, limit: int = 10) -> list:\n    \"\"\"Find predicates connecting two entities using BFS.\n\n    Answers \"What predicates connect A to B?\"\n\n    Args:\n        meta: GraphMeta to search\n        source: Source entity URI\n        target: Target entity URI\n        max_depth: Maximum path length (default: 2)\n        limit: Maximum paths to return\n\n    Returns:\n        List of paths, each path is list of steps:\n        [{'from': uri, 'predicate': uri, 'to': uri, 'direction': 'out'|'in'}, ...]\n    \"\"\"\n    from rdflib import URIRef\n    from collections import deque\n\n    source_uri = URIRef(source)\n    target_uri = URIRef(target)\n\n    # BFS to find paths\n    queue = deque([(source_uri, [])])  # (current_node, path_so_far)\n    visited = set()\n    paths_found = []\n\n    while queue and len(paths_found) < limit:\n        current, path = queue.popleft()\n\n        # Skip if we've exceeded max depth\n        if len(path) >= max_depth:\n            continue\n\n        # Skip if visited (but allow revisiting in different paths up to limit)\n        path_key = (current, tuple(step['predicate'] for step in path))\n        if path_key in visited:\n            continue\n        visited.add(path_key)\n\n        # Check if we reached the target\n        if current == target_uri:\n            paths_found.append(path)\n            continue\n\n        # Explore outgoing edges\n        for s, p, o in meta.graph.triples((current, None, None)):\n            if isinstance(o, URIRef):\n                step = {\n                    'from': str(s),\n                    'predicate': str(p),\n                    'to': str(o),\n                    'direction': 'out'\n                }\n                queue.append((o, path + [step]))\n\n        # Explore incoming edges\n        for s, p, o in meta.graph.triples((None, None, current)):\n            if isinstance(s, URIRef):\n                step = {\n                    'from': str(current),\n                    'predicate': str(p),\n                    'to': str(s),\n                    'direction': 'in'\n                }\n                queue.append((s, path + [step]))\n\n    return paths_found",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "#| export\ndef predicate_frequency(meta: GraphMeta, limit: int = 20,\n                        predicate_type: str = None) -> list:\n    \"\"\"Get predicates ranked by frequency of use.\n\n    Args:\n        meta: GraphMeta to analyze\n        limit: Maximum predicates to return\n        predicate_type: Optional filter - 'object', 'datatype', 'annotation'\n\n    Returns:\n        List of dicts: [{'predicate': str, 'label': str, 'count': int,\n                         'sample_subject': str, 'sample_object': str}, ...]\n    \"\"\"\n    from rdflib import URIRef\n    from collections import Counter\n\n    # Get frequency counter (cached)\n    freq = meta.pred_freq\n\n    # Filter by type if requested\n    if predicate_type:\n        type_props = set()\n\n        if predicate_type == 'object':\n            type_props = set(meta.graph.subjects(RDF.type, OWL.ObjectProperty))\n        elif predicate_type == 'datatype':\n            type_props = set(meta.graph.subjects(RDF.type, OWL.DatatypeProperty))\n        elif predicate_type == 'annotation':\n            type_props = set(meta.graph.subjects(RDF.type, OWL.AnnotationProperty))\n\n        # Filter frequency counts to only include predicates of this type\n        # FIX: Wrap in Counter so most_common() works\n        filtered_freq = Counter({str(p): count for p, count in freq.items() if URIRef(p) in type_props})\n    else:\n        filtered_freq = freq\n\n    # Get top N by frequency\n    top_predicates = filtered_freq.most_common(limit)\n\n    # Build result list with samples\n    results = []\n    for pred_uri, count in top_predicates:\n        # Get label\n        pred_label = meta.labels.get(pred_uri, pred_uri)\n\n        # Get sample triple\n        sample_triple = next(meta.graph.triples((None, URIRef(pred_uri), None)), None)\n\n        if sample_triple:\n            sample_subj = str(sample_triple[0])\n            sample_obj = str(sample_triple[2])\n        else:\n            sample_subj = None\n            sample_obj = None\n\n        results.append({\n            'predicate': pred_uri,\n            'label': pred_label,\n            'count': count,\n            'sample_subject': sample_subj,\n            'sample_object': sample_obj\n        })\n\n    return results",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Test probe_relationships\nactivity_uri = 'http://www.w3.org/ns/prov#Activity'\nprobe_result = probe_relationships(meta, activity_uri, limit=5)\n\nprint(f\"Probing: {probe_result['label']}\")\nprint(f\"Outgoing relationships: {probe_result['outgoing_count']} total, showing {len(probe_result['outgoing'])}\")\nfor rel in probe_result['outgoing'][:3]:\n    print(f\"  --{rel['pred_label']}--> {rel['obj_label']}\")\n\nprint(f\"\\nIncoming relationships: {probe_result['incoming_count']} total, showing {len(probe_result['incoming'])}\")\nfor rel in probe_result['incoming'][:3]:\n    print(f\"  <--{rel['pred_label']}-- {rel['subj_label']}\")\n\n# Test find_path\n# Find path between two PROV classes\nentity_uri = 'http://www.w3.org/ns/prov#Entity'\npaths = find_path(meta, activity_uri, entity_uri, max_depth=2, limit=3)\n\nprint(f\"\\n\\nPaths from Activity to Entity:\")\nif paths:\n    for i, path in enumerate(paths, 1):\n        print(f\"Path {i}:\")\n        for step in path:\n            direction_sym = '-->' if step['direction'] == 'out' else '<--'\n            pred_label = meta.labels.get(step['predicate'], step['predicate'])\n            print(f\"  {direction_sym} {pred_label}\")\nelse:\n    print(\"  No paths found\")\n",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Test predicate_frequency\nprint(\"Top 10 predicates by frequency:\")\nfreq_results = predicate_frequency(meta, limit=10)\nfor r in freq_results:\n    print(f\"  {r['count']:4d} uses - {r['label']}\")\n\n# Test filtering by predicate type\nprint(\"\\nTop 5 object properties:\")\nobj_props = predicate_frequency(meta, limit=5, predicate_type='object')\nfor r in obj_props:\n    print(f\"  {r['count']:4d} uses - {r['label']}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Additional Exploration Functions\n\nFunctions discovered in `dialogs/inspect_tools.ipynb` for deeper ontology exploration.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "#| export\ndef ont_describe(ont: str, uri: str, name: str = 'desc', ns: dict = None) -> str:\n    \"\"\"Get all triples about a URI, store in namespace.\n    \n    Returns both triples where URI is subject and where it's object.\n    \n    Args:\n        ont: Name of ontology variable in namespace\n        uri: URI to describe\n        name: Variable name for storing result\n        ns: Namespace dict\n        \n    Returns:\n        Summary string\n    \"\"\"\n    if ns is None: ns = globals()\n    o = ns[ont]\n    u = URIRef(uri) if not isinstance(uri, URIRef) else uri\n    \n    # Get triples where URI is subject\n    subj_triples = [(str(s), str(p), str(obj)) for s, p, obj in o.graph.triples((u, None, None))]\n    \n    # Get triples where URI is object\n    obj_triples = [(str(s), str(p), str(obj)) for s, p, obj in o.graph.triples((None, None, u))]\n    \n    result = {\n        'as_subject': subj_triples,\n        'as_object': obj_triples\n    }\n    ns[name] = result\n    return f\"Stored {len(subj_triples)} + {len(obj_triples)} triples about '{uri}' into '{name}'\"",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "#| export\ndef ont_meta(ont: str, name: str = 'meta', ns: dict = None) -> str:\n    \"\"\"Extract ontology metadata (prefixes, annotation predicates, imports).\n    \n    Args:\n        ont: Name of ontology variable in namespace\n        name: Variable name for storing result\n        ns: Namespace dict\n        \n    Returns:\n        Summary string\n    \"\"\"\n    if ns is None: ns = globals()\n    o = ns[ont]\n    \n    prefixes = dict(o.graph.namespaces())\n    ann_preds = set(str(p) for s, p, obj in o.graph.triples((None, None, None)) if isinstance(obj, Literal))\n    imports = [str(obj) for s, p, obj in o.graph.triples((None, OWL.imports, None))]\n    \n    res = AttrDict(\n        prefixes=prefixes,\n        ann_preds=list(ann_preds)[:50],  # Limit to first 50\n        imports=imports\n    )\n    ns[name] = res\n    return f\"Stored metadata into '{name}': {len(prefixes)} prefixes, {len(ann_preds)} annotation predicates, {len(imports)} imports\"",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "#| export\ndef ont_roots(ont: str, name: str = 'roots', ns: dict = None) -> str:\n    \"\"\"Find root classes (no declared superclass), store in namespace.\n    \n    Args:\n        ont: Name of ontology variable in namespace\n        name: Variable name for storing result\n        ns: Namespace dict\n        \n    Returns:\n        Summary string\n    \"\"\"\n    if ns is None: ns = globals()\n    o = ns[ont]\n    \n    has_super = set(o.supers.keys())\n    roots = [str(c) for c in o.classes if str(c).startswith('http') and str(c) not in has_super]\n    \n    ns[name] = roots\n    return f\"Stored {len(roots)} root classes into '{name}'\"",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "#| export\ndef setup_ontology_context(path: str | Path, ns: dict, name: str = 'ont', dataset_meta=None) -> str:\n    \"\"\"Load ontology and create meta-graph for RLM use.\n    \n    This sets up both the Graph and GraphMeta in the namespace.\n    \n    NEW: Dataset integration - if dataset_meta provided, automatically mounts\n    the ontology into the dataset as onto/<name> graph.\n    \n    Args:\n        path: Path to ontology file\n        ns: Namespace dict\n        name: Base name for graph handle\n        dataset_meta: Optional DatasetMeta for auto-mounting\n        \n    Returns:\n        Summary string\n    \"\"\"\n    # Load graph\n    load_msg = load_ontology(path, ns, name=name)\n    \n    # Create meta-graph\n    g = ns[name]\n    meta = GraphMeta(g, name=name)\n    ns[f\"{name}_meta\"] = meta\n    \n    # NEW: Auto-mount in dataset if provided\n    if dataset_meta is not None:\n        try:\n            from rlm.dataset import mount_ontology\n            mount_msg = mount_ontology(dataset_meta, ns, str(path), name)\n            load_msg += f\"\\n{mount_msg}\"\n        except Exception as e:\n            print(f\"Warning: Failed to mount ontology in dataset: {e}\")\n    \n    # FIX: Namespace helper functions by ontology name to avoid overwriting\n    # This allows multiple ontologies to coexist\n    from functools import partial\n    \n    # Bind existing functions\n    ns[f'{name}_graph_stats'] = partial(graph_stats, meta)\n    ns[f'{name}_search_by_label'] = partial(search_by_label, meta)\n    ns[f'{name}_describe_entity'] = partial(describe_entity, meta)\n    \n    # NEW: Bind Stage 2 bounded view primitives\n    ns[f'{name}_search_entity'] = partial(search_entity, meta)\n    ns[f'{name}_probe_relationships'] = partial(probe_relationships, meta)\n    ns[f'{name}_find_path'] = partial(find_path, meta)\n    ns[f'{name}_predicate_frequency'] = partial(predicate_frequency, meta)\n    \n    # Also bind without prefix for single-ontology convenience\n    # (will be overwritten if multiple ontologies loaded, but prefixed versions persist)\n    ns['graph_stats'] = partial(graph_stats, meta)\n    ns['search_by_label'] = partial(search_by_label, meta)\n    ns['describe_entity'] = partial(describe_entity, meta)\n    ns['search_entity'] = partial(search_entity, meta)\n    ns['probe_relationships'] = partial(probe_relationships, meta)\n    ns['find_path'] = partial(find_path, meta)\n    ns['predicate_frequency'] = partial(predicate_frequency, meta)\n    \n    return f\"{load_msg}\\nCreated meta-graph '{name}_meta' with {len(meta.classes)} classes, {len(meta.properties)} properties\"",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Ontology Sense Building\n\n### What is a \"Sense Document\"?\n\nWhen an LLM needs to work with an ontology, loading the entire graph into context is wasteful and may exceed limits. Instead, we build a **sense document** - a compact summary that captures:\n\n- **Formalism**: Which OWL/RDFS/SKOS constructs are used\n- **Metadata structure**: Which annotation properties exist (labels, descriptions, etc.)\n- **Domain/scope**: What the ontology is about\n- **Navigation hints**: How to effectively search and traverse\n\nThis approach was developed through experiments in `dialogs/inspect_tools.ipynb` exploring progressive disclosure patterns.\n\n### Why Sense Building Matters\n\n**Design Decision Response** (from ISSUE_ANALYSIS.md):\n> *GraphMeta.labels only uses rdfs:label* - This is a limitation because different ontologies use different annotation properties:\n> - `rdfs:label`, `skos:prefLabel`, `skos:altLabel` for labels\n> - `rdfs:comment`, `skos:definition`, `dcterms:description` for descriptions  \n> - `vann:preferredNamespacePrefix`, `owl:versionInfo` for metadata\n\nRather than hardcode support for all possible properties, `build_sense()` **detects which annotation properties this specific ontology uses**, enabling intelligent search.\n\n### References\n\n- [Widoco Metadata Guide](https://github.com/dgarijo/Widoco/blob/master/doc/metadataGuide/guide.md) - Recommended ontology metadata properties\n- [Anthropic: Building Effective Agents](https://www.anthropic.com/engineering/building-effective-agents) - Orchestrator-workers pattern\n- [Anthropic: Progressive Disclosure](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents) - Context engineering strategy\n\n### Implementation Pattern\n\nThe sense-building workflow (not agentic):\n1. **Metadata collection** - Extract prefixes, detect annotation predicates, find ontology-level metadata\n2. **Structural exploration** - Build hierarchy, property signatures, detect OWL axioms\n3. **LLM synthesis** - One LLM call to identify domain, patterns, navigation hints\n4. **Structured storage** - Store as retrievable AttrDict in REPL namespace",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "#| export\ndef build_sense(path: str, name: str = 'sense', ns: dict = None) -> str:\n    \"\"\"Build ontology sense document using workflow + LLM synthesis.\n    \n    Detects annotation properties per Widoco metadata guide:\n    - Label properties: rdfs:label, skos:prefLabel, skos:altLabel, dcterms:title\n    - Description properties: rdfs:comment, skos:definition, dcterms:description\n    - Ontology metadata: vann:preferredNamespacePrefix, owl:versionInfo, etc.\n    \n    This function:\n    1. Loads ontology and extracts metadata/roots programmatically\n    2. Detects which annotation properties are actually used\n    3. Builds hierarchy (2 levels), property info, characteristics\n    4. Makes one LLM call to synthesize domain/scope/patterns/hints\n    5. Returns structured AttrDict stored in namespace\n    \n    Args:\n        path: Path to ontology file\n        name: Variable name for sense document (default: 'sense')\n        ns: Namespace dict\n        \n    Returns:\n        Summary string\n    \"\"\"\n    if ns is None: ns = {}\n    \n    # Derive ontology name from sense name\n    ont_name = name.replace('_sense', '').replace('sense', 'ont')\n    \n    # Setup ontology context (loads graph + creates GraphMeta)\n    setup_ontology_context(path, ns, name=ont_name)\n    \n    # Get metadata and roots\n    ont_meta(f'{ont_name}_meta', name=f'{ont_name}_metadata', ns=ns)\n    ont_roots(f'{ont_name}_meta', name=f'{ont_name}_roots', ns=ns)\n    \n    # Get references\n    meta_obj = ns[f'{ont_name}_meta']\n    metadata = ns[f'{ont_name}_metadata']\n    roots = ns[f'{ont_name}_roots']\n    g = meta_obj.graph\n    \n    # Detect ontology-level metadata (Widoco guide properties)\n    ont_uri = None\n    for s in g.subjects(RDF.type, OWL.Ontology):\n        ont_uri = str(s)\n        break\n    \n    ont_metadata = {}\n    if ont_uri:\n        ont_ref = URIRef(ont_uri)\n        ont_metadata['uri'] = ont_uri\n        \n        # Title/label\n        for title_prop in [DCTERMS.title, DC.title, RDFS.label]:\n            titles = list(g.objects(ont_ref, title_prop))\n            if titles:\n                ont_metadata['title'] = str(titles[0])\n                break\n        \n        # Description\n        for desc_prop in [DCTERMS.description, DC.description, RDFS.comment]:\n            descs = list(g.objects(ont_ref, desc_prop))\n            if descs:\n                ont_metadata['description'] = str(descs[0])\n                break\n        \n        # Version info\n        versions = list(g.objects(ont_ref, OWL.versionInfo))\n        if versions:\n            ont_metadata['version'] = str(versions[0])\n        \n        # Preferred namespace prefix\n        prefixes = list(g.objects(ont_ref, VANN.preferredNamespacePrefix))\n        if prefixes:\n            ont_metadata['preferred_prefix'] = str(prefixes[0])\n        \n        # Preferred namespace URI\n        ns_uris = list(g.objects(ont_ref, VANN.preferredNamespaceUri))\n        if ns_uris:\n            ont_metadata['preferred_namespace'] = str(ns_uris[0])\n    \n    # Detect which annotation properties are actually used (per Widoco guide)\n    label_props = []\n    desc_props = []\n    \n    # Check label properties\n    for label_prop in [RDFS.label, SKOS.prefLabel, SKOS.altLabel, DCTERMS.title, DC.title]:\n        if list(g.triples((None, label_prop, None))):\n            label_props.append(str(label_prop))\n    \n    # Check description properties\n    for desc_prop in [RDFS.comment, SKOS.definition, SKOS.note, SKOS.example, \n                      DCTERMS.description, DC.description]:\n        if list(g.triples((None, desc_prop, None))):\n            desc_props.append(str(desc_prop))\n    \n    # Build hierarchy (2 levels deep from roots)\n    hier = {}\n    for r in roots[:10]:  # Limit to first 10 roots\n        lbl = meta_obj.labels.get(r, r)\n        children = meta_obj.subs.get(r, [])\n        hier[lbl] = {\n            meta_obj.labels.get(c, c): [\n                meta_obj.labels.get(gc, gc) \n                for gc in meta_obj.subs.get(c, [])[:5]\n            ] \n            for c in children[:10]\n        }\n    \n    # Extract top properties with domains/ranges\n    top_props = []\n    for p in meta_obj.properties[:20]:\n        if p.startswith('http'):\n            prop_label = meta_obj.labels.get(p, p)\n            dom_uri = meta_obj.doms.get(p, '')\n            rng_uri = meta_obj.rngs.get(p, '')\n            dom_label = meta_obj.labels.get(dom_uri, dom_uri) if dom_uri else ''\n            rng_label = meta_obj.labels.get(rng_uri, rng_uri) if rng_uri else ''\n            top_props.append((prop_label, dom_label, rng_label))\n    \n    # Detect property characteristics (OWL axioms)\n    prop_chars = {}\n    for p in meta_obj.properties[:50]:\n        if p.startswith('http'):\n            chars = []\n            p_uri = URIRef(p)\n            \n            # Check for transitive\n            if list(g.triples((p_uri, RDF.type, OWL.TransitiveProperty))):\n                chars.append('transitive')\n            \n            # Check for symmetric\n            if list(g.triples((p_uri, RDF.type, OWL.SymmetricProperty))):\n                chars.append('symmetric')\n            \n            # Check for functional\n            if list(g.triples((p_uri, RDF.type, OWL.FunctionalProperty))):\n                chars.append('functional')\n            \n            # Check for inverse functional\n            if list(g.triples((p_uri, RDF.type, OWL.InverseFunctionalProperty))):\n                chars.append('inverse_functional')\n            \n            # Check for inverse\n            if list(g.triples((p_uri, OWL.inverseOf, None))):\n                chars.append('has_inverse')\n            \n            if chars:\n                prop_chars[p] = chars\n    \n    # Detect OWL constructs usage\n    owl_constructs = {\n        'restrictions': len(list(g.subjects(RDF.type, OWL.Restriction))),\n        'unions': len(list(g.subjects(OWL.unionOf, None))),\n        'intersections': len(list(g.subjects(OWL.intersectionOf, None))),\n        'disjointness': len(list(g.triples((None, OWL.disjointWith, None)))),\n        'equivalence': len(list(g.triples((None, OWL.equivalentClass, None))))\n    }\n    \n    # Get URI pattern samples\n    uri_sample = [c for c in meta_obj.classes[:5] if c.startswith('http')]\n    uri_pattern = uri_sample[0].rsplit('/', 1)[0] if uri_sample else ''\n    \n    # Build prompt for LLM synthesis\n    prompt = f\"\"\"Analyze this ontology and provide a sense document:\n\n**Ontology Metadata:**\n{ont_metadata}\n\n**Stats:** {len(meta_obj.classes)} classes, {len(meta_obj.properties)} properties, {len(meta_obj.labels)} labels\n\n**Annotation Properties Detected:**\n- Label properties: {label_props}\n- Description properties: {desc_props}\n\n**Structure:**\n- Prefixes: {list(metadata.prefixes.keys())[:10]}\n- Root classes: {[meta_obj.labels.get(r, r) for r in roots[:10]]}\n- Hierarchy (2 levels): {hier}\n\n**Properties:**\n- Top properties (label, domain, range): {top_props[:10]}\n- Property characteristics: {prop_chars}\n\n**OWL Constructs Usage:**\n{owl_constructs}\n\n**URI Pattern:** {uri_pattern}\n- Sample URIs: {uri_sample[:3]}\n\nProvide a concise sense document with:\n1) Domain/scope - what is this ontology about?\n2) Key branches - main conceptual areas in the hierarchy\n3) Important properties - key relationships to know\n4) Detected patterns - reification, measurement patterns, part-whole relationships, restriction patterns, etc.\n5) SPARQL navigation hints - how to effectively query this ontology given the annotation properties available\"\"\"\n    \n    # Use llm_query from rlm.core\n    from rlm.core import llm_query\n    summary = llm_query(prompt, ns=ns, name='_sense_summary')\n    \n    # Build structured sense document\n    sense_doc = AttrDict(\n        ont=ont_name,\n        ont_metadata=ont_metadata,\n        stats={'cls': len(meta_obj.classes), 'props': len(meta_obj.properties), 'lbls': len(meta_obj.labels)},\n        prefixes=metadata.prefixes,\n        label_properties=label_props,  # NEW: detected label properties\n        description_properties=desc_props,  # NEW: detected description properties\n        ann_preds=metadata.ann_preds,\n        roots=roots,\n        hier=hier,\n        top_props=top_props,\n        prop_chars=prop_chars,\n        owl_constructs=owl_constructs,  # NEW: OWL construct usage\n        uri_pattern=uri_pattern,\n        summary=ns['_sense_summary']\n    )\n    \n    ns[name] = sense_doc\n    return f\"Built sense document into '{name}': {len(label_props)} label properties, {len(desc_props)} description properties, {len(hier)} root branches\"",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "#| eval: false\n# Test build_sense with PROV ontology\n# Note: Requires API key, marked eval:false to avoid CI failures\n\ntest_ns = {}\nresult = build_sense('ontology/prov.ttl', name='prov_sense', ns=test_ns)\nprint(result)\nprint()\n\n# Inspect the sense document\nsense = test_ns['prov_sense']\nprint(f\"Ontology: {sense.ont}\")\nprint(f\"Ontology Metadata: {sense.ont_metadata}\")\nprint(f\"Stats: {sense.stats}\")\nprint()\n\n# NEW: Show detected annotation properties\nprint(f\"Label properties detected: {sense.label_properties}\")\nprint(f\"Description properties detected: {sense.description_properties}\")\nprint()\n\nprint(f\"Roots: {sense.roots}\")\nprint(f\"Root branches: {list(sense.hier.keys())}\")\nprint(f\"Top properties (first 3): {sense.top_props[:3]}\")\nprint(f\"Property characteristics: {sense.prop_chars}\")\nprint(f\"OWL constructs: {sense.owl_constructs}\")\nprint(f\"URI pattern: {sense.uri_pattern}\")\nprint()\nprint(\"LLM Summary:\")\nprint(sense.summary)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration with RLM\n",
    "\n",
    "Helper to setup ontology context for `rlm_run()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# NOTE: setup_ontology_context() is defined above in cell-27\n# This cell previously contained a duplicate definition"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test setup for RLM\n",
    "test_ns = {}\n",
    "result = setup_ontology_context('ontology/prov.ttl', test_ns, name='prov')\n",
    "print(result)\n",
    "print()\n",
    "print(\"Namespace contains:\")\n",
    "for k in test_ns.keys():\n",
    "    print(f\"  {k}: {type(test_ns[k]).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Test new exploration functions\n# Reuse the test_ns from previous cell with loaded prov ontology\n# Note: prov_meta is a GraphMeta object in test_ns\n\n# Test that new indexes work\nmeta = test_ns['prov_meta']\nassert len(meta.by_label) > 0  # inverted label index\nassert len(meta.subs) > 0 or len(meta.supers) > 0  # class hierarchy\nprint(f\"✓ New GraphMeta indexes work: by_label has {len(meta.by_label)} entries\")\n\n# Test ont_describe (need to pass GraphMeta object as namespace entry)\nresult = ont_describe('prov_meta', 'http://www.w3.org/ns/prov#Activity', name='activity_desc', ns=test_ns)\nassert 'activity_desc' in test_ns\nprint(f\"✓ ont_describe works: {result}\")\n\n# Test ont_meta  \nresult = ont_meta('prov_meta', name='prov_metadata', ns=test_ns)\nassert 'prov_metadata' in test_ns\nprint(f\"✓ ont_meta works: {result}\")\n\n# Test ont_roots\nresult = ont_roots('prov_meta', name='prov_roots', ns=test_ns)\nassert 'prov_roots' in test_ns\nprint(f\"✓ ont_roots works: {result}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with RLM\n",
    "\n",
    "Now let's test asking a question about the PROV ontology using `rlm_run()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from rlm.core import rlm_run\n",
    "\n",
    "# Setup namespace with PROV ontology\n",
    "ns = {}\n",
    "setup_ontology_context('ontology/prov.ttl', ns, name='prov')\n",
    "\n",
    "# Ask a question\n",
    "# The context is the GraphMeta summary, not the full graph\n",
    "context = ns['prov_meta'].summary()\n",
    "\n",
    "answer, iterations, ns = rlm_run(\n",
    "    \"What is the Activity class in the PROV ontology?\",\n",
    "    context,\n",
    "    ns=ns,\n",
    "    max_iters=3\n",
    ")\n",
    "\n",
    "print(f\"Answer: {answer}\")\n",
    "print(f\"Iterations: {len(iterations)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}