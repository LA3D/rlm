{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ontology\n",
    "\n",
    "> RDF ontology loading and meta-graph navigation for RLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ontology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This module implements Stage 1 of the trajectory: Define the Ontology \"Context Model\".\n",
    "\n",
    "### Design Principles\n",
    "\n",
    "- **Handles, not dumps**: Return graph handles with bounded view operations\n",
    "- **Meta-graph scaffolding**: Build navigation indexes (labels, hierarchy, properties)\n",
    "- **Progressive disclosure**: Small summaries guide exploration\n",
    "- **RLM-compatible**: Works with namespace-explicit `rlm_run()`\n",
    "\n",
    "### Context Model\n",
    "\n",
    "From the trajectory document:\n",
    "> The *root model never gets a graph dump*. It gets a handle name (e.g. `ont`, `res_0`) and uses bounded view operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#| export\nfrom rdflib import Graph, Namespace, RDF, RDFS, OWL, URIRef, Literal\nfrom pathlib import Path\nfrom collections import Counter, defaultdict\nfrom dataclasses import dataclass, field\nfrom fastcore.basics import AttrDict"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_ontology(path: str | Path, ns: dict, name: str = 'ont') -> str:\n",
    "    \"\"\"Load an RDF ontology file into namespace as a Graph handle.\n",
    "    \n",
    "    Args:\n",
    "        path: Path to ontology file (.ttl, .rdf, .owl)\n",
    "        ns: Namespace dict where Graph will be stored\n",
    "        name: Variable name for the Graph handle\n",
    "        \n",
    "    Returns:\n",
    "        Summary string describing what was loaded\n",
    "    \"\"\"\n",
    "    g = Graph()\n",
    "    g.parse(path)\n",
    "    ns[name] = g\n",
    "    \n",
    "    return f\"Loaded {len(g)} triples from {Path(path).name} into '{name}'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading prov.ttl\n",
    "test_ns = {}\n",
    "result = load_ontology('ontology/prov.ttl', test_ns, name='prov_ont')\n",
    "print(result)\n",
    "assert 'prov_ont' in test_ns\n",
    "assert isinstance(test_ns['prov_ont'], Graph)\n",
    "assert len(test_ns['prov_ont']) > 0\n",
    "print(f\"✓ Loaded {len(test_ns['prov_ont'])} triples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Graph Navigation\n",
    "\n",
    "Build navigation scaffolding from a Graph to enable progressive disclosure.\n",
    "This is what goes in the REPL environment, not the graph itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@dataclass\nclass GraphMeta:\n    \"\"\"Meta-graph navigation scaffolding for an RDF Graph.\n    \n    This is REPL-resident and provides bounded views over the graph.\n    Indexes discovered in dialogs/inspect_tools.ipynb exploration.\n    \"\"\"\n    graph: Graph\n    name: str = 'ont'\n    \n    # Computed lazily\n    _namespaces: dict = field(default=None, init=False, repr=False)\n    _classes: list = field(default=None, init=False, repr=False)\n    _properties: list = field(default=None, init=False, repr=False)\n    _individuals: list = field(default=None, init=False, repr=False)\n    _labels: dict = field(default=None, init=False, repr=False)\n    _by_label: dict = field(default=None, init=False, repr=False)\n    _subs: dict = field(default=None, init=False, repr=False)\n    _supers: dict = field(default=None, init=False, repr=False)\n    _doms: dict = field(default=None, init=False, repr=False)\n    _rngs: dict = field(default=None, init=False, repr=False)\n    \n    @property\n    def triple_count(self) -> int:\n        \"\"\"Total number of triples in graph.\"\"\"\n        return len(self.graph)\n    \n    @property\n    def namespaces(self) -> dict:\n        \"\"\"Get namespace prefix bindings.\"\"\"\n        if self._namespaces is None:\n            self._namespaces = {prefix: str(ns) for prefix, ns in self.graph.namespaces()}\n        return self._namespaces\n    \n    @property\n    def classes(self) -> list:\n        \"\"\"Get all OWL/RDFS classes (URIs only, sorted).\"\"\"\n        if self._classes is None:\n            classes = set(\n                self.graph.subjects(RDF.type, OWL.Class)\n            ).union(\n                self.graph.subjects(RDF.type, RDFS.Class)\n            )\n            self._classes = sorted([str(c) for c in classes])\n        return self._classes\n    \n    @property\n    def properties(self) -> list:\n        \"\"\"Get all properties (URIs only, sorted).\"\"\"\n        if self._properties is None:\n            props = set(\n                self.graph.subjects(RDF.type, OWL.ObjectProperty)\n            ).union(\n                self.graph.subjects(RDF.type, OWL.DatatypeProperty)\n            ).union(\n                self.graph.subjects(RDF.type, OWL.AnnotationProperty)\n            ).union(\n                self.graph.subjects(RDF.type, RDF.Property)\n            )\n            self._properties = sorted([str(p) for p in props])\n        return self._properties\n    \n    @property\n    def individuals(self) -> list:\n        \"\"\"Get all named individuals (URIs only, sorted).\"\"\"\n        if self._individuals is None:\n            inds = set(self.graph.subjects(RDF.type, OWL.NamedIndividual))\n            self._individuals = sorted([str(i) for i in inds])\n        return self._individuals\n    \n    @property\n    def labels(self) -> dict:\n        \"\"\"Get label index: URI -> label string.\"\"\"\n        if self._labels is None:\n            self._labels = {}\n            for s, o in self.graph.subject_objects(RDFS.label):\n                self._labels[str(s)] = str(o)\n        return self._labels\n    \n    @property\n    def by_label(self) -> dict:\n        \"\"\"Get inverted label index: label_text -> list of URIs.\"\"\"\n        if self._by_label is None:\n            inv = defaultdict(list)\n            for uri, lbl in self.labels.items():\n                inv[lbl.lower()].append(uri)\n            self._by_label = dict(inv)\n        return self._by_label\n    \n    @property\n    def subs(self) -> dict:\n        \"\"\"Get subclass relationships: superclass_uri -> list of subclass_uris.\"\"\"\n        if self._subs is None:\n            subs_dict = defaultdict(list)\n            for s, _, o in self.graph.triples((None, RDFS.subClassOf, None)):\n                if isinstance(o, URIRef):\n                    subs_dict[str(o)].append(str(s))\n            self._subs = dict(subs_dict)\n        return self._subs\n    \n    @property\n    def supers(self) -> dict:\n        \"\"\"Get superclass relationships: subclass_uri -> list of superclass_uris.\"\"\"\n        if self._supers is None:\n            supers_dict = defaultdict(list)\n            for s, _, o in self.graph.triples((None, RDFS.subClassOf, None)):\n                if isinstance(o, URIRef):\n                    supers_dict[str(s)].append(str(o))\n            self._supers = dict(supers_dict)\n        return self._supers\n    \n    @property\n    def doms(self) -> dict:\n        \"\"\"Get property domains: property_uri -> domain_uri.\"\"\"\n        if self._doms is None:\n            self._doms = {str(s): str(o) for s, _, o in self.graph.triples((None, RDFS.domain, None))}\n        return self._doms\n    \n    @property\n    def rngs(self) -> dict:\n        \"\"\"Get property ranges: property_uri -> range_uri.\"\"\"\n        if self._rngs is None:\n            self._rngs = {str(s): str(o) for s, _, o in self.graph.triples((None, RDFS.range, None))}\n        return self._rngs\n    \n    def summary(self) -> str:\n        \"\"\"Generate a summary of the graph for display.\"\"\"\n        lines = [\n            f\"Graph '{self.name}': {self.triple_count:,} triples\",\n            f\"Classes: {len(self.classes)}\",\n            f\"Properties: {len(self.properties)}\",\n            f\"Individuals: {len(self.individuals)}\",\n            f\"Namespaces: {', '.join(self.namespaces.keys())}\"\n        ]\n        return '\\n'.join(lines)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test GraphMeta with prov ontology\n",
    "prov_g = test_ns['prov_ont']\n",
    "meta = GraphMeta(prov_g, name='prov')\n",
    "\n",
    "print(meta.summary())\n",
    "print()\n",
    "print(f\"Sample classes (first 5): {meta.classes[:5]}\")\n",
    "print(f\"Sample properties (first 5): {meta.properties[:5]}\")\n",
    "print(f\"Namespaces: {list(meta.namespaces.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bounded View Functions\n",
    "\n",
    "These operate on GraphMeta and return small, bounded summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def graph_stats(meta: GraphMeta) -> str:\n",
    "    \"\"\"Get graph statistics summary.\"\"\"\n",
    "    return meta.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def search_by_label(meta: GraphMeta, search: str, limit: int = 10) -> list:\n",
    "    \"\"\"Search for entities by label substring (case-insensitive).\n",
    "    \n",
    "    Args:\n",
    "        meta: GraphMeta to search\n",
    "        search: Substring to search for in labels\n",
    "        limit: Maximum results to return\n",
    "        \n",
    "    Returns:\n",
    "        List of (URI, label) tuples\n",
    "    \"\"\"\n",
    "    search_lower = search.lower()\n",
    "    matches = [\n",
    "        (uri, label) \n",
    "        for uri, label in meta.labels.items()\n",
    "        if search_lower in label.lower()\n",
    "    ]\n",
    "    return matches[:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test search_by_label\n",
    "results = search_by_label(meta, 'activity', limit=5)\n",
    "print(f\"Found {len(results)} matches for 'activity':\")\n",
    "for uri, label in results:\n",
    "    print(f\"  {label}: {uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#| export\ndef describe_entity(meta: GraphMeta, uri: str, limit: int = 20) -> dict:\n    \"\"\"Get bounded description of an entity.\n    \n    Args:\n        meta: GraphMeta containing the entity\n        uri: URI of entity to describe\n        limit: Max number of triples to include\n        \n    Returns:\n        Dict with label, types, and sample triples\n    \"\"\"\n    from rdflib import URIRef\n    \n    entity = URIRef(uri)\n    \n    # Get label\n    label = meta.labels.get(uri, uri)\n    \n    # Get types\n    types = [str(t) for t in meta.graph.objects(entity, RDF.type)]\n    \n    # Get sample of outgoing triples\n    outgoing = []\n    for p, o in list(meta.graph.predicate_objects(entity))[:limit]:\n        outgoing.append((str(p), str(o)))\n    \n    # Get comment if available\n    comments = list(meta.graph.objects(entity, RDFS.comment))\n    comment = str(comments[0]) if comments else None\n    \n    return {\n        'uri': uri,\n        'label': label,\n        'types': types,\n        'comment': comment,\n        'outgoing_sample': outgoing[:limit]  # FIX: Use limit parameter, not hardcoded [:10]\n    }"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test describe_entity\n",
    "# Find the Activity class\n",
    "activity_uri = 'http://www.w3.org/ns/prov#Activity'\n",
    "desc = describe_entity(meta, activity_uri)\n",
    "\n",
    "print(f\"Label: {desc['label']}\")\n",
    "print(f\"Types: {desc['types']}\")\n",
    "print(f\"Comment: {desc['comment'][:100]}...\" if desc['comment'] else \"No comment\")\n",
    "print(f\"Outgoing triples: {len(desc['outgoing_sample'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Additional Exploration Functions\n\nFunctions discovered in `dialogs/inspect_tools.ipynb` for deeper ontology exploration.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "#| export\ndef ont_describe(ont: str, uri: str, name: str = 'desc', ns: dict = None) -> str:\n    \"\"\"Get all triples about a URI, store in namespace.\n    \n    Returns both triples where URI is subject and where it's object.\n    \n    Args:\n        ont: Name of ontology variable in namespace\n        uri: URI to describe\n        name: Variable name for storing result\n        ns: Namespace dict\n        \n    Returns:\n        Summary string\n    \"\"\"\n    if ns is None: ns = globals()\n    o = ns[ont]\n    u = URIRef(uri) if not isinstance(uri, URIRef) else uri\n    \n    # Get triples where URI is subject\n    subj_triples = [(str(s), str(p), str(obj)) for s, p, obj in o.graph.triples((u, None, None))]\n    \n    # Get triples where URI is object\n    obj_triples = [(str(s), str(p), str(obj)) for s, p, obj in o.graph.triples((None, None, u))]\n    \n    result = {\n        'as_subject': subj_triples,\n        'as_object': obj_triples\n    }\n    ns[name] = result\n    return f\"Stored {len(subj_triples)} + {len(obj_triples)} triples about '{uri}' into '{name}'\"",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "#| export\ndef ont_meta(ont: str, name: str = 'meta', ns: dict = None) -> str:\n    \"\"\"Extract ontology metadata (prefixes, annotation predicates, imports).\n    \n    Args:\n        ont: Name of ontology variable in namespace\n        name: Variable name for storing result\n        ns: Namespace dict\n        \n    Returns:\n        Summary string\n    \"\"\"\n    if ns is None: ns = globals()\n    o = ns[ont]\n    \n    prefixes = dict(o.graph.namespaces())\n    ann_preds = set(str(p) for s, p, obj in o.graph.triples((None, None, None)) if isinstance(obj, Literal))\n    imports = [str(obj) for s, p, obj in o.graph.triples((None, OWL.imports, None))]\n    \n    res = AttrDict(\n        prefixes=prefixes,\n        ann_preds=list(ann_preds)[:50],  # Limit to first 50\n        imports=imports\n    )\n    ns[name] = res\n    return f\"Stored metadata into '{name}': {len(prefixes)} prefixes, {len(ann_preds)} annotation predicates, {len(imports)} imports\"",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "#| export\ndef ont_roots(ont: str, name: str = 'roots', ns: dict = None) -> str:\n    \"\"\"Find root classes (no declared superclass), store in namespace.\n    \n    Args:\n        ont: Name of ontology variable in namespace\n        name: Variable name for storing result\n        ns: Namespace dict\n        \n    Returns:\n        Summary string\n    \"\"\"\n    if ns is None: ns = globals()\n    o = ns[ont]\n    \n    has_super = set(o.supers.keys())\n    roots = [str(c) for c in o.classes if str(c).startswith('http') and str(c) not in has_super]\n    \n    ns[name] = roots\n    return f\"Stored {len(roots)} root classes into '{name}'\"",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Ontology Sense Building\n\nBuild a structured \"sense document\" for an ontology - a summary that helps LLMs understand the ontology well enough to construct SPARQL queries and reason about knowledge graphs.\n\nThis uses a **workflow pattern** (not agentic): gather structure programmatically, then use one LLM call to synthesize findings.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "#| export\ndef build_sense(path: str, name: str = 'sense', ns: dict = None) -> str:\n    \"\"\"Build ontology sense document using workflow + LLM synthesis.\n    \n    This function:\n    1. Loads ontology and extracts metadata/roots programmatically\n    2. Builds hierarchy (2 levels), property info, characteristics\n    3. Makes one LLM call to synthesize domain/scope/patterns/hints\n    4. Returns structured AttrDict stored in namespace\n    \n    Args:\n        path: Path to ontology file\n        name: Variable name for sense document (default: 'sense')\n        ns: Namespace dict\n        \n    Returns:\n        Summary string\n    \"\"\"\n    if ns is None: ns = {}\n    \n    # Derive ontology name from sense name\n    ont_name = name.replace('_sense', '').replace('sense', 'ont')\n    \n    # Setup ontology context (loads graph + creates GraphMeta)\n    setup_ontology_context(path, ns, name=ont_name)\n    \n    # Get metadata and roots\n    ont_meta(f'{ont_name}_meta', name=f'{ont_name}_metadata', ns=ns)\n    ont_roots(f'{ont_name}_meta', name=f'{ont_name}_roots', ns=ns)\n    \n    # Get references\n    meta_obj = ns[f'{ont_name}_meta']\n    metadata = ns[f'{ont_name}_metadata']\n    roots = ns[f'{ont_name}_roots']\n    \n    # Build hierarchy (2 levels deep from roots)\n    hier = {}\n    for r in roots[:10]:  # Limit to first 10 roots\n        lbl = meta_obj.labels.get(r, r)\n        children = meta_obj.subs.get(r, [])\n        hier[lbl] = {\n            meta_obj.labels.get(c, c): [\n                meta_obj.labels.get(gc, gc) \n                for gc in meta_obj.subs.get(c, [])[:5]\n            ] \n            for c in children[:10]\n        }\n    \n    # Extract top properties with domains/ranges\n    top_props = []\n    for p in meta_obj.properties[:20]:\n        if p.startswith('http'):\n            prop_label = meta_obj.labels.get(p, p)\n            dom_uri = meta_obj.doms.get(p, '')\n            rng_uri = meta_obj.rngs.get(p, '')\n            dom_label = meta_obj.labels.get(dom_uri, dom_uri) if dom_uri else ''\n            rng_label = meta_obj.labels.get(rng_uri, rng_uri) if rng_uri else ''\n            top_props.append((prop_label, dom_label, rng_label))\n    \n    # Detect property characteristics (OWL axioms)\n    prop_chars = {}\n    for p in meta_obj.properties[:50]:\n        if p.startswith('http'):\n            chars = []\n            p_uri = URIRef(p)\n            \n            # Check for transitive\n            if list(meta_obj.graph.triples((p_uri, RDF.type, OWL.TransitiveProperty))):\n                chars.append('transitive')\n            \n            # Check for symmetric\n            if list(meta_obj.graph.triples((p_uri, RDF.type, OWL.SymmetricProperty))):\n                chars.append('symmetric')\n            \n            # Check for inverse\n            if list(meta_obj.graph.triples((p_uri, OWL.inverseOf, None))):\n                chars.append('has_inverse')\n            \n            if chars:\n                prop_chars[p] = chars\n    \n    # Get URI pattern samples\n    uri_sample = [c for c in meta_obj.classes[:5] if c.startswith('http')]\n    uri_pattern = uri_sample[0].rsplit('/', 1)[0] if uri_sample else ''\n    \n    # Build prompt for LLM synthesis\n    prompt = f\"\"\"Analyze this ontology and provide a sense document:\n\nStats: {len(meta_obj.classes)} classes, {len(meta_obj.properties)} properties, {len(meta_obj.labels)} labels\nPrefixes: {list(metadata.prefixes.keys())[:10]}\nAnnotation predicates: {metadata.ann_preds[:10]}\nRoot classes: {[meta_obj.labels.get(r, r) for r in roots[:10]]}\nHierarchy (2 levels): {hier}\nTop properties (label, domain, range): {top_props[:10]}\nProperty characteristics: {prop_chars}\nURI pattern examples: {uri_sample[:3]}\n\nProvide a concise sense document with:\n1. Domain/scope - what is this ontology about?\n2. Key branches - main conceptual areas in the hierarchy\n3. Important properties - key relationships to know\n4. Detected patterns - reification, measurement patterns, part-whole relationships, etc.\n5. SPARQL navigation hints - how to effectively query this ontology\"\"\"\n    \n    # Use llm_query from rlm.core (already in namespace from setup_ontology_context)\n    from rlm.core import llm_query\n    summary = llm_query(prompt, ns=ns, name='_sense_summary')\n    \n    # Build structured sense document\n    sense_doc = AttrDict(\n        ont=ont_name,\n        stats={'cls': len(meta_obj.classes), 'props': len(meta_obj.properties), 'lbls': len(meta_obj.labels)},\n        prefixes=metadata.prefixes,\n        ann_preds=metadata.ann_preds,\n        roots=roots,\n        hier=hier,\n        top_props=top_props,\n        prop_chars=prop_chars,\n        uri_pattern=uri_pattern,\n        summary=ns['_sense_summary']\n    )\n    \n    ns[name] = sense_doc\n    return f\"Built sense document into '{name}' with {len(hier)} root branches, {len(top_props)} properties\"",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "#| eval: false\n# Test build_sense with PROV ontology\n# Note: Requires API key, marked eval:false to avoid CI failures\n\ntest_ns = {}\nresult = build_sense('ontology/prov.ttl', name='prov_sense', ns=test_ns)\nprint(result)\nprint()\n\n# Inspect the sense document\nsense = test_ns['prov_sense']\nprint(f\"Ontology: {sense.ont}\")\nprint(f\"Stats: {sense.stats}\")\nprint(f\"Roots: {sense.roots}\")\nprint(f\"Root branches: {list(sense.hier.keys())}\")\nprint(f\"Top properties (first 3): {sense.top_props[:3]}\")\nprint(f\"Property characteristics: {sense.prop_chars}\")\nprint(f\"URI pattern: {sense.uri_pattern}\")\nprint()\nprint(\"LLM Summary:\")\nprint(sense.summary)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration with RLM\n",
    "\n",
    "Helper to setup ontology context for `rlm_run()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#| export\ndef setup_ontology_context(path: str | Path, ns: dict, name: str = 'ont') -> str:\n    \"\"\"Load ontology and create meta-graph for RLM use.\n    \n    This sets up both the Graph and GraphMeta in the namespace.\n    \n    Args:\n        path: Path to ontology file\n        ns: Namespace dict\n        name: Base name for graph handle\n        \n    Returns:\n        Summary string\n    \"\"\"\n    # Load graph\n    load_msg = load_ontology(path, ns, name=name)\n    \n    # Create meta-graph\n    g = ns[name]\n    meta = GraphMeta(g, name=name)\n    ns[f\"{name}_meta\"] = meta\n    \n    # FIX: Namespace helper functions by ontology name to avoid overwriting\n    # This allows multiple ontologies to coexist\n    from functools import partial\n    ns[f'{name}_graph_stats'] = partial(graph_stats, meta)\n    ns[f'{name}_search_by_label'] = partial(search_by_label, meta)\n    ns[f'{name}_describe_entity'] = partial(describe_entity, meta)\n    \n    # Also bind without prefix for single-ontology convenience\n    # (will be overwritten if multiple ontologies loaded, but prefixed versions persist)\n    ns['graph_stats'] = partial(graph_stats, meta)\n    ns['search_by_label'] = partial(search_by_label, meta)\n    ns['describe_entity'] = partial(describe_entity, meta)\n    \n    return f\"{load_msg}\\nCreated meta-graph '{name}_meta' with {len(meta.classes)} classes, {len(meta.properties)} properties\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test setup for RLM\n",
    "test_ns = {}\n",
    "result = setup_ontology_context('ontology/prov.ttl', test_ns, name='prov')\n",
    "print(result)\n",
    "print()\n",
    "print(\"Namespace contains:\")\n",
    "for k in test_ns.keys():\n",
    "    print(f\"  {k}: {type(test_ns[k]).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Test new exploration functions\n# Reuse the test_ns from previous cell with loaded prov ontology\n# Note: prov_meta is a GraphMeta object in test_ns\n\n# Test that new indexes work\nmeta = test_ns['prov_meta']\nassert len(meta.by_label) > 0  # inverted label index\nassert len(meta.subs) > 0 or len(meta.supers) > 0  # class hierarchy\nprint(f\"✓ New GraphMeta indexes work: by_label has {len(meta.by_label)} entries\")\n\n# Test ont_describe (need to pass GraphMeta object as namespace entry)\nresult = ont_describe('prov_meta', 'http://www.w3.org/ns/prov#Activity', name='activity_desc', ns=test_ns)\nassert 'activity_desc' in test_ns\nprint(f\"✓ ont_describe works: {result}\")\n\n# Test ont_meta  \nresult = ont_meta('prov_meta', name='prov_metadata', ns=test_ns)\nassert 'prov_metadata' in test_ns\nprint(f\"✓ ont_meta works: {result}\")\n\n# Test ont_roots\nresult = ont_roots('prov_meta', name='prov_roots', ns=test_ns)\nassert 'prov_roots' in test_ns\nprint(f\"✓ ont_roots works: {result}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with RLM\n",
    "\n",
    "Now let's test asking a question about the PROV ontology using `rlm_run()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from rlm.core import rlm_run\n",
    "\n",
    "# Setup namespace with PROV ontology\n",
    "ns = {}\n",
    "setup_ontology_context('ontology/prov.ttl', ns, name='prov')\n",
    "\n",
    "# Ask a question\n",
    "# The context is the GraphMeta summary, not the full graph\n",
    "context = ns['prov_meta'].summary()\n",
    "\n",
    "answer, iterations, ns = rlm_run(\n",
    "    \"What is the Activity class in the PROV ontology?\",\n",
    "    context,\n",
    "    ns=ns,\n",
    "    max_iters=3\n",
    ")\n",
    "\n",
    "print(f\"Answer: {answer}\")\n",
    "print(f\"Iterations: {len(iterations)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}