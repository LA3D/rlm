{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ontology\n",
    "\n",
    "> RDF ontology loading and meta-graph navigation for RLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ontology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This module implements Stage 1 of the trajectory: Define the Ontology \"Context Model\".\n",
    "\n",
    "### Design Principles\n",
    "\n",
    "- **Handles, not dumps**: Return graph handles with bounded view operations\n",
    "- **Meta-graph scaffolding**: Build navigation indexes (labels, hierarchy, properties)\n",
    "- **Progressive disclosure**: Small summaries guide exploration\n",
    "- **RLM-compatible**: Works with namespace-explicit `rlm_run()`\n",
    "\n",
    "### Context Model\n",
    "\n",
    "From the trajectory document:\n",
    "> The *root model never gets a graph dump*. It gets a handle name (e.g. `ont`, `res_0`) and uses bounded view operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#| export\nfrom rdflib import Graph, Namespace, RDF, RDFS, OWL, URIRef, Literal, SKOS, DCTERMS\nfrom pathlib import Path\nfrom collections import Counter, defaultdict\nfrom dataclasses import dataclass, field\nfrom fastcore.basics import AttrDict\n\n# Additional namespaces for ontology metadata (Widoco guide)\nVANN = Namespace('http://purl.org/vocab/vann/')\nDC = Namespace('http://purl.org/dc/elements/1.1/')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_ontology(path: str | Path, ns: dict, name: str = 'ont') -> str:\n",
    "    \"\"\"Load an RDF ontology file into namespace as a Graph handle.\n",
    "    \n",
    "    Args:\n",
    "        path: Path to ontology file (.ttl, .rdf, .owl)\n",
    "        ns: Namespace dict where Graph will be stored\n",
    "        name: Variable name for the Graph handle\n",
    "        \n",
    "    Returns:\n",
    "        Summary string describing what was loaded\n",
    "    \"\"\"\n",
    "    g = Graph()\n",
    "    g.parse(path)\n",
    "    ns[name] = g\n",
    "    \n",
    "    return f\"Loaded {len(g)} triples from {Path(path).name} into '{name}'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading prov.ttl\n",
    "test_ns = {}\n",
    "result = load_ontology('ontology/prov.ttl', test_ns, name='prov_ont')\n",
    "print(result)\n",
    "assert 'prov_ont' in test_ns\n",
    "assert isinstance(test_ns['prov_ont'], Graph)\n",
    "assert len(test_ns['prov_ont']) > 0\n",
    "print(f\"✓ Loaded {len(test_ns['prov_ont'])} triples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Graph Navigation\n",
    "\n",
    "Build navigation scaffolding from a Graph to enable progressive disclosure.\n",
    "This is what goes in the REPL environment, not the graph itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@dataclass\nclass GraphMeta:\n    \"\"\"Meta-graph navigation scaffolding for an RDF Graph.\n    \n    This is REPL-resident and provides bounded views over the graph.\n    Indexes discovered in dialogs/inspect_tools.ipynb exploration.\n    \"\"\"\n    graph: Graph\n    name: str = 'ont'\n    \n    # Computed lazily\n    _namespaces: dict = field(default=None, init=False, repr=False)\n    _classes: list = field(default=None, init=False, repr=False)\n    _properties: list = field(default=None, init=False, repr=False)\n    _individuals: list = field(default=None, init=False, repr=False)\n    _labels: dict = field(default=None, init=False, repr=False)\n    _by_label: dict = field(default=None, init=False, repr=False)\n    _subs: dict = field(default=None, init=False, repr=False)\n    _supers: dict = field(default=None, init=False, repr=False)\n    _doms: dict = field(default=None, init=False, repr=False)\n    _rngs: dict = field(default=None, init=False, repr=False)\n    \n    @property\n    def triple_count(self) -> int:\n        \"\"\"Total number of triples in graph.\"\"\"\n        return len(self.graph)\n    \n    @property\n    def namespaces(self) -> dict:\n        \"\"\"Get namespace prefix bindings.\"\"\"\n        if self._namespaces is None:\n            self._namespaces = {prefix: str(ns) for prefix, ns in self.graph.namespaces()}\n        return self._namespaces\n    \n    @property\n    def classes(self) -> list:\n        \"\"\"Get all OWL/RDFS classes (URIs only, sorted).\"\"\"\n        if self._classes is None:\n            classes = set(\n                self.graph.subjects(RDF.type, OWL.Class)\n            ).union(\n                self.graph.subjects(RDF.type, RDFS.Class)\n            )\n            self._classes = sorted([str(c) for c in classes])\n        return self._classes\n    \n    @property\n    def properties(self) -> list:\n        \"\"\"Get all properties (URIs only, sorted).\"\"\"\n        if self._properties is None:\n            props = set(\n                self.graph.subjects(RDF.type, OWL.ObjectProperty)\n            ).union(\n                self.graph.subjects(RDF.type, OWL.DatatypeProperty)\n            ).union(\n                self.graph.subjects(RDF.type, OWL.AnnotationProperty)\n            ).union(\n                self.graph.subjects(RDF.type, RDF.Property)\n            )\n            self._properties = sorted([str(p) for p in props])\n        return self._properties\n    \n    @property\n    def individuals(self) -> list:\n        \"\"\"Get all named individuals (URIs only, sorted).\"\"\"\n        if self._individuals is None:\n            inds = set(self.graph.subjects(RDF.type, OWL.NamedIndividual))\n            self._individuals = sorted([str(i) for i in inds])\n        return self._individuals\n    \n    @property\n    def labels(self) -> dict:\n        \"\"\"Get label index: URI -> label string.\"\"\"\n        if self._labels is None:\n            self._labels = {}\n            for s, o in self.graph.subject_objects(RDFS.label):\n                self._labels[str(s)] = str(o)\n        return self._labels\n    \n    @property\n    def by_label(self) -> dict:\n        \"\"\"Get inverted label index: label_text -> list of URIs.\"\"\"\n        if self._by_label is None:\n            inv = defaultdict(list)\n            for uri, lbl in self.labels.items():\n                inv[lbl.lower()].append(uri)\n            self._by_label = dict(inv)\n        return self._by_label\n    \n    @property\n    def subs(self) -> dict:\n        \"\"\"Get subclass relationships: superclass_uri -> list of subclass_uris.\"\"\"\n        if self._subs is None:\n            subs_dict = defaultdict(list)\n            for s, _, o in self.graph.triples((None, RDFS.subClassOf, None)):\n                if isinstance(o, URIRef):\n                    subs_dict[str(o)].append(str(s))\n            self._subs = dict(subs_dict)\n        return self._subs\n    \n    @property\n    def supers(self) -> dict:\n        \"\"\"Get superclass relationships: subclass_uri -> list of superclass_uris.\"\"\"\n        if self._supers is None:\n            supers_dict = defaultdict(list)\n            for s, _, o in self.graph.triples((None, RDFS.subClassOf, None)):\n                if isinstance(o, URIRef):\n                    supers_dict[str(s)].append(str(o))\n            self._supers = dict(supers_dict)\n        return self._supers\n    \n    @property\n    def doms(self) -> dict:\n        \"\"\"Get property domains: property_uri -> domain_uri.\"\"\"\n        if self._doms is None:\n            self._doms = {str(s): str(o) for s, _, o in self.graph.triples((None, RDFS.domain, None))}\n        return self._doms\n    \n    @property\n    def rngs(self) -> dict:\n        \"\"\"Get property ranges: property_uri -> range_uri.\"\"\"\n        if self._rngs is None:\n            self._rngs = {str(s): str(o) for s, _, o in self.graph.triples((None, RDFS.range, None))}\n        return self._rngs\n    \n    def summary(self) -> str:\n        \"\"\"Generate a summary of the graph for display.\"\"\"\n        lines = [\n            f\"Graph '{self.name}': {self.triple_count:,} triples\",\n            f\"Classes: {len(self.classes)}\",\n            f\"Properties: {len(self.properties)}\",\n            f\"Individuals: {len(self.individuals)}\",\n            f\"Namespaces: {', '.join(self.namespaces.keys())}\"\n        ]\n        return '\\n'.join(lines)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test GraphMeta with prov ontology\n",
    "prov_g = test_ns['prov_ont']\n",
    "meta = GraphMeta(prov_g, name='prov')\n",
    "\n",
    "print(meta.summary())\n",
    "print()\n",
    "print(f\"Sample classes (first 5): {meta.classes[:5]}\")\n",
    "print(f\"Sample properties (first 5): {meta.properties[:5]}\")\n",
    "print(f\"Namespaces: {list(meta.namespaces.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bounded View Functions\n",
    "\n",
    "These operate on GraphMeta and return small, bounded summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def graph_stats(meta: GraphMeta) -> str:\n",
    "    \"\"\"Get graph statistics summary.\"\"\"\n",
    "    return meta.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def search_by_label(meta: GraphMeta, search: str, limit: int = 10) -> list:\n",
    "    \"\"\"Search for entities by label substring (case-insensitive).\n",
    "    \n",
    "    Args:\n",
    "        meta: GraphMeta to search\n",
    "        search: Substring to search for in labels\n",
    "        limit: Maximum results to return\n",
    "        \n",
    "    Returns:\n",
    "        List of (URI, label) tuples\n",
    "    \"\"\"\n",
    "    search_lower = search.lower()\n",
    "    matches = [\n",
    "        (uri, label) \n",
    "        for uri, label in meta.labels.items()\n",
    "        if search_lower in label.lower()\n",
    "    ]\n",
    "    return matches[:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test search_by_label\n",
    "results = search_by_label(meta, 'activity', limit=5)\n",
    "print(f\"Found {len(results)} matches for 'activity':\")\n",
    "for uri, label in results:\n",
    "    print(f\"  {label}: {uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#| export\ndef describe_entity(meta: GraphMeta, uri: str, limit: int = 20) -> dict:\n    \"\"\"Get bounded description of an entity.\n    \n    Args:\n        meta: GraphMeta containing the entity\n        uri: URI of entity to describe\n        limit: Max number of triples to include\n        \n    Returns:\n        Dict with label, types, and sample triples\n    \"\"\"\n    from rdflib import URIRef\n    \n    entity = URIRef(uri)\n    \n    # Get label\n    label = meta.labels.get(uri, uri)\n    \n    # Get types\n    types = [str(t) for t in meta.graph.objects(entity, RDF.type)]\n    \n    # Get sample of outgoing triples\n    outgoing = []\n    for p, o in list(meta.graph.predicate_objects(entity))[:limit]:\n        outgoing.append((str(p), str(o)))\n    \n    # Get comment if available\n    comments = list(meta.graph.objects(entity, RDFS.comment))\n    comment = str(comments[0]) if comments else None\n    \n    return {\n        'uri': uri,\n        'label': label,\n        'types': types,\n        'comment': comment,\n        'outgoing_sample': outgoing[:limit]  # FIX: Use limit parameter, not hardcoded [:10]\n    }"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test describe_entity\n",
    "# Find the Activity class\n",
    "activity_uri = 'http://www.w3.org/ns/prov#Activity'\n",
    "desc = describe_entity(meta, activity_uri)\n",
    "\n",
    "print(f\"Label: {desc['label']}\")\n",
    "print(f\"Types: {desc['types']}\")\n",
    "print(f\"Comment: {desc['comment'][:100]}...\" if desc['comment'] else \"No comment\")\n",
    "print(f\"Outgoing triples: {len(desc['outgoing_sample'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Additional Exploration Functions\n\nFunctions discovered in `dialogs/inspect_tools.ipynb` for deeper ontology exploration.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "#| export\ndef ont_describe(ont: str, uri: str, name: str = 'desc', ns: dict = None) -> str:\n    \"\"\"Get all triples about a URI, store in namespace.\n    \n    Returns both triples where URI is subject and where it's object.\n    \n    Args:\n        ont: Name of ontology variable in namespace\n        uri: URI to describe\n        name: Variable name for storing result\n        ns: Namespace dict\n        \n    Returns:\n        Summary string\n    \"\"\"\n    if ns is None: ns = globals()\n    o = ns[ont]\n    u = URIRef(uri) if not isinstance(uri, URIRef) else uri\n    \n    # Get triples where URI is subject\n    subj_triples = [(str(s), str(p), str(obj)) for s, p, obj in o.graph.triples((u, None, None))]\n    \n    # Get triples where URI is object\n    obj_triples = [(str(s), str(p), str(obj)) for s, p, obj in o.graph.triples((None, None, u))]\n    \n    result = {\n        'as_subject': subj_triples,\n        'as_object': obj_triples\n    }\n    ns[name] = result\n    return f\"Stored {len(subj_triples)} + {len(obj_triples)} triples about '{uri}' into '{name}'\"",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "#| export\ndef ont_meta(ont: str, name: str = 'meta', ns: dict = None) -> str:\n    \"\"\"Extract ontology metadata (prefixes, annotation predicates, imports).\n    \n    Args:\n        ont: Name of ontology variable in namespace\n        name: Variable name for storing result\n        ns: Namespace dict\n        \n    Returns:\n        Summary string\n    \"\"\"\n    if ns is None: ns = globals()\n    o = ns[ont]\n    \n    prefixes = dict(o.graph.namespaces())\n    ann_preds = set(str(p) for s, p, obj in o.graph.triples((None, None, None)) if isinstance(obj, Literal))\n    imports = [str(obj) for s, p, obj in o.graph.triples((None, OWL.imports, None))]\n    \n    res = AttrDict(\n        prefixes=prefixes,\n        ann_preds=list(ann_preds)[:50],  # Limit to first 50\n        imports=imports\n    )\n    ns[name] = res\n    return f\"Stored metadata into '{name}': {len(prefixes)} prefixes, {len(ann_preds)} annotation predicates, {len(imports)} imports\"",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "#| export\ndef ont_roots(ont: str, name: str = 'roots', ns: dict = None) -> str:\n    \"\"\"Find root classes (no declared superclass), store in namespace.\n    \n    Args:\n        ont: Name of ontology variable in namespace\n        name: Variable name for storing result\n        ns: Namespace dict\n        \n    Returns:\n        Summary string\n    \"\"\"\n    if ns is None: ns = globals()\n    o = ns[ont]\n    \n    has_super = set(o.supers.keys())\n    roots = [str(c) for c in o.classes if str(c).startswith('http') and str(c) not in has_super]\n    \n    ns[name] = roots\n    return f\"Stored {len(roots)} root classes into '{name}'\"",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Ontology Sense Building\n\n### What is a \"Sense Document\"?\n\nWhen an LLM needs to work with an ontology, loading the entire graph into context is wasteful and may exceed limits. Instead, we build a **sense document** - a compact summary that captures:\n\n- **Formalism**: Which OWL/RDFS/SKOS constructs are used\n- **Metadata structure**: Which annotation properties exist (labels, descriptions, etc.)\n- **Domain/scope**: What the ontology is about\n- **Navigation hints**: How to effectively search and traverse\n\nThis approach was developed through experiments in `dialogs/inspect_tools.ipynb` exploring progressive disclosure patterns.\n\n### Why Sense Building Matters\n\n**Design Decision Response** (from ISSUE_ANALYSIS.md):\n> *GraphMeta.labels only uses rdfs:label* - This is a limitation because different ontologies use different annotation properties:\n> - `rdfs:label`, `skos:prefLabel`, `skos:altLabel` for labels\n> - `rdfs:comment`, `skos:definition`, `dcterms:description` for descriptions  \n> - `vann:preferredNamespacePrefix`, `owl:versionInfo` for metadata\n\nRather than hardcode support for all possible properties, `build_sense()` **detects which annotation properties this specific ontology uses**, enabling intelligent search.\n\n### References\n\n- [Widoco Metadata Guide](https://github.com/dgarijo/Widoco/blob/master/doc/metadataGuide/guide.md) - Recommended ontology metadata properties\n- [Anthropic: Building Effective Agents](https://www.anthropic.com/engineering/building-effective-agents) - Orchestrator-workers pattern\n- [Anthropic: Progressive Disclosure](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents) - Context engineering strategy\n\n### Implementation Pattern\n\nThe sense-building workflow (not agentic):\n1. **Metadata collection** - Extract prefixes, detect annotation predicates, find ontology-level metadata\n2. **Structural exploration** - Build hierarchy, property signatures, detect OWL axioms\n3. **LLM synthesis** - One LLM call to identify domain, patterns, navigation hints\n4. **Structured storage** - Store as retrievable AttrDict in REPL namespace",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "#| export\ndef build_sense(path: str, name: str = 'sense', ns: dict = None) -> str:\n    \"\"\"Build ontology sense document using workflow + LLM synthesis.\n    \n    Detects annotation properties per Widoco metadata guide:\n    - Label properties: rdfs:label, skos:prefLabel, skos:altLabel, dcterms:title\n    - Description properties: rdfs:comment, skos:definition, dcterms:description\n    - Ontology metadata: vann:preferredNamespacePrefix, owl:versionInfo, etc.\n    \n    This function:\n    1. Loads ontology and extracts metadata/roots programmatically\n    2. Detects which annotation properties are actually used\n    3. Builds hierarchy (2 levels), property info, characteristics\n    4. Makes one LLM call to synthesize domain/scope/patterns/hints\n    5. Returns structured AttrDict stored in namespace\n    \n    Args:\n        path: Path to ontology file\n        name: Variable name for sense document (default: 'sense')\n        ns: Namespace dict\n        \n    Returns:\n        Summary string\n    \"\"\"\n    if ns is None: ns = {}\n    \n    # Derive ontology name from sense name\n    ont_name = name.replace('_sense', '').replace('sense', 'ont')\n    \n    # Setup ontology context (loads graph + creates GraphMeta)\n    setup_ontology_context(path, ns, name=ont_name)\n    \n    # Get metadata and roots\n    ont_meta(f'{ont_name}_meta', name=f'{ont_name}_metadata', ns=ns)\n    ont_roots(f'{ont_name}_meta', name=f'{ont_name}_roots', ns=ns)\n    \n    # Get references\n    meta_obj = ns[f'{ont_name}_meta']\n    metadata = ns[f'{ont_name}_metadata']\n    roots = ns[f'{ont_name}_roots']\n    g = meta_obj.graph\n    \n    # Detect ontology-level metadata (Widoco guide properties)\n    ont_uri = None\n    for s in g.subjects(RDF.type, OWL.Ontology):\n        ont_uri = str(s)\n        break\n    \n    ont_metadata = {}\n    if ont_uri:\n        ont_ref = URIRef(ont_uri)\n        ont_metadata['uri'] = ont_uri\n        \n        # Title/label\n        for title_prop in [DCTERMS.title, DC.title, RDFS.label]:\n            titles = list(g.objects(ont_ref, title_prop))\n            if titles:\n                ont_metadata['title'] = str(titles[0])\n                break\n        \n        # Description\n        for desc_prop in [DCTERMS.description, DC.description, RDFS.comment]:\n            descs = list(g.objects(ont_ref, desc_prop))\n            if descs:\n                ont_metadata['description'] = str(descs[0])\n                break\n        \n        # Version info\n        versions = list(g.objects(ont_ref, OWL.versionInfo))\n        if versions:\n            ont_metadata['version'] = str(versions[0])\n        \n        # Preferred namespace prefix\n        prefixes = list(g.objects(ont_ref, VANN.preferredNamespacePrefix))\n        if prefixes:\n            ont_metadata['preferred_prefix'] = str(prefixes[0])\n        \n        # Preferred namespace URI\n        ns_uris = list(g.objects(ont_ref, VANN.preferredNamespaceUri))\n        if ns_uris:\n            ont_metadata['preferred_namespace'] = str(ns_uris[0])\n    \n    # Detect which annotation properties are actually used (per Widoco guide)\n    label_props = []\n    desc_props = []\n    \n    # Check label properties\n    for label_prop in [RDFS.label, SKOS.prefLabel, SKOS.altLabel, DCTERMS.title, DC.title]:\n        if list(g.triples((None, label_prop, None))):\n            label_props.append(str(label_prop))\n    \n    # Check description properties\n    for desc_prop in [RDFS.comment, SKOS.definition, SKOS.note, SKOS.example, \n                      DCTERMS.description, DC.description]:\n        if list(g.triples((None, desc_prop, None))):\n            desc_props.append(str(desc_prop))\n    \n    # Build hierarchy (2 levels deep from roots)\n    hier = {}\n    for r in roots[:10]:  # Limit to first 10 roots\n        lbl = meta_obj.labels.get(r, r)\n        children = meta_obj.subs.get(r, [])\n        hier[lbl] = {\n            meta_obj.labels.get(c, c): [\n                meta_obj.labels.get(gc, gc) \n                for gc in meta_obj.subs.get(c, [])[:5]\n            ] \n            for c in children[:10]\n        }\n    \n    # Extract top properties with domains/ranges\n    top_props = []\n    for p in meta_obj.properties[:20]:\n        if p.startswith('http'):\n            prop_label = meta_obj.labels.get(p, p)\n            dom_uri = meta_obj.doms.get(p, '')\n            rng_uri = meta_obj.rngs.get(p, '')\n            dom_label = meta_obj.labels.get(dom_uri, dom_uri) if dom_uri else ''\n            rng_label = meta_obj.labels.get(rng_uri, rng_uri) if rng_uri else ''\n            top_props.append((prop_label, dom_label, rng_label))\n    \n    # Detect property characteristics (OWL axioms)\n    prop_chars = {}\n    for p in meta_obj.properties[:50]:\n        if p.startswith('http'):\n            chars = []\n            p_uri = URIRef(p)\n            \n            # Check for transitive\n            if list(g.triples((p_uri, RDF.type, OWL.TransitiveProperty))):\n                chars.append('transitive')\n            \n            # Check for symmetric\n            if list(g.triples((p_uri, RDF.type, OWL.SymmetricProperty))):\n                chars.append('symmetric')\n            \n            # Check for functional\n            if list(g.triples((p_uri, RDF.type, OWL.FunctionalProperty))):\n                chars.append('functional')\n            \n            # Check for inverse functional\n            if list(g.triples((p_uri, RDF.type, OWL.InverseFunctionalProperty))):\n                chars.append('inverse_functional')\n            \n            # Check for inverse\n            if list(g.triples((p_uri, OWL.inverseOf, None))):\n                chars.append('has_inverse')\n            \n            if chars:\n                prop_chars[p] = chars\n    \n    # Detect OWL constructs usage\n    owl_constructs = {\n        'restrictions': len(list(g.subjects(RDF.type, OWL.Restriction))),\n        'unions': len(list(g.subjects(OWL.unionOf, None))),\n        'intersections': len(list(g.subjects(OWL.intersectionOf, None))),\n        'disjointness': len(list(g.triples((None, OWL.disjointWith, None)))),\n        'equivalence': len(list(g.triples((None, OWL.equivalentClass, None))))\n    }\n    \n    # Get URI pattern samples\n    uri_sample = [c for c in meta_obj.classes[:5] if c.startswith('http')]\n    uri_pattern = uri_sample[0].rsplit('/', 1)[0] if uri_sample else ''\n    \n    # Build prompt for LLM synthesis\n    prompt = f\"\"\"Analyze this ontology and provide a sense document:\n\n**Ontology Metadata:**\n{ont_metadata}\n\n**Stats:** {len(meta_obj.classes)} classes, {len(meta_obj.properties)} properties, {len(meta_obj.labels)} labels\n\n**Annotation Properties Detected:**\n- Label properties: {label_props}\n- Description properties: {desc_props}\n\n**Structure:**\n- Prefixes: {list(metadata.prefixes.keys())[:10]}\n- Root classes: {[meta_obj.labels.get(r, r) for r in roots[:10]]}\n- Hierarchy (2 levels): {hier}\n\n**Properties:**\n- Top properties (label, domain, range): {top_props[:10]}\n- Property characteristics: {prop_chars}\n\n**OWL Constructs Usage:**\n{owl_constructs}\n\n**URI Pattern:** {uri_pattern}\n- Sample URIs: {uri_sample[:3]}\n\nProvide a concise sense document with:\n1) Domain/scope - what is this ontology about?\n2) Key branches - main conceptual areas in the hierarchy\n3) Important properties - key relationships to know\n4) Detected patterns - reification, measurement patterns, part-whole relationships, restriction patterns, etc.\n5) SPARQL navigation hints - how to effectively query this ontology given the annotation properties available\"\"\"\n    \n    # Use llm_query from rlm.core\n    from rlm.core import llm_query\n    summary = llm_query(prompt, ns=ns, name='_sense_summary')\n    \n    # Build structured sense document\n    sense_doc = AttrDict(\n        ont=ont_name,\n        ont_metadata=ont_metadata,\n        stats={'cls': len(meta_obj.classes), 'props': len(meta_obj.properties), 'lbls': len(meta_obj.labels)},\n        prefixes=metadata.prefixes,\n        label_properties=label_props,  # NEW: detected label properties\n        description_properties=desc_props,  # NEW: detected description properties\n        ann_preds=metadata.ann_preds,\n        roots=roots,\n        hier=hier,\n        top_props=top_props,\n        prop_chars=prop_chars,\n        owl_constructs=owl_constructs,  # NEW: OWL construct usage\n        uri_pattern=uri_pattern,\n        summary=ns['_sense_summary']\n    )\n    \n    ns[name] = sense_doc\n    return f\"Built sense document into '{name}': {len(label_props)} label properties, {len(desc_props)} description properties, {len(hier)} root branches\"",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "#| eval: false\n# Test build_sense with PROV ontology\n# Note: Requires API key, marked eval:false to avoid CI failures\n\ntest_ns = {}\nresult = build_sense('ontology/prov.ttl', name='prov_sense', ns=test_ns)\nprint(result)\nprint()\n\n# Inspect the sense document\nsense = test_ns['prov_sense']\nprint(f\"Ontology: {sense.ont}\")\nprint(f\"Ontology Metadata: {sense.ont_metadata}\")\nprint(f\"Stats: {sense.stats}\")\nprint()\n\n# NEW: Show detected annotation properties\nprint(f\"Label properties detected: {sense.label_properties}\")\nprint(f\"Description properties detected: {sense.description_properties}\")\nprint()\n\nprint(f\"Roots: {sense.roots}\")\nprint(f\"Root branches: {list(sense.hier.keys())}\")\nprint(f\"Top properties (first 3): {sense.top_props[:3]}\")\nprint(f\"Property characteristics: {sense.prop_chars}\")\nprint(f\"OWL constructs: {sense.owl_constructs}\")\nprint(f\"URI pattern: {sense.uri_pattern}\")\nprint()\nprint(\"LLM Summary:\")\nprint(sense.summary)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration with RLM\n",
    "\n",
    "Helper to setup ontology context for `rlm_run()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#| export\ndef setup_ontology_context(path: str | Path, ns: dict, name: str = 'ont') -> str:\n    \"\"\"Load ontology and create meta-graph for RLM use.\n    \n    This sets up both the Graph and GraphMeta in the namespace.\n    \n    Args:\n        path: Path to ontology file\n        ns: Namespace dict\n        name: Base name for graph handle\n        \n    Returns:\n        Summary string\n    \"\"\"\n    # Load graph\n    load_msg = load_ontology(path, ns, name=name)\n    \n    # Create meta-graph\n    g = ns[name]\n    meta = GraphMeta(g, name=name)\n    ns[f\"{name}_meta\"] = meta\n    \n    # FIX: Namespace helper functions by ontology name to avoid overwriting\n    # This allows multiple ontologies to coexist\n    from functools import partial\n    ns[f'{name}_graph_stats'] = partial(graph_stats, meta)\n    ns[f'{name}_search_by_label'] = partial(search_by_label, meta)\n    ns[f'{name}_describe_entity'] = partial(describe_entity, meta)\n    \n    # Also bind without prefix for single-ontology convenience\n    # (will be overwritten if multiple ontologies loaded, but prefixed versions persist)\n    ns['graph_stats'] = partial(graph_stats, meta)\n    ns['search_by_label'] = partial(search_by_label, meta)\n    ns['describe_entity'] = partial(describe_entity, meta)\n    \n    return f\"{load_msg}\\nCreated meta-graph '{name}_meta' with {len(meta.classes)} classes, {len(meta.properties)} properties\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test setup for RLM\n",
    "test_ns = {}\n",
    "result = setup_ontology_context('ontology/prov.ttl', test_ns, name='prov')\n",
    "print(result)\n",
    "print()\n",
    "print(\"Namespace contains:\")\n",
    "for k in test_ns.keys():\n",
    "    print(f\"  {k}: {type(test_ns[k]).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Test new exploration functions\n# Reuse the test_ns from previous cell with loaded prov ontology\n# Note: prov_meta is a GraphMeta object in test_ns\n\n# Test that new indexes work\nmeta = test_ns['prov_meta']\nassert len(meta.by_label) > 0  # inverted label index\nassert len(meta.subs) > 0 or len(meta.supers) > 0  # class hierarchy\nprint(f\"✓ New GraphMeta indexes work: by_label has {len(meta.by_label)} entries\")\n\n# Test ont_describe (need to pass GraphMeta object as namespace entry)\nresult = ont_describe('prov_meta', 'http://www.w3.org/ns/prov#Activity', name='activity_desc', ns=test_ns)\nassert 'activity_desc' in test_ns\nprint(f\"✓ ont_describe works: {result}\")\n\n# Test ont_meta  \nresult = ont_meta('prov_meta', name='prov_metadata', ns=test_ns)\nassert 'prov_metadata' in test_ns\nprint(f\"✓ ont_meta works: {result}\")\n\n# Test ont_roots\nresult = ont_roots('prov_meta', name='prov_roots', ns=test_ns)\nassert 'prov_roots' in test_ns\nprint(f\"✓ ont_roots works: {result}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with RLM\n",
    "\n",
    "Now let's test asking a question about the PROV ontology using `rlm_run()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from rlm.core import rlm_run\n",
    "\n",
    "# Setup namespace with PROV ontology\n",
    "ns = {}\n",
    "setup_ontology_context('ontology/prov.ttl', ns, name='prov')\n",
    "\n",
    "# Ask a question\n",
    "# The context is the GraphMeta summary, not the full graph\n",
    "context = ns['prov_meta'].summary()\n",
    "\n",
    "answer, iterations, ns = rlm_run(\n",
    "    \"What is the Activity class in the PROV ontology?\",\n",
    "    context,\n",
    "    ns=ns,\n",
    "    max_iters=3\n",
    ")\n",
    "\n",
    "print(f\"Answer: {answer}\")\n",
    "print(f\"Iterations: {len(iterations)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}