"""ReasoningBank-style procedural memory for RLM"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/05_procedural_memory.ipynb.

# %% auto #0
__all__ = ['MemoryItem', 'MemoryStore', 'extract_trajectory_artifact', 'judge_trajectory', 'extract_memories',
           'retrieve_memories', 'format_memories_for_injection', 'rlm_run_with_memory', 'bootstrap_general_strategies',
           'validate_no_hardcoded_uris', 'validate_bootstrap_strategies', 'check_memory_deduplication',
           'score_generalization', 'validate_retrieval_quality']

# %% ../nbs/05_procedural_memory.ipynb #a53b4e66
from dataclasses import dataclass, field, asdict
from typing import Optional
from pathlib import Path
from datetime import datetime, timezone
import json
import uuid
from rank_bm25 import BM25Okapi

# %% ../nbs/05_procedural_memory.ipynb #f02e3b5c
from .core import llm_query, rlm_run
from ._rlmpaper_compat import RLMIteration

# %% ../nbs/05_procedural_memory.ipynb #efc33a90
@dataclass
class MemoryItem:
    """A reusable procedural memory extracted from an RLM trajectory.
    
    Attributes:
        id: Unique identifier (UUID)
        title: Concise identifier (≤10 words)
        description: One-sentence summary
        content: Procedural steps/checklist/template (Markdown)
        source_type: 'success' or 'failure'
        task_query: Original task that produced this memory
        created_at: ISO timestamp
        access_count: Number of times retrieved (for future consolidation)
        tags: Keywords for BM25 retrieval
        session_id: Optional session ID from DatasetMeta (links to dataset session)
    """
    id: str
    title: str
    description: str
    content: str
    source_type: str  # 'success' or 'failure'
    task_query: str
    created_at: str
    access_count: int = 0
    tags: Optional[list[str]] = None
    session_id: Optional[str] = None  # NEW: Links to DatasetMeta.session_id
    
    def to_dict(self) -> dict:
        """Convert to dictionary for JSON serialization."""
        return asdict(self)
    
    @classmethod
    def from_dict(cls, data: dict) -> 'MemoryItem':
        """Create MemoryItem from dictionary."""
        return cls(**data)

# %% ../nbs/05_procedural_memory.ipynb #54b28490
@dataclass
class MemoryStore:
    """Persistent storage for procedural memories.
    
    Attributes:
        memories: List of MemoryItem objects
        path: Path to JSON file
    """
    memories: list[MemoryItem] = field(default_factory=list)
    path: Optional[Path] = None
    
    def add(self, item: MemoryItem) -> str:
        """Add a memory item to the store.
        
        Returns:
            Status message
        """
        self.memories.append(item)
        return f"Added memory '{item.title}' (id={item.id})"
    
    def save(self) -> str:
        """Persist memories to JSON file.
        
        Returns:
            Status message with path and count
        """
        if self.path is None:
            return "No path configured - not saving"
        
        self.path.parent.mkdir(parents=True, exist_ok=True)
        data = [m.to_dict() for m in self.memories]
        
        with open(self.path, 'w') as f:
            json.dump(data, f, indent=2)
        
        return f"Saved {len(self.memories)} memories to {self.path}"
    
    @classmethod
    def load(cls, path: Path) -> 'MemoryStore':
        """Load memories from JSON file.
        
        Returns:
            MemoryStore instance with loaded memories
        """
        if not path.exists():
            return cls(memories=[], path=path)
        
        with open(path, 'r') as f:
            data = json.load(f)
        
        memories = [MemoryItem.from_dict(item) for item in data]
        return cls(memories=memories, path=path)
    
    def get_corpus_for_bm25(self) -> list[list[str]]:
        """Build corpus for BM25 indexing.
        
        Each document is title + description + tags, tokenized.
        
        Returns:
            List of tokenized documents
        """
        corpus = []
        for m in self.memories:
            text = f"{m.title} {m.description}"
            if m.tags:
                text += " " + " ".join(m.tags)
            corpus.append(text.lower().split())
        return corpus

# %% ../nbs/05_procedural_memory.ipynb #6f61a272
def extract_trajectory_artifact(
    task: str,
    answer: str,
    iterations: list[RLMIteration],
    ns: dict
) -> dict:
    """Create bounded trajectory artifact for judge/extractor.
    
    Summarizes each iteration's code blocks into 1-2 line "action + outcome",
    limiting to ~10 most informative key steps.
    
    Args:
        task: Original task query
        answer: Final answer from rlm_run
        iterations: List of RLMIteration objects
        ns: Final namespace dict
    
    Returns:
        Dictionary with keys:
        - task: str
        - final_answer: str
        - iteration_count: int
        - converged: bool (whether final_answer was set)
        - key_steps: List of {iteration, action, outcome}
        - variables_created: List of variable names in ns
        - errors_encountered: List of error messages from stderr
    """
    key_steps = []
    errors = []
    
    for i, iteration in enumerate(iterations, 1):
        # Summarize code blocks in this iteration
        for block in iteration.code_blocks:
            # Extract action from code (first line or summary)
            code_lines = block.code.strip().split('\n')
            action = code_lines[0][:80] if code_lines else "[empty code]"
            
            # Extract outcome from result
            if block.result and block.result.stderr:
                outcome = f"ERROR: {block.result.stderr[:100]}"
                errors.append(block.result.stderr)
            elif block.result and block.result.stdout:
                outcome = block.result.stdout[:100]
            else:
                outcome = "(no output)"
            
            key_steps.append({
                'iteration': i,
                'action': action,
                'outcome': outcome
            })
    
    # Limit to 10 most informative steps (prioritize errors and final steps)
    if len(key_steps) > 10:
        # Keep first 3, last 4, and up to 3 with errors
        error_steps = [s for s in key_steps if 'ERROR' in s['outcome']]
        key_steps = key_steps[:3] + error_steps[:3] + key_steps[-4:]
        # Remove duplicates while preserving order
        seen = set()
        key_steps = [s for s in key_steps if not (tuple(s.items()) in seen or seen.add(tuple(s.items())))]
        key_steps = key_steps[:10]
    
    return {
        'task': task,
        'final_answer': answer,
        'iteration_count': len(iterations),
        'converged': bool(answer and answer != "No answer provided"),
        'key_steps': key_steps,
        'variables_created': list(ns.keys()) if ns else [],
        'errors_encountered': errors
    }

# %% ../nbs/05_procedural_memory.ipynb #a062d233
def judge_trajectory(artifact: dict, ns: dict = None) -> dict:
    """Judge trajectory success using llm_query.
    
    Evidence-sensitive: success requires grounding in retrieved evidence.
    
    Args:
        artifact: Trajectory artifact from extract_trajectory_artifact()
        ns: Optional namespace for additional context
    
    Returns:
        Dictionary with keys:
        - is_success: bool
        - reason: str
        - confidence: str ('high', 'medium', 'low')
        - missing: list[str] (what evidence was lacking if failure)
    """
    # Format key steps for prompt
    steps_text = "\n".join([
        f"  {s['iteration']}. {s['action']} → {s['outcome']}"
        for s in artifact['key_steps']
    ])
    
    prompt = f"""Evaluate this RLM trajectory for task completion quality.

Task: {artifact['task']}
Final Answer: {artifact['final_answer']}
Converged: {artifact['converged']}
Key Steps:
{steps_text}

A trajectory is SUCCESSFUL if:
1. The answer directly addresses the task
2. The answer is grounded in retrieved evidence (not hallucinated)
3. The reasoning steps show systematic exploration

A trajectory FAILED if:
1. No answer was produced (didn't converge)
2. Answer doesn't address the task
3. Answer makes claims without supporting evidence

Return ONLY valid JSON:
{{"is_success": true/false, "reason": "...", "confidence": "high/medium/low", "missing": ["..."]}}"""
    
    # Use llm_query to get judgment (create temp namespace)
    temp_ns = ns if ns is not None else {}
    response = llm_query(prompt, temp_ns, name='judgment_response')
    
    # Parse JSON response
    try:
        # Try to extract JSON from response
        response_text = response.strip()
        if '```json' in response_text:
            response_text = response_text.split('```json')[1].split('```')[0].strip()
        elif '```' in response_text:
            response_text = response_text.split('```')[1].split('```')[0].strip()
        
        judgment = json.loads(response_text)
        
        # Ensure required fields
        if 'missing' not in judgment:
            judgment['missing'] = []
        
        return judgment
    except (json.JSONDecodeError, IndexError) as e:
        # Fallback for parsing errors
        return {
            'is_success': artifact['converged'],
            'reason': f"Parse error: {e}. Raw response: {response[:200]}",
            'confidence': 'low',
            'missing': ['Unable to parse judgment']
        }

# %% ../nbs/05_procedural_memory.ipynb #bcbbb406
def extract_memories(
    artifact: dict,
    judgment: dict,
    ns: dict = None
) -> list[MemoryItem]:
    """Extract up to 3 reusable memory items from trajectory.
    
    Args:
        artifact: Trajectory artifact from extract_trajectory_artifact()
        judgment: Judgment dict from judge_trajectory()
        ns: Optional namespace for additional context
    
    Returns:
        List of MemoryItem objects (0-3 items)
    """
    source_type = 'success' if judgment['is_success'] else 'failure'
    
    # Capture session_id if available in namespace
    session_id = None
    if ns is not None:
        # Try to get session_id from DatasetMeta
        if 'ds_meta' in ns and hasattr(ns['ds_meta'], 'session_id'):
            session_id = ns['ds_meta'].session_id
    
    # Format key steps for prompt
    steps_text = "\n".join([
        f"  {s['iteration']}. {s['action']} → {s['outcome']}"
        for s in artifact['key_steps']
    ])
    
    prompt = f"""Extract reusable procedural memories from this {source_type} trajectory.

Task: {artifact['task']}
Outcome: {judgment['reason']}
Key Steps:
{steps_text}

Extract UP TO 3 distinct, reusable insights. Each should be:
- Procedural (steps/checklist/template), NOT a retelling of this run
- Applicable to similar future tasks
- Concise but actionable

For ontology/SPARQL work, prefer:
- Query templates with placeholders
- Debugging strategies ("if X fails, try Y")
- Exploration patterns ("start with search, then describe, then probe")

Return ONLY valid JSON array (may have 1-3 items, or empty if no lessons):
[{{
  "title": "≤10 word identifier",
  "description": "One sentence summary",
  "content": "Markdown with steps/checklist/template",
  "tags": ["keyword1", "keyword2"]
}}]"""
    
    # Use llm_query to extract memories (create temp namespace)
    temp_ns = ns if ns is not None else {}
    response = llm_query(prompt, temp_ns, name='extractor_response')
    
    # Parse JSON response
    try:
        response_text = response.strip()
        if '```json' in response_text:
            response_text = response_text.split('```json')[1].split('```')[0].strip()
        elif '```' in response_text:
            response_text = response_text.split('```')[1].split('```')[0].strip()
        
        extracted = json.loads(response_text)
        
        # Convert to MemoryItem objects
        memories = []
        for item in extracted[:3]:  # Limit to 3
            memory = MemoryItem(
                id=str(uuid.uuid4()),
                title=item['title'],
                description=item['description'],
                content=item['content'],
                source_type=source_type,
                task_query=artifact['task'],
                created_at=datetime.now(timezone.utc).isoformat(),
                tags=item.get('tags', []),
                session_id=session_id  # NEW: Capture session_id from namespace
            )
            memories.append(memory)
        
        return memories
    except (json.JSONDecodeError, KeyError, IndexError) as e:
        # Return empty list on parsing errors
        print(f"Warning: Failed to extract memories: {e}")
        return []

# %% ../nbs/05_procedural_memory.ipynb #be6dea0c
def retrieve_memories(
    store: MemoryStore,
    task: str,
    k: int = 3
) -> list[MemoryItem]:
    """Retrieve top-k relevant memories using BM25.
    
    Tokenizes task and searches over title + description + tags.
    
    Args:
        store: MemoryStore instance
        task: Task query string
        k: Number of memories to retrieve
    
    Returns:
        List of top-k MemoryItem objects (may be fewer if scores ≤ 0)
    """
    if not store.memories:
        return []
    
    # Build BM25 index
    corpus = store.get_corpus_for_bm25()
    bm25 = BM25Okapi(corpus)
    
    # Query
    query_tokens = task.lower().split()
    scores = bm25.get_scores(query_tokens)
    
    # Get top-k by score (BM25 can return negative scores for small corpora)
    scored = [(i, s) for i, s in enumerate(scores)]
    scored.sort(key=lambda x: x[1], reverse=True)
    
    # Increment access_count for retrieved memories
    results = []
    for i, _ in scored[:k]:
        store.memories[i].access_count += 1
        results.append(store.memories[i])
    
    return results

# %% ../nbs/05_procedural_memory.ipynb #ae7e51cb
def format_memories_for_injection(
    memories: list[MemoryItem],
    max_bullets: int = 3
) -> str:
    """Format memories for bounded prompt injection.
    
    Returns string with:
    - Assessment instruction
    - Title + description + key bullets from content (up to max_bullets)
    
    Args:
        memories: List of MemoryItem objects to format
        max_bullets: Maximum bullets to extract from content
    
    Returns:
        Formatted string for prompt injection
    """
    if not memories:
        return ""
    
    lines = [
        "## Relevant Prior Experience",
        "",
        "Before taking action, briefly assess which of these strategies apply to your current task and which do not.",
        ""
    ]
    
    for i, mem in enumerate(memories, 1):
        lines.append(f"### {i}. {mem.title}")
        lines.append(mem.description)
        lines.append("Key points:")
        
        # Extract bullets from content (look for lines starting with - or numbers)
        content_lines = mem.content.split('\n')
        bullets = []
        for line in content_lines:
            stripped = line.strip()
            if stripped.startswith('-') or stripped.startswith('*'):
                bullets.append(stripped)
            elif len(stripped) > 0 and stripped[0].isdigit() and '.' in stripped:
                bullets.append(stripped)
        
        # Use first max_bullets bullets, or first max_bullets lines if no bullets found
        if bullets:
            for bullet in bullets[:max_bullets]:
                lines.append(f"- {bullet.lstrip('- *')}")
        else:
            # Fall back to first few lines
            for line in content_lines[:max_bullets]:
                if line.strip():
                    lines.append(f"- {line.strip()}")
        
        lines.append("")  # Blank line between memories
    
    return "\n".join(lines)

# %% ../nbs/05_procedural_memory.ipynb #54c5c843
def rlm_run_with_memory(
    query: str,
    context: str,
    memory_store: MemoryStore,
    ns: dict = None,
    enable_memory_extraction: bool = True,
    # NEW: Dataset persistence
    persist_dataset: bool = False,
    dataset_path: Path = None,
    **kwargs
) -> tuple[str, list, dict, list[MemoryItem]]:
    """RLM run with procedural memory loop.
    
    Closed-loop cycle:
    1. RETRIEVE: Get relevant memories via BM25
    2. INJECT: Add to context/prompt
    3. INTERACT: Run rlm_run()
    4. EXTRACT: Judge + extract new memories
    5. STORE: Persist new memories
    
    NEW: Dataset persistence:
    - If persist_dataset=True and dataset_path provided, loads snapshot before run
    - After run, if dataset was modified, saves snapshot
    - Stores snapshot path in extracted MemoryItem for lineage
    
    Args:
        query: Task query string
        context: Context string (e.g., ontology summary)
        memory_store: MemoryStore instance for retrieval/storage
        ns: Optional namespace dict
        enable_memory_extraction: Whether to extract and store new memories (default True)
        persist_dataset: Whether to persist dataset snapshots (default False)
        dataset_path: Optional path for dataset snapshot
        **kwargs: Additional arguments for rlm_run()
    
    Returns:
        Tuple of (answer, iterations, ns, new_memories)
    """
    # NEW: Load dataset snapshot if it exists
    if persist_dataset and dataset_path is not None and dataset_path.exists():
        try:
            from rlm.dataset import load_snapshot
            load_snapshot(str(dataset_path), ns)
        except Exception as e:
            print(f"Warning: Failed to load dataset snapshot: {e}")
    
    # 1. RETRIEVE relevant memories
    relevant = retrieve_memories(memory_store, query, k=3)
    
    # 2. INJECT into context
    if relevant:
        memory_text = format_memories_for_injection(relevant)
        enhanced_context = f"{memory_text}\n\n---\n\n{context}"
    else:
        enhanced_context = context
    
    # 3. INTERACT - run RLM
    answer, iterations, ns = rlm_run(query, enhanced_context, ns=ns, **kwargs)
    
    # NEW: Save dataset snapshot if dataset was modified
    if persist_dataset and dataset_path is not None:
        try:
            from rlm.dataset import snapshot_dataset
            if 'ds_meta' in ns:
                result = snapshot_dataset(ns['ds_meta'], path=str(dataset_path))
                print(f"Dataset snapshot: {result}")
        except Exception as e:
            print(f"Warning: Failed to save dataset snapshot: {e}")
    
    new_memories = []
    if enable_memory_extraction:
        # 4. EXTRACT - judge and extract memories
        artifact = extract_trajectory_artifact(query, answer, iterations, ns)
        judgment = judge_trajectory(artifact, ns)
        new_memories = extract_memories(artifact, judgment, ns)
        
        # 5. STORE - persist new memories
        for mem in new_memories:
            memory_store.add(mem)
        if memory_store.path:
            memory_store.save()
    
    return answer, iterations, ns, new_memories

# %% ../nbs/05_procedural_memory.ipynb #effb9aba
def bootstrap_general_strategies() -> list[MemoryItem]:
    """Create general strategy memories for bootstrapping.
    
    These are universal patterns extracted from successful RLM runs
    that apply to all ontologies.
    
    Returns:
        List of MemoryItem objects representing general strategies
    """
    strategies = [
        MemoryItem(
            id=str(uuid.uuid4()),
            title='Describe Entity by Label',
            description='Universal pattern for finding and describing an entity when you only have its label.',
            content="""1. Use `search_entity(label)` to find matching entities
2. Extract the `uri` field from the first result
3. Use `describe_entity(uri)` to get types, comment, and outgoing triples
4. If you need relationships, use `probe_relationships(uri)` for incoming/outgoing links""",
            source_type='success',
            task_query='entity_description',
            created_at=datetime.now(timezone.utc).isoformat(),
            tags=['entity', 'search', 'describe', 'universal']
        ),
        
        MemoryItem(
            id=str(uuid.uuid4()),
            title='Find Subclasses Using GraphMeta',
            description='Fast subclass lookup using pre-indexed GraphMeta hierarchy.',
            content="""1. Use `search_entity(class_label)` to get the full URI
2. Access `{ontology}_meta.subs[class_uri]` directly for the subclass list
3. Get labels for each subclass: `{ontology}_meta.labels.get(sub_uri)`

Alternative if GraphMeta not available:
- Use `probe_relationships(uri, direction='in')` and filter for `rdfs:subClassOf`""",
            source_type='success',
            task_query='hierarchy',
            created_at=datetime.now(timezone.utc).isoformat(),
            tags=['hierarchy', 'subclass', 'graphmeta', 'universal']
        ),
        
        MemoryItem(
            id=str(uuid.uuid4()),
            title='Find Superclasses Using GraphMeta',
            description='Fast superclass lookup using pre-indexed GraphMeta hierarchy.',
            content="""1. Use `search_entity(class_label)` to get the full URI
2. Access `{ontology}_meta.supers[class_uri]` directly for the superclass list
3. Get labels for each superclass: `{ontology}_meta.labels.get(super_uri)`

Alternative if GraphMeta not available:
- Use `probe_relationships(uri, direction='out')` and filter for `rdfs:subClassOf`""",
            source_type='success',
            task_query='hierarchy',
            created_at=datetime.now(timezone.utc).isoformat(),
            tags=['hierarchy', 'superclass', 'graphmeta', 'universal']
        ),
        
        MemoryItem(
            id=str(uuid.uuid4()),
            title='Find Properties by Domain/Range',
            description='Find properties that have a specific class as domain or range.',
            content="""1. Use `search_entity(class_label)` to get the class URI
2. For properties with this domain: check `{ontology}_meta.doms` (inverted dict)
3. For properties with this range: check `{ontology}_meta.rngs` (inverted dict)
4. Use `describe_entity(property_uri)` for details on each property

Note: May need to iterate through all properties and check domain/range if indexes don't support reverse lookup.""",
            source_type='success',
            task_query='property_discovery',
            created_at=datetime.now(timezone.utc).isoformat(),
            tags=['properties', 'domain', 'range', 'universal']
        ),
        
        MemoryItem(
            id=str(uuid.uuid4()),
            title='Pattern-Based Entity Search',
            description='Search for multiple entities matching a keyword or pattern.',
            content="""1. Use `search_entity(pattern, search_in='all')` for broad search
2. Results include `match_type` field: 'label', 'iri', or 'localname'
3. Filter by match_type if needed
4. For each interesting result, use `describe_entity(uri)` for details
5. Use `limit` parameter to control result count (default: 10)""",
            source_type='success',
            task_query='pattern_search',
            created_at=datetime.now(timezone.utc).isoformat(),
            tags=['search', 'pattern', 'multiple', 'universal']
        ),
        
        MemoryItem(
            id=str(uuid.uuid4()),
            title='Find Relationship Path Between Entities',
            description='Find how two entities are related via predicates.',
            content="""1. Use `search_entity()` to get full URIs for both entities
2. Use `find_path(source_uri, target_uri, max_depth=2)` to find connecting paths
3. Each path shows predicates and direction ('out' or 'in')
4. Interpret the path steps to understand the relationship

Example path:
[{'from': A, 'predicate': 'used', 'to': B, 'direction': 'out'}]
means: A --used--> B""",
            source_type='success',
            task_query='relationship_discovery',
            created_at=datetime.now(timezone.utc).isoformat(),
            tags=['relationships', 'path', 'connection', 'universal']
        ),
        
        MemoryItem(
            id=str(uuid.uuid4()),
            title='Navigate Class Hierarchy from Roots',
            description='Systematic exploration of class hierarchy starting from root classes.',
            content="""1. Check `sense.hierarchy_overview` for root classes (if sense_brief available)
2. For each root, use `{ontology}_meta.subs[root_uri]` to get immediate subclasses
3. Recursively explore subclasses to desired depth
4. Use `describe_entity()` on interesting classes for details

Tip: `sense.available_indexes.hierarchy` tells you how many relationships exist.
Tip: Avoid deep recursion - explore breadth-first for overview.""",
            source_type='success',
            task_query='hierarchy',
            created_at=datetime.now(timezone.utc).isoformat(),
            tags=['hierarchy', 'exploration', 'roots', 'universal']
        )
    ]
    
    return strategies

# %% ../nbs/05_procedural_memory.ipynb #72b34239
def validate_no_hardcoded_uris(strategies: list[MemoryItem]) -> bool:
    """Ensure strategies don't reference specific ontology URIs.
    
    Universal strategies should use placeholders like {ontology}_meta
    instead of hardcoded ontology prefixes.
    """
    ontology_prefixes = ['prov:', 'sio:', 'schema:', 'foaf:']
    
    for strategy in strategies:
        content_lower = strategy.content.lower()
        for prefix in ontology_prefixes:
            if prefix in content_lower:
                return False
    
    return True


# %% ../nbs/05_procedural_memory.ipynb #7357a483
def validate_bootstrap_strategies() -> dict:
    """Validate bootstrap creates valid, non-conflicting strategies.
    
    Checks:
    - Correct count (7 strategies)
    - All are valid MemoryItem objects
    - Unique titles (no duplicates)
    - All tagged as 'universal'
    - No hardcoded ontology-specific URIs
    
    Returns:
        Dictionary with 'valid' flag and detailed checks
    """
    strategies = bootstrap_general_strategies()
    
    checks = {
        'count': len(strategies) == 7,
        'all_valid': all(isinstance(s, MemoryItem) for s in strategies),
        'unique_titles': len(set(s.title for s in strategies)) == 7,
        'tagged_universal': all('universal' in s.tags for s in strategies),
        'no_hardcoded_uris': validate_no_hardcoded_uris(strategies)
    }
    
    return {
        'valid': all(checks.values()),
        'checks': checks
    }


# %% ../nbs/05_procedural_memory.ipynb #448c26a5
def check_memory_deduplication(
    new_memory: MemoryItem,
    store: MemoryStore,
    threshold: float = 0.7
) -> str:
    """Gate 1: Check for duplicate memories.
    
    Uses title similarity to detect duplicates and decide action:
    - add: No similar memories, safe to add
    - merge: Similar memory exists, should combine insights
    - skip: Similar memory exists and is better, don't add
    - replace: New memory is better, replace existing
    
    Args:
        new_memory: MemoryItem to check
        store: MemoryStore to check against
        threshold: Similarity threshold (0-1) for considering duplicate
    
    Returns:
        Action string: 'add', 'merge', 'skip', or 'replace'
    """
    from difflib import SequenceMatcher
    
    for existing in store.memories:
        similarity = SequenceMatcher(
            None,
            new_memory.title.lower(),
            existing.title.lower()
        ).ratio()
        
        if similarity >= threshold:
            # High similarity - decide action based on quality signals
            if new_memory.source_type == 'success' and existing.source_type == 'failure':
                return 'replace'  # Success overwrites failure
            elif existing.access_count > 5 and new_memory.access_count == 0:
                return 'skip'  # Keep well-used memory
            else:
                return 'merge'  # Combine insights
    
    return 'add'  # No duplicates found


# %% ../nbs/05_procedural_memory.ipynb #fdbcf7a7
def score_generalization(memory: MemoryItem) -> float:
    """Gate 3: Score how generalizable a memory is (0-1).
    
    Higher score = more general/reusable across ontologies.
    Lower score = specific to one ontology or situation.
    
    Scoring factors:
    - Penalize hardcoded URIs (prov:, sio:, http://)
    - Reward procedural language (use, check, try, if/then)
    - Reward 'universal' tag
    
    Args:
        memory: MemoryItem to score
    
    Returns:
        Score between 0.0 and 1.0
    """
    score = 0.5  # Base score
    
    content_lower = memory.content.lower()
    
    # Penalize specific URIs (hardcoded ontology references)
    if any(prefix in content_lower for prefix in ['prov:', 'sio:', 'http://']):
        score -= 0.3
    
    # Reward procedural language
    procedural_words = ['use', 'check', 'try', 'if', 'then', 'step']
    if any(word in content_lower for word in procedural_words):
        score += 0.2
    
    # Reward 'universal' tag
    if 'universal' in memory.tags:
        score += 0.3
    
    return max(0.0, min(1.0, score))


# %% ../nbs/05_procedural_memory.ipynb #7092ef6f
def validate_retrieval_quality(
    memory_store: MemoryStore,
    test_cases: list[tuple[str, list[str]]]
) -> dict:
    """Validate BM25 retrieves relevant memories for known queries.
    
    Args:
        memory_store: MemoryStore with strategies
        test_cases: List of (query, expected_tags) tuples
    
    Returns:
        Dictionary with validation results including success_rate
    """
    results = []
    
    for query, expected_tags in test_cases:
        retrieved = retrieve_memories(memory_store, query, k=3)
        
        # Check if at least one retrieved memory has expected tags
        has_relevant = any(
            any(tag in retrieved_mem.tags for tag in expected_tags)
            for retrieved_mem in retrieved
        )
        
        results.append({
            'query': query,
            'expected_tags': expected_tags,
            'retrieved_count': len(retrieved),
            'has_relevant': has_relevant
        })
    
    success_rate = sum(r['has_relevant'] for r in results) / len(results) if results else 0
    
    return {
        'valid': success_rate >= 0.8,  # 80% success rate threshold
        'success_rate': success_rate,
        'results': results
    }

