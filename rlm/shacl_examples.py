"""Enables 'retrieve example → adapt → run → inspect' workflow for discovering how to query unfamiliar datasets."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/06_shacl_examples.ipynb.

# %% auto 0
__all__ = ['detect_sparql_executables', 'QueryIndex', 'extract_query_keywords', 'build_query_index', 'search_queries',
           'describe_query', 'get_query_text', 'load_query_examples', 'SHACLIndex', 'detect_shacl', 'extract_keywords',
           'build_shacl_index', 'describe_shape', 'search_shapes', 'shape_constraints']

# %% ../nbs/06_shacl_examples.ipynb 2
from dataclasses import dataclass, field
from typing import Dict, List, Optional
from rdflib import Graph, Namespace, RDF, RDFS, URIRef, Literal
from rdflib.namespace import SH

# %% ../nbs/06_shacl_examples.ipynb 4
def detect_sparql_executables(graph: Graph) -> dict:
    """Detect sh:SPARQLExecutable content in a graph.

    Args:
        graph: RDF graph to analyze

    Returns:
        Dict with:
            has_executables: True if any SPARQLExecutable found
            select_count: Count of sh:SPARQLSelectExecutable instances
            construct_count: Count of sh:SPARQLConstructExecutable instances
            ask_count: Count of sh:SPARQLAskExecutable instances
            total_count: Total query count
    """
    SCHEMA = Namespace("https://schema.org/")
    
    # Check for SPARQLExecutable types
    executables = list(graph.subjects(RDF.type, SH.SPARQLExecutable))
    select_exec = list(graph.subjects(RDF.type, SH.SPARQLSelectExecutable))
    construct_exec = list(graph.subjects(RDF.type, SH.SPARQLConstructExecutable))
    ask_exec = list(graph.subjects(RDF.type, SH.SPARQLAskExecutable))
    
    # Union of all (remove duplicates)
    all_queries = set(executables + select_exec + construct_exec + ask_exec)
    
    return {
        'has_executables': len(all_queries) > 0,
        'select_count': len(select_exec),
        'construct_count': len(construct_exec),
        'ask_count': len(ask_exec),
        'total_count': len(all_queries)
    }

# %% ../nbs/06_shacl_examples.ipynb 5
@dataclass
class QueryIndex:
    """Index of sh:SPARQLExecutable query templates for retrieval.

    Attributes:
        queries: List of query URIs
        comments: Mapping from query URI to rdfs:comment description
        keywords: Inverted index from keyword to query URIs
        endpoints: Mapping from query URI to target endpoint URLs
        query_text: Mapping from query URI to sh:select/sh:construct text
        query_type: Mapping from query URI to type ('select', 'construct', 'ask')
        source_file: Mapping from query URI to source file path
    """
    queries: List[str] = field(default_factory=list)
    comments: Dict[str, str] = field(default_factory=dict)
    keywords: Dict[str, List[str]] = field(default_factory=dict)
    endpoints: Dict[str, List[str]] = field(default_factory=dict)
    query_text: Dict[str, str] = field(default_factory=dict)
    query_type: Dict[str, str] = field(default_factory=dict)
    source_file: Dict[str, str] = field(default_factory=dict)

    def summary(self) -> str:
        """Return bounded summary of index."""
        return f"QueryIndex: {len(self.queries)} queries, {len(self.keywords)} keywords"

# %% ../nbs/06_shacl_examples.ipynb 7
import re
from pathlib import Path

def extract_query_keywords(graph: Graph, query_uri: URIRef, comment: str) -> List[str]:
    """Extract keywords from schema:keywords and rdfs:comment.

    Sources:
        - schema:keywords (explicit tags)
        - rdfs:comment (word extraction)
        - Query URI local name
    
    Args:
        graph: RDF graph containing the query
        query_uri: Query URI
        comment: rdfs:comment text
    
    Returns:
        List of lowercase keywords
    """
    SCHEMA = Namespace("https://schema.org/")
    keywords = set()
    
    # Extract from query URI local name
    query_local = str(query_uri).split('/')[-1].split('#')[-1]
    keywords.add(query_local.lower())
    
    # Extract from explicit schema:keywords
    for keyword in graph.objects(query_uri, SCHEMA.keywords):
        keywords.add(str(keyword).lower())
    
    # Extract words from comment (3+ chars, alphanumeric)
    if comment:
        words = re.findall(r'\b[a-z]{3,}\b', comment.lower())
        # Filter out common words
        stopwords = {'the', 'and', 'for', 'with', 'from', 'that', 'this', 'all'}
        keywords.update(w for w in words if w not in stopwords)
    
    return list(keywords)


# %% ../nbs/06_shacl_examples.ipynb 9
def build_query_index(graph: Graph, source_path: str = None) -> QueryIndex:
    """Build searchable index from sh:SPARQLExecutable templates.

    Extracts: sh:select, sh:construct, sh:ask, rdfs:comment,
              schema:keywords, schema:target
    
    Args:
        graph: RDF graph containing query templates
        source_path: Optional source file path for tracking
    
    Returns:
        QueryIndex with indexed queries
    """
    SCHEMA = Namespace("https://schema.org/")
    
    queries = []
    comments = {}
    keywords = {}
    endpoints = {}
    query_text = {}
    query_type = {}
    source_file = {}
    
    # Find all SPARQLExecutable instances
    all_exec = set(
        list(graph.subjects(RDF.type, SH.SPARQLExecutable)) +
        list(graph.subjects(RDF.type, SH.SPARQLSelectExecutable)) +
        list(graph.subjects(RDF.type, SH.SPARQLConstructExecutable)) +
        list(graph.subjects(RDF.type, SH.SPARQLAskExecutable))
    )
    
    for query_uri in all_exec:
        query_str = str(query_uri)
        queries.append(query_str)
        
        # Extract comment
        comment = graph.value(query_uri, RDFS.comment)
        comments[query_str] = str(comment) if comment else ''
        
        # Extract endpoints
        targets = [str(t) for t in graph.objects(query_uri, SCHEMA.target)]
        endpoints[query_str] = targets
        
        # Extract query text and determine type
        select_q = graph.value(query_uri, SH.select)
        construct_q = graph.value(query_uri, SH.construct)
        ask_q = graph.value(query_uri, SH.ask)
        
        if select_q:
            query_text[query_str] = str(select_q)
            query_type[query_str] = 'select'
        elif construct_q:
            query_text[query_str] = str(construct_q)
            query_type[query_str] = 'construct'
        elif ask_q:
            query_text[query_str] = str(ask_q)
            query_type[query_str] = 'ask'
        
        # Track source file
        if source_path:
            source_file[query_str] = source_path
        
        # Build keyword index
        query_keywords = extract_query_keywords(graph, query_uri, comments[query_str])
        for kw in query_keywords:
            if kw not in keywords:
                keywords[kw] = []
            if query_str not in keywords[kw]:
                keywords[kw].append(query_str)
    
    return QueryIndex(
        queries=queries,
        comments=comments,
        keywords=keywords,
        endpoints=endpoints,
        query_text=query_text,
        query_type=query_type,
        source_file=source_file
    )


# %% ../nbs/06_shacl_examples.ipynb 11
def search_queries(index: QueryIndex, keyword: str, limit: int = 5) -> list:
    """Find query templates matching keyword.

    Args:
        index: QueryIndex to search
        keyword: Search term
        limit: Maximum number of results
    
    Returns:
        List of dicts with: uri, comment, endpoints, matched_keyword
    """
    keyword_lower = keyword.lower()
    matches = []
    
    for kw, query_uris in index.keywords.items():
        if keyword_lower in kw:
            for uri in query_uris:
                matches.append({
                    'uri': uri,
                    'comment': index.comments.get(uri, '')[:100],  # Preview
                    'endpoints': index.endpoints.get(uri, []),
                    'matched_keyword': kw
                })
    
    # Dedupe by URI
    seen = set()
    unique = []
    for m in matches:
        if m['uri'] not in seen:
            seen.add(m['uri'])
            unique.append(m)
    
    return unique[:limit]


# %% ../nbs/06_shacl_examples.ipynb 12
def describe_query(index: QueryIndex, query_uri: str) -> dict:
    """Get bounded description of a query template.

    Args:
        index: QueryIndex to query
        query_uri: URI of query
    
    Returns:
        Dict with: uri, comment, endpoints, query_type,
                   keywords, query_preview (200 chars)
    """
    if query_uri not in index.comments:
        return {'error': f'Query {query_uri} not found in index'}
    
    # Find keywords for this query
    query_keywords = [kw for kw, uris in index.keywords.items() if query_uri in uris]
    
    # Get query preview
    full_query = index.query_text.get(query_uri, '')
    preview = full_query[:200] + '...' if len(full_query) > 200 else full_query
    
    return {
        'uri': query_uri,
        'comment': index.comments[query_uri],
        'endpoints': index.endpoints.get(query_uri, []),
        'query_type': index.query_type.get(query_uri, 'unknown'),
        'keywords': query_keywords[:10],  # Limit keywords
        'query_preview': preview
    }


# %% ../nbs/06_shacl_examples.ipynb 13
def get_query_text(index: QueryIndex, query_uri: str) -> str:
    """Get full SPARQL query text for execution.
    
    Args:
        index: QueryIndex to query
        query_uri: URI of query
    
    Returns:
        Full SPARQL query text
    """
    return index.query_text.get(query_uri, '')


# %% ../nbs/06_shacl_examples.ipynb 14
def load_query_examples(path: str, ns: dict, name: str = 'queries') -> str:
    """Load SPARQL example files from directory into QueryIndex.

    Recursively loads all .ttl files and builds combined index.
    
    Args:
        path: Directory path containing .ttl example files
        ns: Namespace dict for storing the index
        name: Variable name for the index in ns
    
    Returns:
        Status message
    """
    from pathlib import Path
    
    path_obj = Path(path)
    if not path_obj.exists():
        return f"Path {path} not found"
    
    # Collect all .ttl files
    ttl_files = list(path_obj.glob('**/*.ttl'))
    
    # Build combined index
    combined_queries = []
    combined_comments = {}
    combined_keywords = {}
    combined_endpoints = {}
    combined_query_text = {}
    combined_query_type = {}
    combined_source_file = {}
    
    for ttl_file in ttl_files:
        g = Graph()
        try:
            g.parse(ttl_file)
            idx = build_query_index(g, str(ttl_file))
            
            # Merge into combined index
            combined_queries.extend(idx.queries)
            combined_comments.update(idx.comments)
            combined_endpoints.update(idx.endpoints)
            combined_query_text.update(idx.query_text)
            combined_query_type.update(idx.query_type)
            combined_source_file.update(idx.source_file)
            
            # Merge keywords
            for kw, uris in idx.keywords.items():
                if kw not in combined_keywords:
                    combined_keywords[kw] = []
                combined_keywords[kw].extend(uri for uri in uris if uri not in combined_keywords[kw])
        except Exception as e:
            print(f"Warning: Could not parse {ttl_file}: {e}")
            continue
    
    # Create combined QueryIndex
    combined_index = QueryIndex(
        queries=combined_queries,
        comments=combined_comments,
        keywords=combined_keywords,
        endpoints=combined_endpoints,
        query_text=combined_query_text,
        query_type=combined_query_type,
        source_file=combined_source_file
    )
    
    # Store in namespace
    ns[name] = combined_index
    
    return f"Loaded {len(combined_queries)} queries from {len(ttl_files)} files into '{name}'"


# %% ../nbs/06_shacl_examples.ipynb 16
@dataclass
class SHACLIndex:
    """Index of SHACL shapes for retrieval.
    
    Attributes:
        shapes: List of shape URIs
        targets: Mapping from shape URI to target class URIs
        properties: Mapping from shape URI to property constraint dicts
        keywords: Inverted index from keyword to shape URIs
        paradigm: SHACL usage paradigm ('validation', 'shacl-first', 'mixed')
    """
    shapes: List[str] = field(default_factory=list)
    targets: Dict[str, List[str]] = field(default_factory=dict)
    properties: Dict[str, List[dict]] = field(default_factory=dict)
    keywords: Dict[str, List[str]] = field(default_factory=dict)
    paradigm: str = 'unknown'

    def summary(self) -> str:
        """Return bounded summary of index."""
        return f"SHACLIndex: {len(self.shapes)} shapes, {len(self.keywords)} keywords, paradigm={self.paradigm}"

# %% ../nbs/06_shacl_examples.ipynb 18
def detect_shacl(graph: Graph) -> dict:
    """Detect SHACL content in a graph.

    Args:
        graph: RDF graph to analyze

    Returns:
        Dict with:
            has_shacl: True if any SHACL patterns found
            node_shapes: Count of sh:NodeShape instances
            property_shapes: Count of sh:PropertyShape instances
            paradigm: 'validation', 'shacl-first', or 'mixed'
    """
    # Count SHACL shape types
    node_shapes = list(graph.subjects(RDF.type, SH.NodeShape))
    property_shapes = list(graph.subjects(RDF.type, SH.PropertyShape))
    
    has_shacl = len(node_shapes) > 0 or len(property_shapes) > 0
    
    if not has_shacl:
        return {
            'has_shacl': False,
            'node_shapes': 0,
            'property_shapes': 0,
            'paradigm': 'none'
        }
    
    # Detect paradigm
    DASH = Namespace("http://datashapes.org/dash#")
    dash_shape_classes = list(graph.subjects(RDF.type, DASH.ShapeClass))
    
    # Check if shapes are also OWL classes (mixed paradigm)
    OWL = Namespace("http://www.w3.org/2002/07/owl#")
    shapes_as_classes = any(
        (s, RDF.type, OWL.Class) in graph or 
        (s, RDFS.subClassOf, None) in graph
        for s in node_shapes
    )
    
    if dash_shape_classes:
        paradigm = 'shacl-first'
    elif shapes_as_classes:
        paradigm = 'mixed'
    else:
        paradigm = 'validation'
    
    return {
        'has_shacl': True,
        'node_shapes': len(node_shapes),
        'property_shapes': len(property_shapes),
        'paradigm': paradigm
    }

# %% ../nbs/06_shacl_examples.ipynb 20
def extract_keywords(graph: Graph, shape: URIRef, target_classes: List[str], props: List[dict]) -> List[str]:
    """Extract searchable keywords from a shape.
    
    Args:
        graph: RDF graph containing the shape
        shape: Shape URI
        target_classes: Target class URIs
        props: Property constraint dicts
    
    Returns:
        List of lowercase keywords
    """
    keywords = set()
    
    # Extract from shape URI local name
    shape_local = str(shape).split('/')[-1].split('#')[-1]
    keywords.add(shape_local.lower())
    
    # Extract from labels
    for label in graph.objects(shape, RDFS.label):
        keywords.add(str(label).lower())
    
    # Extract from target class local names
    for tc in target_classes:
        tc_local = tc.split('/')[-1].split('#')[-1]
        keywords.add(tc_local.lower())
    
    # Extract from property paths
    for prop in props:
        if prop.get('path'):
            path_local = prop['path'].split('/')[-1].split('#')[-1]
            keywords.add(path_local.lower())
    
    return list(keywords)

# %% ../nbs/06_shacl_examples.ipynb 22
def build_shacl_index(graph: Graph) -> SHACLIndex:
    """Build searchable index from SHACL shapes in graph.
    
    Args:
        graph: RDF graph containing SHACL shapes
    
    Returns:
        SHACLIndex with indexed shapes
    """
    detection = detect_shacl(graph)
    
    if not detection['has_shacl']:
        return SHACLIndex(paradigm='none')
    
    shapes = []
    targets = {}
    properties = {}
    keywords = {}
    
    # Index all NodeShapes
    for shape in graph.subjects(RDF.type, SH.NodeShape):
        shape_uri = str(shape)
        shapes.append(shape_uri)
        
        # Get target classes
        target_classes = [str(t) for t in graph.objects(shape, SH.targetClass)]
        targets[shape_uri] = target_classes
        
        # Get property constraints
        props = []
        for prop_node in graph.objects(shape, SH.property):
            path = graph.value(prop_node, SH.path)
            datatype = graph.value(prop_node, SH.datatype)
            node_kind = graph.value(prop_node, SH.nodeKind)
            min_count = graph.value(prop_node, SH.minCount)
            max_count = graph.value(prop_node, SH.maxCount)
            class_constraint = graph.value(prop_node, SH['class'])
            
            props.append({
                'path': str(path) if path else None,
                'datatype': str(datatype) if datatype else None,
                'nodeKind': str(node_kind) if node_kind else None,
                'minCount': int(min_count) if min_count else None,
                'maxCount': int(max_count) if max_count else None,
                'class': str(class_constraint) if class_constraint else None,
            })
        properties[shape_uri] = props
        
        # Build keyword index
        shape_keywords = extract_keywords(graph, shape, target_classes, props)
        for kw in shape_keywords:
            if kw not in keywords:
                keywords[kw] = []
            if shape_uri not in keywords[kw]:
                keywords[kw].append(shape_uri)
    
    return SHACLIndex(
        shapes=shapes,
        targets=targets,
        properties=properties,
        keywords=keywords,
        paradigm=detection['paradigm']
    )

# %% ../nbs/06_shacl_examples.ipynb 24
def describe_shape(index: SHACLIndex, shape_uri: str, limit: int = 10) -> dict:
    """Get bounded description of a SHACL shape.

    Args:
        index: SHACL index to query
        shape_uri: URI of shape to describe
        limit: Maximum number of properties to return

    Returns:
        Dict with:
            uri: Shape URI
            targets: List of target class URIs
            properties: First `limit` property constraints
            property_count: Total property count
            truncated: True if property list was truncated
    """
    if shape_uri not in index.targets:
        return {'error': f'Shape {shape_uri} not found in index'}

    props = index.properties.get(shape_uri, [])
    return {
        'uri': shape_uri,
        'targets': index.targets[shape_uri],
        'properties': props[:limit],
        'property_count': len(props),
        'truncated': len(props) > limit
    }

# %% ../nbs/06_shacl_examples.ipynb 25
def search_shapes(index: SHACLIndex, keyword: str, limit: int = 5) -> list:
    """Find shapes matching keyword.

    Args:
        index: SHACL index to search
        keyword: Search term
        limit: Maximum number of results

    Returns:
        List of dicts with:
            uri: Shape URI
            targets: Target class URIs
            matched_keyword: The keyword that matched
    """
    keyword_lower = keyword.lower()
    matches = []

    for kw, shape_uris in index.keywords.items():
        if keyword_lower in kw.lower():
            for uri in shape_uris:
                matches.append({
                    'uri': uri,
                    'targets': index.targets.get(uri, []),
                    'matched_keyword': kw
                })

    # Dedupe by URI, keep first match
    seen = set()
    unique = []
    for m in matches:
        if m['uri'] not in seen:
            seen.add(m['uri'])
            unique.append(m)

    return unique[:limit]

# %% ../nbs/06_shacl_examples.ipynb 26
def shape_constraints(index: SHACLIndex, shape_uri: str) -> str:
    """Get human-readable property constraints for a shape.
    
    Args:
        index: SHACL index to query
        shape_uri: URI of shape
    
    Returns:
        Formatted string with property constraints
    """
    if shape_uri not in index.properties:
        return f"Shape {shape_uri} not found in index"

    lines = [f"Constraints for {shape_uri.split('/')[-1].split('#')[-1]}:"]
    
    props = index.properties[shape_uri]
    if not props:
        lines.append("  (no property constraints)")
        return '\n'.join(lines)
    
    for prop in props:
        path = prop.get('path', '?')
        path_local = path.split('/')[-1].split('#')[-1] if path else '?'
        
        parts = []
        if prop.get('datatype'):
            dt_local = prop['datatype'].split('#')[-1]
            parts.append(f"type={dt_local}")
        if prop.get('class'):
            cls_local = prop['class'].split('/')[-1].split('#')[-1]
            parts.append(f"class={cls_local}")
        if prop.get('nodeKind'):
            nk_local = prop['nodeKind'].split('#')[-1]
            parts.append(f"kind={nk_local}")
        if prop.get('minCount') is not None:
            parts.append(f"min={prop['minCount']}")
        if prop.get('maxCount') is not None:
            parts.append(f"max={prop['maxCount']}")
        
        constraint = ', '.join(parts) if parts else 'no constraints'
        lines.append(f"  {path_local}: {constraint}")

    return '\n'.join(lines)
