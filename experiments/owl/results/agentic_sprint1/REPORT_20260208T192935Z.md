# Agentic OWL+SHACL Sprint-1 Report

## Run Metadata

- Timestamp: `20260208T192935Z`
- Objective: Evaluate agentic ontology construction over sprint-1 competency questions (`CQ1..CQ5`) using strict-symbolic RLM tooling.
- Main model: `anthropic/claude-sonnet-4-5-20250929`
- Sub-model: `anthropic/claude-haiku-4-5-20251001`
- Ontology input: `ontology/core-vocabulary.ttl`
- SHACL input: `ontology/core-shapes.ttl`
- Runner: `experiments/owl/agentic_owl_runner.py`

## Repro Command

```bash
~/uvws/.venv/bin/python experiments/owl/agentic_owl_runner.py \
  --ontology-path ontology/core-vocabulary.ttl \
  --shapes-path ontology/core-shapes.ttl \
  --out-dir experiments/owl/results/agentic_sprint1 \
  --cqs CQ1,CQ2,CQ3,CQ4,CQ5
```

## Artifacts

- Summary: `experiments/owl/results/agentic_sprint1/summary_20260208T192935Z.json`
- Trajectory JSONL: `experiments/owl/results/agentic_sprint1/trajectory_20260208T192935Z.jsonl`
- Final graph snapshot: `experiments/owl/results/agentic_sprint1/working_graph_20260208T192935Z.ttl`

## Headline Results

- CQ pass rate: `3/5` (`60%`)
- Passed: `CQ1`, `CQ3`, `CQ4`
- Failed: `CQ2`, `CQ5`
- Final SHACL conformance: `false`
- Final SHACL validation results: `29`
- Final graph size: `175` triples
- Total tokens: `494,183`
- Total cost: `1.933356`

## Per-CQ Results

| CQ | Passed | SHACL Conforms | Iterations | Duration (s) | Tokens | Cost | Large Returns |
|---|---:|---:|---:|---:|---:|---:|---:|
| CQ1 | true | false | 12 | 147.7 | 109,824 | 0.447459 | 7 |
| CQ2 | false | false | 13 | 137.0 | 117,265 | 0.437811 | 6 |
| CQ3 | true | false | 12 | 120.3 | 90,254 | 0.360906 | 4 |
| CQ4 | true | false | 12 | 114.5 | 83,434 | 0.325122 | 6 |
| CQ5 | false | false | 12 | 112.3 | 93,406 | 0.362058 | 7 |

## Trajectory Statistics

- Total events: `525`
- Event mix:
  - `run_start`: `5`
  - `run_complete`: `5`
  - `iteration`: `61`
  - `tool_call`: `227`
  - `tool_result`: `227`
- Top tool calls (global):
  - `op_set_single_literal`: `55`
  - `op_set_single_iri`: `41`
  - `ontology_node_outgoing`: `31`
  - `cq_eval`: `29`
  - `ontology_validate`: `24`
- Largest tool return payloads were `ontology_validate` (`~10k-16k chars`), the dominant contributor to `large_returns`.

## Behavioral Findings

1. The agent consistently followed the tool-first execution style:
   - Inspect CQ/context -> mutate graph with operators -> re-evaluate (`cq_eval`) -> re-validate (`ontology_validate`) -> submit.
2. CoT and code traces were captured for each iteration (`61` iteration events total), including intermediate reasoning and generated code blocks.
3. Memory channel was unused during this run:
   - Summary reports `memory_stats.items_total = 0` (no principles/episodes persisted).

## Failure Analysis

### CQ2 failure (remained false)

- Pattern observed: repeated retries with alternative predicates (`hasMember`, `member`, `hasKnowledgeGraph`, `dcat:distribution`, `dct:hasPart`) while `cq_eval("CQ2")` stayed false.
- Root issue from trajectory behavior: the agent created and edited `http://la3d.local/dataset/kd1` and `http://la3d.local/kg/graph1`, while CQ2 expects the specific query targets (`ex:ds1` and `ex:kg1`) from the competency question.
- Result: structurally plausible edits, but wrong target individuals for the CQ predicate bindings.

### CQ5 failure (remained false)

- Pattern observed: heavy mutation of `prof:hasResource` and related profile fields with repeated overwrites.
- Root issue from tool semantics:
  - `op_set_single_iri` is destructive (single-value replace), but CQ5/SHACL constraints require multi-valued resource links and multiple conformance links.
  - The agent repeatedly replaced `prof:hasResource` instead of accumulating required role-qualified descriptors.
- Result: persistent profile/resource SHACL failures despite substantial editing.

### Global SHACL non-conformance

- Even when CQ-specific goals passed (`CQ1`, `CQ3`, `CQ4`), global shape requirements remained unresolved.
- High-volume `ontology_validate` payloads increased context pressure and large return counts without sufficient reduction in unresolved violations.

## Pre-Fix Conclusions

The experiment validates the trajectory logging pipeline and exposes two concrete architectural bottlenecks before further tuning:

1. **Target binding mismatch** for CQ-driven edits (agent often repairs semantically correct but query-irrelevant nodes).
2. **Operator expressivity gap** for multi-valued RDF properties (single-value setters are insufficient for PROF/SHACL profile constraints).

Given these constraints, the current runner is suitable for diagnostics but not yet for reliable convergence on profile-heavy SHACL tasks.

## Recommended Next Fixes (Not Applied in This Report)

1. Add additive graph operators for multi-valued object properties:
   - `add_iri_link(node, prop, value)` and `remove_iri_link(node, prop, value)` without replacing all values.
2. Add CQ target introspection helpers:
   - expose required subject/object anchors from each CQ so edits are bound to expected IRIs.
3. Add compact validation views:
   - return grouped signature counts by default; keep full report behind handle to reduce large returns.
4. Require memory write-back on each CQ:
   - persist `Episode` records keyed by violation signature and operator outcome.
